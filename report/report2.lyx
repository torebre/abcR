#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\begin_preamble
% Først spesifiserer vi hvilken dokumentklasse vi vil ha og noen 
% globale opsjoner. Bytt ut 'article' med 'book' hvis du vil ha 
% med kapitler.
%\documentclass[a4paper, twoside, titlepage, 11pt]{article}

% Så sier vi fra om hvilke tilleggspakker vi trenger
% til dokumentet vårt. De som du ikke trenger (se kommentaren) 
% kan det være en fordel å kommentere ut (sett prosenttegn foran),
% da vil kompilering gå raskere.

%\usepackage[norsk]{babel}	% norske navn rundt omkring
\usepackage[T1]{fontenc}		% norsk tegnsett (æøå)
%\usepackage[utf8]{inputenc}	% norsk tegnsett
\usepackage{geometry}		% anbefalt pakke for å styre marger.

\usepackage{amsmath,amsfonts,amssymb} % matematikksymboler
\usepackage{amsthm}                   % for å lage teoremer og lignende.
\usepackage{graphicx}                 % inkludering av grafikk
\usepackage{subfig}                   % hvis du vil kunne ha flere
                                      % figurer inni en figur
\usepackage{listings}                 % Fin for inkludering av kildekode

%\usepackage{hyperref}                % Lager hyperlinker i evt. pdf-dokument
                                      % men har noen bugs, så den er kommentert
                                      % bort her.
                                 
% Indeksgenerering er kommentert ut her. Ta bort prosenttegnene
% hvis du vil ha en indeks:
%\usepackage{makeidx}     
%\makeindex              

\usepackage{placeins}

\usepackage{algpseudocode}


% \begin{document}

\pagestyle{empty}
\pagenumbering{roman}

% Inkluder forsida:
%\input{forside}


% Romerske tall på alt før selve rapporten starter er pent.
\pagenumbering{roman}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding utf8-plain
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand include
filename "forside.tex"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
pagestyle{headings}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
pagenumbering{arabic} 
\end_layout

\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Approximate Bayesian Computation (ABC) is a term used for methods that in
 a Bayesian setting estimate the posterior without evaluating the likelihood
 function.
 Because the likelihood function is not evaluated, ABC methods are also
 known as 
\shape italic
likelihood-free
\shape default
 methods.
 The first such were developed in the field of population genetics in the
 late 1990s
\begin_inset Note Note
status open

\begin_layout Plain Layout
Check if this is a correct spelling
\end_layout

\end_inset

, and has since found use in other areas, notably in those with a relation
 to biology, see sections 3 and 7 in 
\begin_inset CommandInset citation
LatexCommand cite
key "1ef20ace6466467899d76e9976c9b6fa"

\end_inset

 for a history and examples.
 There are also examples of use in other fields, for instance image analysis
 
\begin_inset CommandInset citation
LatexCommand cite
key "Moores2014"

\end_inset

 and dynamical model selection 
\begin_inset CommandInset citation
LatexCommand cite
key "Toni187"

\end_inset

.
\end_layout

\begin_layout Standard
There is research being done on several aspects of ABC, see 
\begin_inset CommandInset citation
LatexCommand cite
key "approx_bayes_comp"

\end_inset

 for an overview of research on the computational part.
 Here we will focus on one computational strategy that there are several
 variations on in the ABC literature: Use of what is called sequential Monte
 Carlo (SMC) when obtaining samples from the approximation to the posterior.
 More specifically we will focus on the work done in 
\begin_inset CommandInset citation
LatexCommand cite
key "adaptive_smc_for_abc"

\end_inset

 and explain that in detail.
\end_layout

\begin_layout Standard
We start with a quick look at the basics of Bayesian inference, and point
 out that there can often be a problem in evaluating the posterior probability.
 From here we look at some strategies for approximating the posterior, before
 we move on to the situation where we cannot evaluate the likelihood function,
 and it is here ABC becomes an alternative.
 We then describe ABC in general, before looking at the mentioned SMC in
 ABC approach for obtaining samples.
 This approach will be illustrated by some examples, and comparisons to
 other ABC methods.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Check names in reference list
\end_layout

\end_inset


\end_layout

\begin_layout Section
Bayesian inference
\end_layout

\begin_layout Standard
We start with a quick overview of the basics of Bayesian inference to better
 our understanding of the problems that led to the development of ABC methods.
\end_layout

\begin_layout Standard
Our main goal is to summarize a dataset, 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, through a set of functions on the data 
\begin_inset Formula $S(\boldsymbol{y})$
\end_inset

.
 We call a such a function of the data a statistic, and the they can in
 turn be estimates for parameters, which we denote 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 here, in a model.
 We assume that 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 is a sample from a random vector, 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

.
 If 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 only was a single number, we would call it a sample from a random variable
 
\begin_inset Formula $Y$
\end_inset

.
 A random vector is a function from the sample space to 
\begin_inset Formula $\mathbb{R}^{n}$
\end_inset

, and a statistic is in turn defined to be a function on a random variable/vecto
r.
 For a more thorough look at the definitions see chapter 5 of 
\begin_inset CommandInset citation
LatexCommand cite
key "CaseBerg:01"

\end_inset

.
\end_layout

\begin_layout Standard
To make it more concrete, 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 could be the heights of 50 people, and then the random variable 
\begin_inset Formula $\boldsymbol{X}$
\end_inset

 would be a function from the sample space, which here would the set of
 all permutations of 50 people in the population, into 
\begin_inset Formula $\mathbb{R}^{50}$
\end_inset

.
 A statistic of interest could be the average height of the population,
 and to estimate it we could define 
\begin_inset Formula $\hat{\theta}=\frac{1}{50}\sum_{i=1}^{50}Y_{i}$
\end_inset

, where 
\begin_inset Formula $\hat{\theta}$
\end_inset

 is an estimate of the population average, 
\begin_inset Formula $\theta$
\end_inset

, using the smaller sample set.
\end_layout

\begin_layout Standard
There are two approaches to viewing 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

.
 One is called the frequentist approach, where 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 is viewed as a vector of fixed numbers.
 That is: For the height example, 
\begin_inset Formula $\theta$
\end_inset

 is the average of all members of the population, which is a fixed number,
 but one that we can not compute without much effort: Gathering all the
 individuals and measuring their heights.
 So we instead make inferences using the smaller sample set, 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, and try to answer questions like: What is the probability that the interval
 
\begin_inset Formula $[175,185]$
\end_inset

 centimeters cover the true value 
\begin_inset Formula $\theta$
\end_inset

?
\end_layout

\begin_layout Standard
A different approach is to view 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 as a random vector.
 Here we say that for the purposes of analysis 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 is allowed to take on values from a set, but that some values may be more
 likely than others.
 This changes the form of the answer we give to our goal from that of the
 frequentist approach.
 We now answer questions of the type: How likely is 
\begin_inset Formula $\boldsymbol{\theta}_{1}$
\end_inset

, say, as a value of 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 given the data 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

.
 This question would not make sense in the frequentist setting, since there
 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 is fixed, and either 
\begin_inset Formula $\boldsymbol{\theta}_{1}=\boldsymbol{\theta}$
\end_inset

 or 
\begin_inset Formula $\boldsymbol{\theta}_{1}\neq\boldsymbol{\theta}$
\end_inset

, resulting in probability 1 or 0 respectively
\begin_inset Note Note
status open

\begin_layout Plain Layout
Make more clear
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
Viewing 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 as a random vector gives us what is termed the Bayesian approach to inference.
 We can reformulate our main goal a bit to better fit in this framework:
 Let 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 denote a vector of model parameters, and 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 is a vector of observed data.
 Our aim is to make inferences about 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 that are consistent with the observed data.
 In a data analysis setting we can view this inference process to consist
 of three steps (see 
\begin_inset CommandInset citation
LatexCommand cite
key "gelman2013bayesian"

\end_inset

 for a full treatment on all aspects of Bayesian data analysis):
\end_layout

\begin_layout Enumerate
Setting up a full probability model.
 This means formulating a joint probability model for 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

: 
\begin_inset Formula $p(\boldsymbol{\theta},\boldsymbol{y})$
\end_inset

.
 Note again that we can do this is because 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 is a random vector, as opposed to the frequentist approach.
\end_layout

\begin_layout Enumerate
Conditioning on the observed data.
 This means evaluating 
\begin_inset Formula $p(\boldsymbol{\theta}|\boldsymbol{y})$
\end_inset

.
\end_layout

\begin_layout Enumerate
Evaluating the model.
 If the model does not fit the observed data, it can be changed, and the
 process starts from step 1 again.
\end_layout

\begin_layout Standard
In step 2 above, we need to make inferences about 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 given the observed data 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

.
 If we condition on the observed data, we can make use of Bayes' rule and
 write the conditional distribution as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(\boldsymbol{\theta}|\boldsymbol{y})=\frac{p(\boldsymbol{\theta},\boldsymbol{y})}{p(\boldsymbol{y})}=\frac{p(\boldsymbol{y}|\boldsymbol{\theta})p(\boldsymbol{\theta})}{p(\boldsymbol{y})}
\]

\end_inset


\end_layout

\begin_layout Standard
The factor 
\begin_inset Formula $p(\boldsymbol{y})$
\end_inset

 does not depend on 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

, and since the data is given, that is; 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 does not change, 
\begin_inset Formula $p(\boldsymbol{\theta}|\boldsymbol{y})$
\end_inset

 is a function of 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 only, and we can view 
\begin_inset Formula $p(\boldsymbol{y})$
\end_inset

 as a constant.
 We can thus write:
\begin_inset Formula 
\[
p(\boldsymbol{\theta}|\boldsymbol{y})\propto p(\boldsymbol{y}|\boldsymbol{\theta})p(\boldsymbol{\theta})
\]

\end_inset


\end_layout

\begin_layout Standard
There are expressions for the two terms on the right side: 
\begin_inset Formula $p(\boldsymbol{y}|\boldsymbol{\theta})$
\end_inset

 is termed the likelihood, and noting since 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 is constant, it is a function of 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

, and 
\begin_inset Formula $p(\boldsymbol{\theta})$
\end_inset

 is termed the prior distribution.
\begin_inset Note Note
status open

\begin_layout Plain Layout
Also mention predictive distribution
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Evaluating the posterior
\end_layout

\begin_layout Standard
Concentrating on the 
\begin_inset Formula $p(\boldsymbol{y}|\boldsymbol{\theta})p(\boldsymbol{\theta})$
\end_inset

 form of the joint distribution, we need to think about how to set up the
 likelihood and prior.
 The prior represents our knowledge of 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 before we have seen any experimental data.
 This knowledge may be vague, or non-existent, in which case it might make
 sense to formulate 
\begin_inset Formula $p(\boldsymbol{\theta})$
\end_inset

 as uniform distribution over all possible values 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 can take, 
\begin_inset Formula $\boldsymbol{\theta}\sim\mathrm{Uniform}(\boldsymbol{\theta}_{min},\boldsymbol{\theta}_{max})$
\end_inset

, presuming we at least know what is the possible range.
 Or it may be that we have some prior knowledge that allows us to be more
 specific.
\end_layout

\begin_layout Standard
The expression for the likelihood is also formulated as a probability distributi
on.
 Keeping with the height example we can propose: 
\begin_inset Formula $p(\boldsymbol{y}|\boldsymbol{\theta})\sim\mathrm{N}(\theta_{1},\theta_{2})$
\end_inset

, a normal distribution with mean 
\begin_inset Formula $\theta_{1}$
\end_inset

 and variance 
\begin_inset Formula $\theta_{2}$
\end_inset

, so that 
\begin_inset Formula $\boldsymbol{\theta}=[\theta_{1},\theta_{2}]$
\end_inset

.
 To illustrate a point, we will simplify the setup, and say that 
\begin_inset Formula $\theta_{2}$
\end_inset

 is known so that what we are interested in evaluating is 
\begin_inset Formula $p(\theta_{1}|\boldsymbol{y})$
\end_inset

, and that the prior is 
\begin_inset Formula $\theta_{1}\sim\mathrm{N}(\mu,\sigma^{2})$
\end_inset

, with for instance 
\begin_inset Formula $\mu=180$
\end_inset

 and 
\begin_inset Formula $\sigma=10$
\end_inset

.
 In addition we assume the observations, 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, are independent.
 We can then write:
\begin_inset Formula 
\begin{align}
p(\theta_{1}|\boldsymbol{y}) & \propto p(\boldsymbol{y}|\theta_{1})p(\theta_{1})\nonumber \\
 & =\frac{1}{\sqrt{2\pi}\theta_{2}}\exp\left(-\frac{1}{2}\sum_{i=1}^{n}\frac{(y_{i}-\theta_{1})^{2}}{\theta_{2}}\right)\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{1}{2}\frac{(\theta_{1}-\mu)^{2}}{\sigma^{2}}\right)\nonumber \\
 & \propto\exp\left(-\frac{1}{2}\sum_{i=1}^{n}\frac{(y_{i}-\theta_{1})^{2}}{\theta_{2}}-\frac{1}{2}\frac{(\theta_{1}-\mu)^{2}}{\sigma^{2}}\right)\nonumber \\
 & \propto\exp\left(\left(\frac{n}{\theta_{2}^{2}}+\frac{1}{\sigma^{2}}\right)^{-1}\left(\frac{n}{\theta_{2}^{2}}\overline{y}+\frac{\mu}{\sigma^{2}}\right)^{2}+\theta_{1}^{2}\right)^{2}\label{eq:conjugate_prior}
\end{align}

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Check if the variance term needs to be included
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Going from the third to the fourth line above involves a bit of algebra,
 specifially using the trick of completing the square and also using that
 terms not involving 
\begin_inset Formula $\theta_{1}$
\end_inset

 can treated as constants, and thus removed when working with equations
 that only need to be proportional to each other.
\end_layout

\begin_layout Standard
There are a couple of points of interest in equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:conjugate_prior"

\end_inset

.
 One is that the final expression does not involve the actual data points
 in 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, only their average 
\begin_inset Formula $\overline{y}$
\end_inset

.
 This relationship between 
\begin_inset Formula $\overline{y}$
\end_inset

, which is a statistic of 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, and the mean 
\begin_inset Formula $\theta_{1}$
\end_inset

, which is the parameter we want to estimate, has a name: We say that the
 statistic 
\begin_inset Formula $\overline{y}$
\end_inset

 is 
\shape italic
sufficient
\shape default
 for the mean 
\begin_inset Formula $\theta_{1}$
\end_inset

.
 Later we will touch upon this concept again, but see chapter 6 of 
\begin_inset CommandInset citation
LatexCommand cite
key "CaseBerg:01"

\end_inset

 for a more in-depth discussion.
\end_layout

\begin_layout Standard
The other point is that the final expression has the form of the probability
 density function of a normal distribution (we only need to add an appropriate
 constant in front).
 So we have shown that the posterior is a normal distribution.
 When the posterior distribution follows the same form as the prior distribution
, we call that property conjugacy.
 That it followed the same form depended on the fact that we chose the likelihoo
d to be a normal distribution, so we say that the normal prior distribution
 is a conjugate family for normal likelihood.
 Several such couplings exist, for instance the beta prior distribution
 is a conjugate family for the binomial likelihood.
\end_layout

\begin_layout Standard
Using the conjugacy property makes the posterior have a closed form, which
 makes it easy to work with.
 The problem is that we cannot always use this property.
 It may be that the chosen prior and/or likelihood has a form where the
 posterior will be a non-standard distribution or not a closed expression.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Add example?
\end_layout

\end_inset

To evaluate the posterior in such cases we need to look at other techniques
 where we instead compute an approximation to it.
\end_layout

\begin_layout Subsection
Approximating the posterior
\end_layout

\begin_layout Standard
There exist a multitude of methods for approximating a distribution, and
 we will make no attempt at an in-depth description.
 We again refer to 
\begin_inset CommandInset citation
LatexCommand cite
key "gelman2013bayesian"

\end_inset

 which provides an overview.
 
\end_layout

\begin_layout Standard
To get a feel for what the problem is, we proceed with a short discussion
 of some points.
 We might have a closed expression for the probability density function,
 which means a formula with no inifinte series involed, for the distribution,
 but still not be able to easily compute statistics involving it.
 Consider the expected value of some function of a parameter 
\begin_inset Formula $\theta$
\end_inset

:
\begin_inset Formula 
\begin{equation}
\mathrm{E}(h(\theta)|y)=\int h(\theta)p(\theta|y)d\theta\approx\frac{1}{N}\sum_{n=1}^{N}h(\theta_{n}^{s})\label{eq:expected_value}
\end{equation}

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Check use of variables
\end_layout

\end_inset


\end_layout

\begin_layout Standard
It may very well be that we cannot compute the integral in 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:expected_value"

\end_inset

, and so cannot compute the expected value.
 In our one-dimensional, there is only one parameter to estimate, examples
 so far this might not seem like a big problem to handle: The integral can
 be estimated to the required level of accuracy using some numerical procedure.
 However, in more real settings one can be confronted with much larger models
 with many unknown parameters, resulting in a much more complicated high-dimensi
onal integral which will be more difficult to estimate.
\end_layout

\begin_layout Standard
In equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:expected_value"

\end_inset

 we allude to a way of achieving an approximation of the expected value
 without evaluating the integral.
 In the formula 
\begin_inset Formula $\theta_{n}^{s}$
\end_inset

 denotes a simulated sample, that is: It is a draw from 
\begin_inset Formula $p(\theta|y$
\end_inset

).
 Intuitively if we have a large collection of samples, 
\begin_inset Formula $\theta^{s}$
\end_inset

, and compute the average of 
\begin_inset Formula $h(\theta^{s})$
\end_inset

, we expect to get an approximation to the expected value.
\begin_inset Note Note
status open

\begin_layout Plain Layout
Write a bit more
\end_layout

\end_inset


\end_layout

\begin_layout Standard
We can carry this idea further: With sample draws we can get an estimate
 of any aspect of the distribution 
\begin_inset Formula $p(\theta|y)$
\end_inset

, including the distribution itself, see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Approximations-to-normal"

\end_inset

 for an illustration.
 So if we had a method of generating samples from an arbitrary distrubtion,
 it would be a very useful tool.
 In the next section we will describe the foundations of a popular set of
 methods that do just this and go under the collective term Markov Chain
 Monte Carlo (MCMC) methods.
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Approximations to normal distribution.
\begin_inset CommandInset label
LatexCommand label
name "fig:Approximations-to-normal"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/sample_approximations.png
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Markov Chain Monte Carlo
\end_layout

\begin_layout Standard
Even though the method we will focus on later is not an MCMC method, it
 does make use of some the theory underlying MCMC, so we will quickly go
 through some of the basics that we will need to understand the later discussion.
\end_layout

\begin_layout Standard
The core idea of an MCMC method is to use what is called a Markov Chain,
 which is a form of stochastic process, to generate samples from some distributi
on.
 To start us off we define what a stochastic process is: A stochastic process
 is a collection of indexed random variables, 
\begin_inset Formula $X(t)$
\end_inset

, where 
\begin_inset Formula $t$
\end_inset

 is a member of some countable set.
 For instance tossing a coin multiple times could be viewed as a stochastic
 process.
 Let 
\begin_inset Formula $t$
\end_inset

 denote toss number, and let 
\begin_inset Formula $X(t)$
\end_inset

 be 1 if the coin turns up heads, and 0 if tails.
 Assuming the coin is fair we have 
\begin_inset Formula $P(X(t))=\frac{1}{2}$
\end_inset

 for all 
\begin_inset Formula $t$
\end_inset

.
\end_layout

\begin_layout Standard
A Markov Chain is a stochastic process that posesses what is called the
 Markov property:
\begin_inset Formula 
\begin{align*}
P(X(t)=x_{t}|P(X(t-1)_{t-1},P(X(t-2)_{t-2},...)= & P(X(t)=x_{t}|P(X(t-1)=x_{t-1})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The state of the process given its history, depends only on the state at
 the previous step.
 If we assume that the toin tosses mentioned above are independent, this
 process fulfills the Markov property.
 Actually, it more than fulfills it since we have 
\begin_inset Formula $P(X(t)=x_{t}|X(t-1)=x_{t-1})=P(X(t)=x_{t})$
\end_inset

.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Write more.
 Mention Gibbs sampling
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
FloatBarrier
\end_layout

\end_inset


\end_layout

\begin_layout Section
Approximate Bayesian Computation
\end_layout

\begin_layout Standard
The likelihood function may be difficult to evaluate, for instance it may
 be computationally intractable to do so, or the function does not have
 an analytic form.
 In such settings what are termed likelihood-free methods can be employed
 to draw inferences.
 The name refers to the fact that the methods do not explicitly evaluate
 the likelihood function, but instead approximate it using simulations.
 A requirement is then that we must at least be able to generate samples
 from the likelihood.
\end_layout

\begin_layout Standard
To understand how likelihood-free methods work, let us look at the posterior
 again, and introduce an auxillary variable, 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

 (see 
\begin_inset CommandInset citation
LatexCommand cite
key "Sisson2011"

\end_inset

 for more details).
 From Bayes rule we have:
\begin_inset Formula 
\begin{equation}
p(\boldsymbol{\theta},\boldsymbol{x}|\boldsymbol{y})\propto p(\boldsymbol{y}|\boldsymbol{x},\boldsymbol{\theta})p(\boldsymbol{x}|\boldsymbol{\theta})p(\boldsymbol{\theta})\label{eq:abc_sampling_distribution}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The posterior can be retrieved by integrating out 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

:
\begin_inset Formula 
\begin{align*}
p(\boldsymbol{\theta}|\boldsymbol{y}) & \propto p(\boldsymbol{\theta})\int_{Y}p(\boldsymbol{y}|\boldsymbol{x},\boldsymbol{\theta})p(\boldsymbol{x}|\boldsymbol{\theta})d\boldsymbol{x}\\
 & =p(\boldsymbol{\theta})\int_{Y}p(\boldsymbol{y},\boldsymbol{x}|\boldsymbol{\theta})d\boldsymbol{x}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
It is assumed that we have an expression for the prior, 
\begin_inset Formula $p(\boldsymbol{\theta})$
\end_inset

, and are able to generate samples from 
\begin_inset Formula $p(\boldsymbol{x}|\boldsymbol{\theta}).$
\end_inset

 If 
\begin_inset Formula $p(\boldsymbol{y}|\boldsymbol{x},\boldsymbol{\theta})$
\end_inset

 is defined to the Dirac-function with 
\begin_inset Formula $\boldsymbol{x}=\boldsymbol{y}$
\end_inset

 we get:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
p(\boldsymbol{\theta}|\boldsymbol{y}) & \propto p(\boldsymbol{\theta})\int_{Y}I(\boldsymbol{x}=\boldsymbol{y})p(\boldsymbol{x}|\boldsymbol{\theta})d\boldsymbol{x}\nonumber \\
 & =p(\boldsymbol{\theta})p(\boldsymbol{y}|\boldsymbol{\theta})\label{eq:likelihood_dirac}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
If we were able to draw samples from the likelihood function such that 
\begin_inset Formula $\boldsymbol{x}=\boldsymbol{y}$
\end_inset

, we could estimate the posterior probability.
 A simple algorithm for this is shown in algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "likelihoo-free_alg1"

\end_inset

.
 The algorithm will produce samples from the posterior, but there is a practical
 problem in the comparison 
\begin_inset Formula $\boldsymbol{x}=\boldsymbol{y}$
\end_inset

.
 For continuous probability distributions, the probability that two samples
 are exactly the same is 0, and for discrete probability distributions the
 probability for the being the same is also likely to be close to 0 in practical
 problems.
 Agorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "likelihoo-free_alg1"

\end_inset

 is not practically useful, since most samples being generated will be discarded.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Likelihood free sampling
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "likelihoo-free_alg1"

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithmic}
\end_layout

\begin_layout Plain Layout


\backslash
State $counter 
\backslash
leftarrow 0$
\end_layout

\begin_layout Plain Layout


\backslash
State $samples 
\backslash
leftarrow 
\backslash
text{empty array}$
\end_layout

\begin_layout Plain Layout


\backslash
While{$counter<N$}
\end_layout

\begin_layout Plain Layout


\backslash
State Sample $
\backslash
boldsymbol{
\backslash
theta}$ from $p(
\backslash
boldsymbol{
\backslash
theta})$ 
\end_layout

\begin_layout Plain Layout


\backslash
State Sample $
\backslash
boldsymbol{x}$ from $p(
\backslash
boldsymbol{x}|
\backslash
boldsymbol{
\backslash
theta})$
\end_layout

\begin_layout Plain Layout


\backslash
If{$
\backslash
boldsymbol{x}=
\backslash
boldsymbol{y}$}
\end_layout

\begin_layout Plain Layout


\backslash
State $samples[counter] 
\backslash
leftarrow 
\backslash
boldsymbol{
\backslash
theta}$
\end_layout

\begin_layout Plain Layout


\backslash
State $counter=counter+1$
\end_layout

\begin_layout Plain Layout


\backslash
EndIf
\end_layout

\begin_layout Plain Layout


\backslash
EndWhile
\end_layout

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Keeping the core idea, we can make a couple of changes to make the algorithm
 more useful.
 The requirement that 
\begin_inset Formula $\boldsymbol{x}=\boldsymbol{y}$
\end_inset

 can be relaxed, and instead samples that lie within some defined distance
 of 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 are accepted: 
\begin_inset Formula $d(\boldsymbol{x},\boldsymbol{y})\leq\rho$
\end_inset

.
 This begs the question what 
\begin_inset Formula $\rho$
\end_inset

 should be, and how it affects the approximation.
 Intuitively smaller values yields better approximations, but increases
 computation time, since more samples are discarded.
 We will examine strategies to determine 
\begin_inset Formula $\rho$
\end_inset

 later.
\end_layout

\begin_layout Standard
We also need to make a choice for a distance function 
\begin_inset Formula $d(\boldsymbol{x},\boldsymbol{y})$
\end_inset

.
 If 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 are vectors consisting of numbers, the Euclidean distance could for instance
 be used, which may or may not be a good choice.
 In other cases the Euclidean distance measure cannot be used directly on
 the samples, if the sample for instance represents a DNA sequence, which
 does not have a clear numerical representation.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Add some examples of what a sample can be (DNA sequence, result from a stochasti
c process)
\end_layout

\end_inset

 Attention also has to be paid to the cost of evaluating 
\begin_inset Formula $d(\boldsymbol{x},\boldsymbol{y})$
\end_inset

.
 The samples can contain large amount of data, again think of a DNA sequence
 as an example.
\end_layout

\begin_layout Standard
If we cannot find a suitable distance measure that works directly on the
 samples, or if it would be computationally intractable to evaluate such
 a distance function, we can instead focus on summary statistics for the
 sample.
 Let 
\begin_inset Formula $\mathrm{S}(\boldsymbol{x})$
\end_inset

 denote the possibly vector valued summary statistic we have chosen for
 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

.
 The main point is that we assume 
\begin_inset Formula $dim(S(\boldsymbol{x}))<dim(\boldsymbol{x})$
\end_inset

 holds, and so it should be computationally cheaper to evaluate 
\begin_inset Formula $d(S(\boldsymbol{x}),S(\boldsymbol{y}))$
\end_inset

.
 Also note that the reduction in dimension in practice renders the probability
 that 
\begin_inset Formula $S(\boldsymbol{x})=S(\boldsymbol{y})$
\end_inset

 greater than that of 
\begin_inset Formula $\boldsymbol{x}=\boldsymbol{y}.$
\end_inset

 This improves the efficiency of algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "likelihoo-free_alg1"

\end_inset

, but again, probably not to such a degree to make it practically useful.
\end_layout

\begin_layout Standard
Ideally we would want 
\begin_inset Formula $\mathrm{S}(\cdot)$
\end_inset

 to be sufficient for the parameters that are being estimated, since then
 we have the following relation, again letting 
\begin_inset Formula $p(S(\boldsymbol{y})|S(\boldsymbol{x}),\boldsymbol{\theta})$
\end_inset

 be the Dirac-delta function:
\begin_inset Formula 
\begin{align*}
p(\boldsymbol{\theta},S(\boldsymbol{x})|S(\boldsymbol{y})) & \propto p(\boldsymbol{\theta})\int_{S(Y)}p(S(\boldsymbol{y})|S(\boldsymbol{x}),\boldsymbol{\theta})p(S(\boldsymbol{x})|\boldsymbol{\theta})dS(\boldsymbol{x})\\
 & =p(\boldsymbol{\theta})p(S(\boldsymbol{y})|\boldsymbol{\theta})\\
 & \text{by sufficiency}\\
 & =p(\boldsymbol{\theta})p(\boldsymbol{y}|\boldsymbol{\theta})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Add section about distance measures on statistics
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Several strategies have been developed for dealing with the difficulties
 in ABC: Finding suitable statistics automatically and improving the efficiency,
 being two areas where work has been done.
 See 
\begin_inset CommandInset citation
LatexCommand cite
key "approx_bayes_comp"

\end_inset

 for an overview of areas of research.
\begin_inset Note Note
status open

\begin_layout Plain Layout
Add an example scenario where the likelihood cannot be calculated
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
MCMC in ABC
\end_layout

\begin_layout Standard
To motivate the development of the a sequential Monte Carlo later, we will
 quickly show how MCMC can be used in an ABC setting, and point out a problem
 that the sequential sampler addresses.
 In algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:Markov-Chain-Monte-in-ABC"

\end_inset

 a method described in 
\begin_inset CommandInset citation
LatexCommand cite
key "Marjoram23122003"

\end_inset

 is outlined.
 
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Markov Chain Monte Carlo in an ABC setting
\begin_inset CommandInset label
LatexCommand label
name "alg:Markov-Chain-Monte-in-ABC"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithmic}
\end_layout

\begin_layout Plain Layout


\backslash
Require $
\backslash
boldsymbol{
\backslash
theta}_{init}, N$
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
State $counter 
\backslash
leftarrow 1$
\end_layout

\begin_layout Plain Layout


\backslash
State $samples 
\backslash
leftarrow array[N]$
\end_layout

\begin_layout Plain Layout


\backslash
State $samples[0] 
\backslash
leftarrow 
\backslash
boldsymbol{
\backslash
theta}_{init}$
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
While{$counter < N$}
\end_layout

\begin_layout Plain Layout


\backslash
State $samples[counter] 
\backslash
leftarrow 
\backslash
mathrm{DoMetropolisHastingsStep}(samples[counter - 1])$
\end_layout

\begin_layout Plain Layout


\backslash
State $counter 
\backslash
leftarrow counter + 1$
\end_layout

\begin_layout Plain Layout


\backslash
EndWhile
\end_layout

\begin_layout Plain Layout


\backslash
newline
\end_layout

\begin_layout Plain Layout


\backslash
Function{DoMetropolisHastingsStep}{$
\backslash
boldsymbol{
\backslash
theta}_ {old}, 
\backslash
boldsymbol{y}, 
\backslash
epsilon$}
\end_layout

\begin_layout Plain Layout


\backslash
While{true}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
State Sample $
\backslash
boldsymbol{
\backslash
theta}_{new}$ from $q(
\backslash
boldsymbol{
\backslash
theta}_ {old}, 
\backslash
boldsymbol{
\backslash
theta}_ {new})$
\end_layout

\begin_layout Plain Layout


\backslash
If{$Distance(
\backslash
boldsymbol{x}, 
\backslash
boldsymbol{y}) < 
\backslash
epsilon$}
\end_layout

\begin_layout Plain Layout


\backslash
State $ratio 
\backslash
leftarrow 
\backslash
frac{q(
\backslash
boldsymbol{
\backslash
theta}_ {new}, 
\backslash
boldsymbol{
\backslash
theta}_ {old})p(
\backslash
boldsymbol{
\backslash
theta}_{new})}{q(
\backslash
boldsymbol{
\backslash
theta}_ {old}, 
\backslash
boldsymbol{
\backslash
theta}_ {new})p(
\backslash
boldsymbol{
\backslash
theta}_{old})}$
\end_layout

\begin_layout Plain Layout


\backslash
State Sample $u$ from $
\backslash
mathrm{Uniform}(0,1)$
\end_layout

\begin_layout Plain Layout


\backslash
If{$ratio < u$}
\end_layout

\begin_layout Plain Layout


\backslash
State 
\backslash
textbf{return} $
\backslash
boldsymbol{
\backslash
theta}_{new}$
\end_layout

\begin_layout Plain Layout


\backslash
EndIf
\end_layout

\begin_layout Plain Layout


\backslash
EndIf
\end_layout

\begin_layout Plain Layout


\backslash
EndWhile
\end_layout

\begin_layout Plain Layout


\backslash
EndFunction
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Show MCMC method, and how SMC can be an alternative?
\end_layout

\end_inset


\end_layout

\begin_layout Section
Sequential Monte Carlo in an ABC setting
\end_layout

\begin_layout Standard
Sequential Monte Carlo (SMC) methods provide an alternative to MCMC methods
 when generating samples from a distribution, and there exist several variations
 on how it is used within ABC, see for example 
\begin_inset CommandInset citation
LatexCommand cite
key "Peters2012,Toni187,adaptive_smc_for_abc"

\end_inset

.
 An SMC method decomposes the problem of generating a sample from the target
 distribution into a sequence of steps that are smaller and simpler than
 trying to generate a sample directly.
 It does this by first generating a number of samples from an approximation
 to the target distribution, termed particles, and then updating these by
 guiding them through the series of further approximations to the target
 distribution.
 We will in the following look at the algorithm developed in 
\begin_inset CommandInset citation
LatexCommand cite
key "adaptive_smc_for_abc"

\end_inset

, which in turn builds on what is termed an SMC sampler developed in 
\begin_inset CommandInset citation
LatexCommand cite
key "citeulike:637817"

\end_inset

.
\end_layout

\begin_layout Standard
The output in the end is a set of weighted samples, which in turn can be
 used to approximate a sample set from the target distribution.
 The premise will be explained in detail, and we start with the concept
 of a weighted sample, which we illustrate by looking at the sampling importance
 resampling (SIR) method for generating samples from a distribution.
\end_layout

\begin_layout Subsection
Sampling importance resampling algorithm
\begin_inset CommandInset label
LatexCommand label
name "sub:Sampling-importance-resampling"

\end_inset


\end_layout

\begin_layout Standard
Suppose we have a 
\begin_inset Formula $k$
\end_inset

-dimensional random variable 
\begin_inset Formula $\boldsymbol{X}$
\end_inset

 coming from a distribution with probability density function 
\begin_inset Formula $p(\boldsymbol{x})$
\end_inset

, and that we are unable to generate samples it from because it is computational
ly intractable.
 Suppose further that we have another density defined on the same space
 that we are able to generate samples from, and that this density has probabilit
y density function 
\begin_inset Formula $g(\boldsymbol{x})$
\end_inset

 and the following holds:
\begin_inset Formula 
\[
\exists c\text{ such that }cg(\boldsymbol{x})\geq p(\boldsymbol{x}),\forall\boldsymbol{x}
\]

\end_inset


\end_layout

\begin_layout Standard
In words: There must be a constant 
\begin_inset Formula $c$
\end_inset

 such that 
\begin_inset Formula $g(\boldsymbol{x})$
\end_inset

 always is greater than 
\begin_inset Formula $p(\boldsymbol{x})$
\end_inset

.
 An illustration is provided in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Target-and-proposal"

\end_inset

.
 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Caption

\begin_layout Plain Layout
Target and proposal distribution.
\begin_inset CommandInset label
LatexCommand label
name "fig:Target-and-proposal"

\end_inset


\end_layout

\end_inset


\begin_inset Graphics
	filename figures/targetAndProposalIllustration.png
	scale 60

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
We can use this relationship to give the samples we draw from 
\begin_inset Formula $g(\cdot)$
\end_inset

 a weight based on how probable this sample is under 
\begin_inset Formula $p(\cdot)$
\end_inset

, and then use these samples and weights to generate samples that approximate
 the distribution of 
\begin_inset Formula $\boldsymbol{X}$
\end_inset

.
 Since we are drawing samples from 
\begin_inset Formula $g(\cdot)$
\end_inset

 we call it the proposal distribution.
 
\end_layout

\begin_layout Standard
To see how this relationship lets us approximate the distribution of 
\begin_inset Formula $\boldsymbol{X}$
\end_inset

, we start by defining the quantity known as the standardized importance
 weight as:
\begin_inset Formula 
\[
w(\boldsymbol{x}_{i})=\frac{p(\boldsymbol{x}_{i})/g(\boldsymbol{x}_{i})}{\sum_{i=1}^{m}p(\boldsymbol{x}_{i})/g(\boldsymbol{x}_{i})}
\]

\end_inset


\end_layout

\begin_layout Standard
The reason why we standardise the weights, is that we then do not have to
 think about 
\begin_inset Formula $c$
\end_inset

, since it will cancel in the nominator and denominator.
 We also define 
\begin_inset Formula $\boldsymbol{y}_{1},...,\boldsymbol{y}_{n}$
\end_inset

 to be draws from the distribution of 
\begin_inset Formula $g(\boldsymbol{x})$
\end_inset

 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Use better notation
\end_layout

\end_inset

.
 Now consider the following algorithm:
\end_layout

\begin_layout Enumerate
Sample 
\begin_inset Formula $\boldsymbol{y}_{1},...,\boldsymbol{y}_{n}$
\end_inset

 from 
\begin_inset Formula $g(\boldsymbol{x})$
\end_inset

 
\end_layout

\begin_layout Enumerate
Calculate the weights, 
\begin_inset Formula $w(\boldsymbol{y}_{i})=\frac{p(\boldsymbol{y}_{i})}{g(\boldsymbol{y}_{i})}$
\end_inset


\end_layout

\begin_layout Enumerate
Resample from the set 
\begin_inset Formula $\boldsymbol{y}_{1},...,\boldsymbol{y}_{n}$
\end_inset

 
\begin_inset Formula $m$
\end_inset

 times with probabilities for drawing 
\begin_inset Formula $\boldsymbol{y}_{i}$
\end_inset

 being proportional to the weight 
\begin_inset Formula $w(\boldsymbol{y}_{i})$
\end_inset

.
 Denote this resampled set as 
\begin_inset Formula $\boldsymbol{y}_{1},...,\boldsymbol{y}_{m}$
\end_inset

.
\end_layout

\begin_layout Standard
We now claim that the sample set 
\begin_inset Formula $\boldsymbol{y}_{1},...,\boldsymbol{y}_{m}$
\end_inset

 converges to the distribution for 
\begin_inset Formula $p(\boldsymbol{x})$
\end_inset

 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Use better notation
\end_layout

\end_inset

as 
\begin_inset Formula $m\to\infty$
\end_inset

.
 Following a similar route as found in 
\begin_inset CommandInset citation
LatexCommand cite
after "pp. 293-295"
key "ross2013simulation"

\end_inset

 we prove this by first noting that:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
P(\boldsymbol{X}\in A|\boldsymbol{Y}_{1},...,\boldsymbol{Y}_{n}) & =\frac{\sum_{i=1}^{n}I(\boldsymbol{Y}_{i}\in A)w(\boldsymbol{Y}_{i})}{\sum_{i=1}^{n}w(\boldsymbol{Y}_{i})}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
By the strong law of large numbers we get:
\begin_inset Note Note
status open

\begin_layout Plain Layout
Check strong law of large numbers
\end_layout

\end_inset


\begin_inset Formula 
\begin{align*}
\lim_{n\to\infty}\sum_{i=1}^{n}\frac{1}{n} & I(\boldsymbol{Y}_{i}\in A)w(\boldsymbol{Y}_{i})=\\
 & =E(I(\boldsymbol{Y}\in A)w(\boldsymbol{Y}))\\
 & =E(I(\boldsymbol{Y}\in A)w(\boldsymbol{Y})|I(\boldsymbol{Y}\in A))P(I(\boldsymbol{Y}\in A)\\
 & =E(w(\boldsymbol{Y})|\boldsymbol{Y}\in A)P(\boldsymbol{Y}\in A)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We also have:
\begin_inset Formula 
\begin{align*}
\lim_{n\to\infty}\sum_{i=1}^{n}\frac{1}{n}w(\boldsymbol{Y}_{i}) & =E(w(\boldsymbol{Y}))\\
 & =E(\frac{p(\boldsymbol{Y})}{g(\boldsymbol{Y})})\\
 & =\int\frac{p(\boldsymbol{y})}{g(\boldsymbol{y})}g(\boldsymbol{y})d\boldsymbol{y}\\
 & =\int p(\boldsymbol{y})d\boldsymbol{y}\\
 & =C
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $C$
\end_inset

 is an unknown constant.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{alignat*}{1}
\lim_{n\to\infty}P(\boldsymbol{X}\in A|\boldsymbol{Y}_{1},...,\boldsymbol{Y}_{n}) & =C^{-1}E(w(\boldsymbol{Y})|\boldsymbol{Y}\in A)P(\boldsymbol{Y}\in A)\\
 & =C^{-1}\int_{\boldsymbol{y}\in A}\frac{p(\boldsymbol{y})}{g(\boldsymbol{y})}g(\boldsymbol{y})d\boldsymbol{y}\\
 & =C^{-1}\int_{\boldsymbol{y}\in A}p(\boldsymbol{y})d\boldsymbol{y}
\end{alignat*}

\end_inset


\end_layout

\begin_layout Standard
On the other hand we have by Lebesgue's dominated convergence theorem:
\begin_inset Formula 
\[
P(\boldsymbol{X}\in A)=CE(P(\boldsymbol{X}\in A)|\boldsymbol{Y}_{1},...\boldsymbol{Y}_{n})=\int_{\boldsymbol{y}\in A}p(\boldsymbol{y})d\boldsymbol{y}
\]

\end_inset


\end_layout

\begin_layout Standard
The constant 
\begin_inset Formula $C$
\end_inset

 does not affect the sampling distribution, and we see that for large 
\begin_inset Formula $m$
\end_inset

 we get a good approximation to the distribution.
 In the next section we will extend the weight calculation step by splitting
 into several smaller steps that can be computed recursively.
\end_layout

\begin_layout Subsection
Sequential Importance Sampling
\begin_inset CommandInset label
LatexCommand label
name "sub:Sequential-Importance-Sampling"

\end_inset


\end_layout

\begin_layout Standard
The expression for the weight in the previous section, 
\begin_inset Formula $w(\boldsymbol{x})=\frac{p(\boldsymbol{x})}{g(\boldsymbol{x})}$
\end_inset

, can be rewritten as follows:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
w(\boldsymbol{x})=\frac{p(x_{1})p(x_{2}|x_{1})p(x_{3}|x_{1},x_{2})...p(x_{k}|x_{1},...,x_{k-1})}{g(x_{1})g(x_{2}|x_{1})g(x_{3}|x_{1},x_{2})...g(x_{k}|x_{1},...,x_{k-1})}\label{eq:weight_decomposition}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
If we define 
\begin_inset Formula $\boldsymbol{x}_{t}=(x_{1},...,x_{t})$
\end_inset

, the above can be written recursively as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
w_{t}(\boldsymbol{x})=w_{t-1}(\boldsymbol{x}_{t-1})\frac{p(x_{t}|\boldsymbol{x}_{t-1})}{g(x_{t}|\boldsymbol{x}_{t-1})}
\]

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $1\leq t\leq k$
\end_inset

, we define 
\begin_inset Formula $w(\boldsymbol{x})=w_{k}(\boldsymbol{x}_{t})$
\end_inset

.
 To ease the notation we define 
\begin_inset Formula $u_{t}(\boldsymbol{x}_{t-1})=\frac{p(x_{t}|\boldsymbol{x}_{t-1})}{g(x_{t}|\boldsymbol{x}_{t-1})}$
\end_inset

 and call it the weight update.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Check that the expression is correct
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Doing such a decomposition has some advantages when dealing with high-dimensiona
l problems, where it is difficult to find a good proposal distribution
\begin_inset CommandInset citation
LatexCommand cite
after "pp. 46-47"
key "liu2001monte"

\end_inset

: It lets us stop calculation of the weights early if we see it comes close
 to 0, and we can also make use of 
\begin_inset Formula $p(x_{t}|\boldsymbol{x}_{t-1})$
\end_inset

 when setting up the proposal distribution 
\begin_inset Formula $g(x_{t}|\boldsymbol{x}_{t-1})$
\end_inset

.
\end_layout

\begin_layout Standard
There is a problem in that we need the marginal distributions, 
\begin_inset Formula $p(x_{1})$
\end_inset

,
\begin_inset Formula $p(x_{1},x_{2})$
\end_inset

,..., to get expressions for the conditional distributions.
 To get the marginal distributions there is a need to integrate out variables.
 For instance:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(x_{1},x_{2})=\int...\int p(x_{1},x_{2},...,x_{k})\mathrm{d}x_{3}...\mathrm{d}x_{k}
\]

\end_inset


\end_layout

\begin_layout Standard
This may be difficult, or impossible, and to get around this problem, we
 introduce another layer of complexity and look for a sequence of marginal
 distributions that are approximations to 
\begin_inset Formula $p(\boldsymbol{x}_{t})$
\end_inset

: 
\begin_inset Formula $\hat{p}(x_{1})$
\end_inset

, 
\begin_inset Formula $\hat{p}(x_{1},x_{2})$
\end_inset

,...,
\begin_inset Formula $p(x_{1},x_{2},...,x_{k})$
\end_inset

.
 The full joint distribution in the previous is not an approximation, but
 the actual 
\begin_inset Formula $p(\boldsymbol{x})$
\end_inset

.
 So we can view the approximations as converging to the true distribution.
 
\end_layout

\begin_layout Standard
In summary we are faced with two challenges: Finding good proposal distributions
, and approximations 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\hat{p}(x_{t}|\boldsymbol{x}_{t-1})$
\end_inset

.
\end_layout

\begin_layout Subsubsection
Weight degeneracy
\end_layout

\begin_layout Standard
When updating the weights, their variance will increase, that is: They will
 spread out.
 It may happen that a proportion of the weights tend toward 0.
 This does not mean that the particles with these weights are stuck in a
 low weight region forever, but in practice we would like to avoid spending
 too much computational resources on updating particles that do not contribute
 to our approximation of 
\begin_inset Formula $p(\boldsymbol{x})$
\end_inset

.
 A low weight means a low probability of drawing that particle in step 3
 in the SIR algorithm in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Sampling-importance-resampling"

\end_inset

.
\end_layout

\begin_layout Standard
A strategy to better utilize the computational resources is to insert a
 resampling step in the incremental weight update process if a high proportion
 of the particles get stuck with low weights.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Add section on problems: Weight degeneracy.
 How to remedy: Resampling
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Sequential Markov chain sampler
\end_layout

\begin_layout Standard
Recalling the nominator and denominator from 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:weight_decomposition"

\end_inset

, we see that the weight update iterations in the SMC method we described
 operate on an increasing probability space: 
\begin_inset Formula $x_{1},(x_{2}|x_{1}),(x_{3}|x_{1},x_{2}),...$
\end_inset

.
\begin_inset Note Note
status open

\begin_layout Plain Layout
Unclear notation
\end_layout

\end_inset

 The SMC sampler developed in 
\begin_inset CommandInset citation
LatexCommand cite
key "citeulike:637817"

\end_inset

 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Write why this is important
\end_layout

\end_inset

instead operates on the same probability space through all the weight updates.
 Note that this means we cannot use the decomposition shown in 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:weight_decomposition"

\end_inset

 right out of the box.
\end_layout

\begin_layout Standard
Nevertheless, we still want to decompose the problem of drawing samples
 from 
\begin_inset Formula $p(\boldsymbol{x})$
\end_inset

 somehow.
 To do this we again start by defining a sequence of better and better approxima
te distributions to 
\begin_inset Formula $p(\boldsymbol{x})$
\end_inset

: 
\begin_inset Formula $\{p_{i}(\boldsymbol{x})\}_{i\in1,...,n}$
\end_inset

, and the the corresponding proposal distributions are denoted similarly
 
\begin_inset Formula $\{g_{i}(\boldsymbol{x})\}_{i\in1,...,n}$
\end_inset

.
 The idea developed in 
\begin_inset CommandInset citation
LatexCommand cite
key "citeulike:637817"

\end_inset

 uses a Markov kernel to establish the proposal distribution at step 
\begin_inset Formula $i$
\end_inset

:
\begin_inset Formula 
\[
g_{i}(\boldsymbol{x}|\boldsymbol{x}')=K(\boldsymbol{x}',\boldsymbol{x})
\]

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $\boldsymbol{x}'$
\end_inset

 is distributed according to 
\begin_inset Formula $g_{i-1}(\boldsymbol{x}')$
\end_inset

.
 The marginal distribution 
\begin_inset Formula $g_{i}(\boldsymbol{x})$
\end_inset

 is given as:
\begin_inset Formula 
\begin{equation}
g_{i}(\boldsymbol{x})=\int K(\boldsymbol{x}',\boldsymbol{x})g_{i-1}(\boldsymbol{x}\text{'})d\boldsymbol{x}'\label{eq:kernel_update}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Note that we need this marginal distribution, since the decomposition in
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:weight_decomposition"

\end_inset

 is unavailable to us.
 The rationale behind the use of a kernel, is that as the target distribution
 evolves from one step to the next, it should be possible for us to use
 the particles at step 
\begin_inset Formula $i-1$
\end_inset

 to make a good approximation to the target at step 
\begin_inset Formula $i$
\end_inset

.
 However the integral in 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:kernel_update"

\end_inset

 turns out to be impossible to compute in most cases.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Add example
\end_layout

\end_inset


\end_layout

\begin_layout Standard
One approach to get around this is to approximate 
\begin_inset Formula $g_{i}(\boldsymbol{x})$
\end_inset

 pointwise:
\begin_inset Formula 
\begin{equation}
g_{i}(\boldsymbol{x})\approx g_{i}^{n}(\boldsymbol{x})=\frac{1}{n}\sum_{j=1}^{n}K(\boldsymbol{X}_{i-1}^{(j)},\boldsymbol{x})\label{eq:update_approximation}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Assuming we use the 
\begin_inset Formula $n$
\end_inset

 particles we are evolving in when doing the weight update above, we need
 to perform 
\begin_inset Formula $n$
\end_inset

 pointwise evaluations of 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:update_approximation"

\end_inset

 for each of the 
\begin_inset Formula $n$
\end_inset

 particles, resulting in a complexity on the order of 
\begin_inset Formula $O(n^{2})$
\end_inset

 for one weight update step.
 This is computationally prohibitive when 
\begin_inset Formula $n$
\end_inset

 is large.
\end_layout

\begin_layout Subsubsection
Use of backward kernel in weight update
\end_layout

\begin_layout Standard
To avoid having to compute 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:update_approximation"

\end_inset

, 
\begin_inset CommandInset citation
LatexCommand cite
key "citeulike:637817"

\end_inset

 proposes to use what they call backward kernels.
 This idea also lets us frame the weight updates in the form we described
 in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Sequential-Importance-Sampling"

\end_inset

.
 The resulting algorithm has complexity 
\begin_inset Formula $O(n)$
\end_inset

 and provides asymptotically consistent estimates.
\begin_inset Note Note
status open

\begin_layout Plain Layout
Write more
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The backward kernel is introduced as a part of an approximation to the approxima
tion 
\begin_inset Formula $p_{i}(\boldsymbol{x}_{i})$
\end_inset

 as was described in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Sequential-Importance-Sampling"

\end_inset

, and is defined as follows:
\begin_inset Formula 
\[
\hat{p}_{i}(x_{i}|\boldsymbol{x}_{i-1})=p_{i}(\boldsymbol{x}_{i})\Pi_{t=1}^{i-1}L_{i}(x_{t+1},x_{t})
\]

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $L(x_{i+1},x_{i})$
\end_inset

 is a kernel that gives the probability going from 
\begin_inset Formula $x_{i+1}$
\end_inset

 to 
\begin_inset Formula $x_{i}$
\end_inset

.
 We will return to what this kernel can look like later.
 For the proposal distribution we set up a similar sequence of kernels,
 but here with increasing indices: From 
\begin_inset Formula $x_{i-1}$
\end_inset

 to 
\begin_inset Formula $x_{i}$
\end_inset

:
\begin_inset Formula 
\begin{align*}
g_{i}(x_{i}|\boldsymbol{x}_{i-1}) & =\hat{p}_{i-1}(\boldsymbol{x}_{i-1})K_{i}(\boldsymbol{x}_{i-1},x_{i})\\
 & =\hat{p}_{i-2}(\boldsymbol{x}_{i-2})K_{i-2}(\boldsymbol{x}_{i-2},\boldsymbol{x}_{i-1})K_{i-1}(\boldsymbol{x}_{i-1},x_{i})\\
 & =\hat{p}_{1}(\boldsymbol{x}_{1})\prod_{t=1}^{i-1}K(\boldsymbol{x}_{t},\boldsymbol{x}_{t+1})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Note that these approximations and proposals are not defined in terms of
 marginal distributions, 
\begin_inset Formula $g_{i}(\boldsymbol{x}_{i})$
\end_inset

, but conditional ones, 
\begin_inset Formula $g_{i}(x_{i}|\boldsymbol{x}_{i-1})$
\end_inset

.
\end_layout

\begin_layout Standard
Looking at the weight update we get:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
u_{i}(x_{i}) & =\frac{\hat{p}_{i}(x_{i}|\boldsymbol{x}_{i-1})}{g_{i}(x_{i}|\boldsymbol{x}_{i-1})}\nonumber \\
 & =\frac{p_{i}(\boldsymbol{x}_{i})\Pi_{i=1}^{t-1}L_{i}(\boldsymbol{x}_{t+1},\boldsymbol{x}_{t})}{\hat{p}_{i-1}(\boldsymbol{x}_{i-1})K(\boldsymbol{x}_{i-1},\boldsymbol{x}_{i})}\nonumber \\
 & =\frac{p_{i}(\boldsymbol{x}_{i})\Pi_{t=2}^{i}L_{t}(\boldsymbol{x}_{t},\boldsymbol{x}_{t-1})}{p_{i-1}(\boldsymbol{x}_{t})\Pi_{i=1}^{t-1}K(\boldsymbol{x}_{i-1},\boldsymbol{x}_{i})}\nonumber \\
 & =\frac{p_{i}(\boldsymbol{x}_{i})L_{i}(\boldsymbol{x}_{i},\boldsymbol{x}_{i-1})}{p_{i-1}(\boldsymbol{x}_{i-1})K(\boldsymbol{x}_{i-1},\boldsymbol{x}_{i})}\label{eq:weight_update}
\end{align}

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Check indices
\end_layout

\end_inset


\end_layout

\begin_layout Standard
To anchor the recursion at the start we assume that we are able to sample
 perfectly from the first approximation 
\begin_inset Formula $p_{1}(\boldsymbol{x}_{1})$
\end_inset

, so that we can set 
\begin_inset Formula $\hat{p}_{1}(\boldsymbol{x}_{1})=p_{1}(\boldsymbol{x}_{1})$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
w_{2}(x_{2}) & =w_{1}(x_{1})u_{2}(x_{1})\\
 & =\frac{p_{1}(x_{1})}{p_{1}(x_{1})}\frac{p_{2}(x_{2})L(x_{2},x_{1})}{p_{1}(x_{1})K(x_{1},x_{2})}\\
 & =\frac{p_{2}(x_{2})L(x_{2},x_{1})}{p_{1}(x_{1})K(x_{1},x_{2})}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In general the weight at 
\begin_inset Formula $i$
\end_inset

 is:
\begin_inset Formula 
\[
w_{i}(x_{i})=\frac{p_{i}(x_{i})\Pi_{t=2}^{i}L_{t}(x_{t},x_{t-1})}{p_{1}(x_{1})\Pi_{t=1}^{i-1}K(\boldsymbol{x}_{t},\boldsymbol{x}_{t+1})}
\]

\end_inset


\end_layout

\begin_layout Standard
At every step we have a weighted sample from the approximation to the target
 distribution 
\begin_inset Formula $\hat{p}_{i}(x_{i}|\boldsymbol{x}_{i-1})=p_{i}(x_{i})\Pi_{t=2}^{i}L_{t}(x_{t},x_{t-1})$
\end_inset

.
 However, our goal is to have a weighted sample from 
\begin_inset Formula $p_{i}(x_{i})$
\end_inset

, but viewing the expression for the weight on the equivalent form:
\begin_inset Formula 
\[
w_{i}(x_{i})=\frac{p_{i}(x_{i})}{\frac{p_{1}(x_{1})\Pi_{t=1}^{i-1}K(x_{t},\boldsymbol{x}_{t+1})}{\Pi_{t=2}^{i}L_{t}(x_{t},\boldsymbol{x}_{t-1})}}
\]

\end_inset


\end_layout

\begin_layout Standard
We recognize 
\begin_inset Formula $p_{i}(x_{i})$
\end_inset

 as the desired target distribution, and 
\begin_inset Formula $\frac{p_{1}(x_{1})\Pi_{t=1}^{i-1}K(\boldsymbol{x}_{t},\boldsymbol{x}_{t+1})}{\Pi_{t=2}^{i}L_{t}(x_{t},x_{t-1})}$
\end_inset

 as a proposal distribution.
 We now see why the approximation, 
\begin_inset Formula $\hat{p}_{i}(\boldsymbol{x}_{i})$
\end_inset

, to the target distribution had the form it did, and a requirement for
 an approximation distribution to function in this setup is that it has
 the target distribution as a marginal:
\begin_inset Formula 
\[
\int\hat{p}_{i}(x_{i}|\boldsymbol{x}_{i-1})d\boldsymbol{x}_{i-1}=p_{i}(x_{i})
\]

\end_inset


\end_layout

\begin_layout Standard
This requirement is necessary to be able to recover the target distibution,
 and is fulfilled by in our case by the construction of the approximation,
 as can be seen if we look at the integral for an arbitrary backward kernel:
\begin_inset Formula 
\[
\int_{\boldsymbol{X}}L(\boldsymbol{x}_{i},\boldsymbol{x}_{i-1})d\boldsymbol{x}_{i-1}=1
\]

\end_inset


\end_layout

\begin_layout Standard
With these kernels the problem of generating a weight sample can be written
 in the recursive form we described in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Sequential-Importance-Sampling"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Choice of backward kernel
\end_layout

\begin_layout Standard
The backward kernels are essentially arbitrary, but the choice of them will
 affect the efficiency of the computation.
 A desirable property, as mentioned, is that the weights have low variance,
 so we can try to choose a backward kernel that achieves this.
 Del Moral et.
 al.
 
\begin_inset CommandInset citation
LatexCommand cite
key "citeulike:637817"

\end_inset

 do just this and show the following result: The sequence of backward kernels
 that minimize the variance of the unnormalized importance weights is given
 by:
\begin_inset Formula 
\begin{equation}
L_{i}(\boldsymbol{x}_{i},\boldsymbol{x}_{i-1})=\frac{g_{i-1}(\boldsymbol{x}_{i-1})K(\boldsymbol{x}_{i-1},\boldsymbol{x}_{i})}{g_{i}(\boldsymbol{x}_{i})}\label{eq:optimal_backward_kernel}
\end{equation}

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Check indices
\end_layout

\end_inset


\end_layout

\begin_layout Standard
To prove it consider the conditional variance formula applied to 
\begin_inset Formula $w_{i}(\boldsymbol{X}_{1:i})$
\end_inset

:
\begin_inset Formula 
\[
\mathrm{Var}(w_{i}(\boldsymbol{X}_{1:i}))=\mathrm{E}(\mathrm{Var}(w_{i}(\boldsymbol{X}_{1:i})|\boldsymbol{X}_{i}))+\mathrm{Var}(\mathrm{E}(w_{i}(\boldsymbol{X}_{1:i})|\boldsymbol{X}_{i}))
\]

\end_inset


\end_layout

\begin_layout Standard
We can use this formula since 
\begin_inset Formula $w_{i}(\boldsymbol{X}_{1:i})$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{X}_{i}$
\end_inset

, are defined on the same probability space: Even though 
\begin_inset Formula $\boldsymbol{X}_{1:i}$
\end_inset

 is a sequence of random vectors, the weight at step 
\begin_inset Formula $i$
\end_inset

 is a single random vector.
\end_layout

\begin_layout Standard
A property of conditional expectations is: 
\begin_inset Formula $\mathrm{E}(g(\boldsymbol{Y})\boldsymbol{X}|\boldsymbol{Y})=g(\boldsymbol{Y})\mathrm{E}(\boldsymbol{X}|\boldsymbol{Y})$
\end_inset

, where 
\begin_inset Formula $\boldsymbol{X}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

 are random vectors, and 
\begin_inset Formula $g(y)$
\end_inset

 is a function from 
\begin_inset Formula $\mathbb{R}\to\mathbb{R}$
\end_inset

.
 This property also yields the following: 
\begin_inset Formula $\mathrm{E}(g(\boldsymbol{X})|\boldsymbol{X})=g(\boldsymbol{X})$
\end_inset

.
 Applying this, we have for the expectation in the second term:
\begin_inset Formula 
\[
\mathrm{E}(w_{i}(\boldsymbol{X}_{1:i})|\boldsymbol{X}_{i})=w_{i}(\boldsymbol{X}_{i})=\frac{\hat{p}_{i}(\boldsymbol{X}_{i})}{g_{i}(\boldsymbol{X}_{i})}
\]

\end_inset


\end_layout

\begin_layout Standard
Note that this expression does not depend on 
\begin_inset Formula $L_{i}(\boldsymbol{x}_{i},\boldsymbol{x}_{i-1})$
\end_inset

, so the choice of backward kernel does not influence this term.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Check that these distributions have been defined as used here
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Check that the correct distributions are used here
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Now we turn our attention t 
\begin_inset Formula $\mathrm{Var}(w_{i}(\boldsymbol{X}_{1:i})|\boldsymbol{X}_{i})$
\end_inset

.
 If we insert 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:optimal_backward_kernel"

\end_inset

 into the expression for the weight update in equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:weight_update"

\end_inset

 we get:
\begin_inset Formula 
\[
\frac{p_{i}(\boldsymbol{x}_{i})L_{i}(\boldsymbol{x}_{i},\boldsymbol{x}_{i-1})}{p_{i-1}(\boldsymbol{x}_{i-1})K(\boldsymbol{x}_{i-1},\boldsymbol{x}_{i})}=\frac{p_{i}(\boldsymbol{x}_{i})}{p_{i-1}(\boldsymbol{x}_{i-1})K(\boldsymbol{x}_{i-1},\boldsymbol{x}_{i})}\frac{p_{i-1}(\boldsymbol{x}_{i-1})K(\boldsymbol{x}_{i-1},\boldsymbol{x}_{i})}{p_{i}(\boldsymbol{x}_{i})}=1
\]

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Should these be random variables?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Which is a constant, and so has 0 variance.
 Since this holds for all the weight updates, it also does for 
\begin_inset Formula $w_{i}(\boldsymbol{X}_{1:i})$
\end_inset

, and we have 
\begin_inset Formula $\mathrm{E}(\mathrm{Var}(w_{i}(\boldsymbol{X}_{1:i})|\boldsymbol{X}_{i}))=0$
\end_inset

.
\end_layout

\begin_layout Standard
To compute the optimal kernel we need to compute the distributions 
\begin_inset Formula $p_{i-1}(\boldsymbol{x}_{i-1})$
\end_inset

 and 
\begin_inset Formula $p_{i}(\boldsymbol{x}_{i})$
\end_inset

 which we often cannot do in practice.
 We are thus left to chose a suboptimal kernel, and we will return the question
 of how to chose one later when we describe the actual implementation of
 the SMC sampler.
\end_layout

\begin_layout Subsection
SMC sampler in ABC
\end_layout

\begin_layout Standard
We now follow the work done in 
\begin_inset CommandInset citation
LatexCommand cite
key "adaptive_smc_for_abc"

\end_inset

 and describe how the SMC sampler can be used in an ABC setting.
 Remembering the expression in equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:abc_sampling_distribution"

\end_inset

 for the distribution we are sampling from in ABC, a possible sequence of
 approximations to the true posterior is given by decreasing the distance
 between the observations and drawn samples, that is: Let 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

 be sample and 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 an observation, and define a sequence of decreasing values 
\begin_inset Formula $\epsilon_{1}>\epsilon_{2}>...>\epsilon_{n}$
\end_inset

.
 Let 
\begin_inset Formula $p_{\epsilon_{i}}(\boldsymbol{\theta},\boldsymbol{x}|\boldsymbol{y})$
\end_inset

 denote the distribution such that drawn samples from it lie within 
\begin_inset Formula $\epsilon_{i}$
\end_inset

 from 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, that is: 
\begin_inset Formula $d(\boldsymbol{x},\boldsymbol{y})<\epsilon_{i}$
\end_inset

.
 As 
\begin_inset Formula $\epsilon\to0$
\end_inset

 we expect 
\begin_inset Formula $\boldsymbol{x}\to\boldsymbol{y}$
\end_inset

, and hopefully as a consequence 
\begin_inset Formula $p_{\epsilon}(\boldsymbol{\theta},\boldsymbol{x}|\boldsymbol{y})$
\end_inset

 will converge to a distribution that is proportionalto 
\begin_inset Formula $p(\boldsymbol{\theta}|\boldsymbol{y})$
\end_inset

.
 If we let the likelihood function in 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:abc_sampling_distribution"

\end_inset

 be an indiator function that is 1 if 
\begin_inset Formula $d(\boldsymbol{x},\boldsymbol{y})<\epsilon$
\end_inset

, and 0 else, written 
\begin_inset Formula $I_{\epsilon,\boldsymbol{y}}(\boldsymbol{x})$
\end_inset

, these assumptions hold, that is: 
\begin_inset Formula 
\begin{align*}
\lim_{\epsilon\to0}p_{\epsilon}(\boldsymbol{\theta},\boldsymbol{x}|\boldsymbol{y}) & \propto\lim_{\epsilon\to0}I_{\epsilon,\boldsymbol{y}}(\boldsymbol{x})p(\boldsymbol{x}|\boldsymbol{\theta})p(\boldsymbol{\theta})\\
 & =p(\boldsymbol{y}|\boldsymbol{\theta})p(\boldsymbol{\theta})\\
 & \propto p(\boldsymbol{\theta}|\boldsymbol{y})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Using this sequence, 
\begin_inset Formula $p_{\epsilon_{i}}(\boldsymbol{\theta},\boldsymbol{x}|\boldsymbol{y})$
\end_inset

, as approximations to the target distribution, we are left with the tasks
 of specifying forward and backward kernels, and a schedule for updating
 the cutoff distances 
\begin_inset Formula $\epsilon_{i}$
\end_inset

.
\end_layout

\begin_layout Subsubsection
Use of multiple particles for each sample of 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset


\end_layout

\begin_layout Standard
Del Moral et.
 al.
 
\begin_inset CommandInset citation
LatexCommand cite
key "adaptive_smc_for_abc"

\end_inset

 use an MCMC kernel for 
\begin_inset Formula $K(x_{t},\boldsymbol{x}_{t+1})$
\end_inset

 in the weight update step, but before describing it we need to introduce
 one change to the above.
 Instead of having only one sample 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

, and parameter value 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

, drawn from 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $p_{\epsilon}(\boldsymbol{\theta},\boldsymbol{x}|\boldsymbol{y})$
\end_inset

, a number of independent samples are drawn.
 Let 
\begin_inset Formula $\{\boldsymbol{x}\}_{1:m}$
\end_inset

 denote 
\begin_inset Formula $m$
\end_inset

 samples that are independent given 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

.
 This modified proposal distribution is written as:
\begin_inset Formula 
\[
p_{\epsilon}(\boldsymbol{\theta},\{\boldsymbol{x}\}_{1:m}|\boldsymbol{y})
\]

\end_inset


\end_layout

\begin_layout Standard
The reason for introducing this as a proposal distribution is to reduce
 the variance of the Metropolis-Hastings ratio we will encounter in the
 next section, which in turn increases its performance
\begin_inset Note Note
status open

\begin_layout Plain Layout
How is the performance increased?
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
The question is now whether this new proposal distribution is valid.
 We claim that the marginals for 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 in 
\begin_inset Formula $p_{\epsilon}(\boldsymbol{\theta},\{\boldsymbol{x}\}_{1:m}|\boldsymbol{y})$
\end_inset

 are equal up to a constant for any integer 
\begin_inset Formula $m>0$
\end_inset

.
\begin_inset Note Note
status open

\begin_layout Plain Layout
Prove the claim
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
p_{\epsilon}(\boldsymbol{\theta},\{\boldsymbol{x}\}_{1:m}|\boldsymbol{y}) & \propto p(\boldsymbol{y}|\boldsymbol{\theta},\{\boldsymbol{x}\}_{1:m})p(\{\boldsymbol{x}\}_{1:m}|\boldsymbol{\theta})p(\boldsymbol{\theta})
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection
Proposal density with equal marginal likelihood for 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset


\end_layout

\begin_layout Standard
To motivate the proposal distribution in the next section we need to establish
 a result: That 
\begin_inset Formula $p_{\epsilon}(\boldsymbol{\theta},\{\boldsymbol{x}\}_{1:m}|\boldsymbol{y})$
\end_inset

 and 
\begin_inset Formula $(\frac{1}{m}\sum_{i=1}^{m}I_{\epsilon,\boldsymbol{y}}(\boldsymbol{x}_{i}))(\prod_{i=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}))p(\boldsymbol{\theta})$
\end_inset

 have the same marginals for 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

.
 Remember that it is this marginal distribution that we are interested in,
 since it is an approximation to the posterior.
\end_layout

\begin_layout Standard
We calculate the marginal for 
\begin_inset Formula $(\frac{1}{m}\sum_{i=1}^{m}I_{\epsilon,\boldsymbol{y}}(\boldsymbol{x}_{i}))(\prod_{i=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}))p(\boldsymbol{\theta})$
\end_inset

, by in
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
tegrating out all the 
\begin_inset Formula $\boldsymbol{x}_{i}$
\end_inset

's:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\int...\int & \sum_{i=1}^{m}I_{\epsilon,y}(\boldsymbol{x}_{i})\prod_{i=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta})p(\boldsymbol{\theta})d\boldsymbol{x}_{1}...d\boldsymbol{x}_{m}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Let us extract 
\begin_inset Formula $i=1$
\end_inset

 from the sum above and look at the expression:
\begin_inset Formula 
\begin{align*}
\int...\int & I_{\epsilon,y}(\boldsymbol{x}_{i})\prod_{i=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta})p(\boldsymbol{\theta})d\boldsymbol{x}_{1}...d\boldsymbol{x}_{m}=\\
 & p(\boldsymbol{\theta})\int...\int I_{\epsilon,y}(\boldsymbol{x}_{1})\prod_{i=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta})d\boldsymbol{x}_{1}...d\boldsymbol{x}_{m}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
For the part of the integral where 
\begin_inset Formula $i=1$
\end_inset

 we get:
\begin_inset Formula 
\begin{align*}
p(\boldsymbol{\theta})\int I_{\epsilon,y}(\boldsymbol{x}_{1})\prod_{i=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta})d\boldsymbol{x}_{1} & =\\
p(\boldsymbol{\theta})\int I_{\epsilon,y}(\boldsymbol{x}_{1})p(\boldsymbol{x}_{1}|\boldsymbol{\theta})d\boldsymbol{x}_{1}\prod_{i=2}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}) & =\\
\text{by the definition of our likelihood} & \text{}\\
p_{\epsilon}(\boldsymbol{y}|\boldsymbol{\theta})\prod_{i=2}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $j\neq1$
\end_inset

 we get:
\begin_inset Formula 
\begin{align*}
p(\boldsymbol{\theta})\int p(\boldsymbol{x}_{2}|\boldsymbol{\theta})d\boldsymbol{x}_{2} & =\\
\mathrm{c}p(\boldsymbol{\theta})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Putting it all together we have:
\begin_inset Formula 
\begin{align*}
\int...\int & \sum_{i=1}^{m}I_{\epsilon,y}(\boldsymbol{x}_{i})\prod_{i=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta})p(\boldsymbol{\theta})d\boldsymbol{x}_{1}...d\boldsymbol{x}_{m}=\\
 & \mathrm{c}_{2}mp_{\epsilon}(\boldsymbol{y}|\boldsymbol{\theta})p(\boldsymbol{\theta})\propto\\
 & p_{\epsilon}(\boldsymbol{\theta}|\boldsymbol{y})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
So viewing it from the perspective of the marginal of 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 we can write:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
p_{\epsilon}(\boldsymbol{\theta},\{\boldsymbol{x}\}_{1:m}|\boldsymbol{y})\propto(\frac{1}{m}\sum_{i=1}^{m}I_{\epsilon,\boldsymbol{y}}(\boldsymbol{x}_{i}))(\prod_{i=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}))p(\boldsymbol{\theta})\label{eq:proportional_distributions}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
Choice of kernel
\end_layout

\begin_layout Standard
The kernel uses a Metropolis-Hastings (MH) step to achieve the desired invariant
 density.
 To show the form of the kernel we start by defining a proposal distribution:
\begin_inset Formula 
\[
q_{i}(\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{i+1})\prod_{j=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}_{i+1})
\]

\end_inset


\end_layout

\begin_layout Standard
The MH-ratio term is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\alpha(i,i+1)=\min\left(1,\frac{p_{\epsilon}(\boldsymbol{\theta}_{i+1},\{\boldsymbol{x}_{i+1}\}_{1:m}|\boldsymbol{y})q_{i+1}(\boldsymbol{\theta}_{i+1},\boldsymbol{\theta}_{i})\prod_{j=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}_{i})}{p_{\epsilon}(\boldsymbol{\theta}_{i},\{\boldsymbol{x}_{i}\}_{1:m}|\boldsymbol{y})q_{i}(\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{i+1})\prod_{j=1}^{m}p(\boldsymbol{x}_{i+1}|\boldsymbol{\theta}_{i+1})}\right)\label{eq:mh-ratio}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
We now propose that the Markov chain with update probability: 
\begin_inset Formula 
\[
P(i,i+1)=q_{i}(\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{i+1})\prod_{j=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}_{i+1})\alpha(i,i+1)
\]

\end_inset

 Has invariant density 
\begin_inset Formula $p_{\epsilon_{i}}(\boldsymbol{\theta},\boldsymbol{x}_{1:m}|\boldsymbol{y})$
\end_inset

.
 For this to be the case we must first show that the balance equation is
 fulfilled (see for example chapter 4.9 if Ross 
\begin_inset CommandInset citation
LatexCommand cite
key "ross2006introduction"

\end_inset

 for a more in detail discussion of the requirements):
\begin_inset Formula 
\[
p_{\epsilon}(\boldsymbol{\theta}_{i},\{\boldsymbol{x}_{i}\}_{1:m}|\boldsymbol{y})P(i,i+1)=p_{\epsilon}(\boldsymbol{\theta}_{i+1},\{\boldsymbol{x}_{i+1}\}_{1:m}|\boldsymbol{y})P(i+1,i)
\]

\end_inset


\end_layout

\begin_layout Standard
Expanding 
\begin_inset Formula $P(i,i+1)$
\end_inset

 we get:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
p_{\epsilon}(\boldsymbol{\theta}_{i},\{\boldsymbol{x}_{i}\}_{1:m}|\boldsymbol{y})q_{i}(\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{i+1})\prod_{j=1}^{m}p(\boldsymbol{x}_{i+1}|\boldsymbol{\theta}_{i+1}) & \alpha(i,i+1)=\\
p_{\epsilon}(\boldsymbol{\theta}_{i+1},\{\boldsymbol{x}_{i+1}\}_{1:m}|\boldsymbol{y})q_{i+1}(\boldsymbol{\theta}_{i+1},\boldsymbol{\theta}_{i})\prod_{j=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}_{i})\alpha(i+1,i)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
If 
\begin_inset Formula $\alpha(i,i+1)=1$
\end_inset

, then 
\begin_inset Formula $\alpha(i+1,i)=\frac{p_{\epsilon}(\boldsymbol{\theta}_{i},\{\boldsymbol{x}_{i}\}_{1:m}|\boldsymbol{y})q_{i}(\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{i+1})\prod_{j=1}^{m}p(\boldsymbol{x}_{i+1}|\boldsymbol{\theta}_{i+1})}{p_{\epsilon}(\boldsymbol{\theta}_{i+1},\{\boldsymbol{x}_{i+1}\}_{1:m}|\boldsymbol{y})q_{i+1}(\boldsymbol{\theta}_{i+1},\boldsymbol{\theta}_{i})\prod_{j=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}_{i})}<1$
\end_inset

, 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Also check when it is equal to 1
\end_layout

\end_inset

 and we have:
\begin_inset Formula 
\begin{align*}
p_{\epsilon}(\boldsymbol{\theta}_{i},\{\boldsymbol{x}_{i}\}_{1:m}|\boldsymbol{y})q_{i}(\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{i+1})\prod_{j=1}^{m}p(\boldsymbol{x}_{i+1}|\boldsymbol{\theta}_{i+1}) & =\\
p_{\epsilon}(\boldsymbol{\theta}_{i+1},\{\boldsymbol{x}_{i+1}\}_{1:m}|\boldsymbol{y})q_{i+1}(\boldsymbol{\theta}_{i+1},\boldsymbol{\theta}_{i})\prod_{j=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}_{i})\frac{p_{\epsilon}(\boldsymbol{\theta}_{i},\{\boldsymbol{x}_{i}\}_{1:m}|\boldsymbol{y})q_{i}(\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{i+1})\prod_{j=1}^{m}p(\boldsymbol{x}_{i+1}|\boldsymbol{\theta}_{i+1})}{p_{\epsilon}(\boldsymbol{\theta}_{i+1},\{\boldsymbol{x}_{i+1}\}_{1:m}|\boldsymbol{y})q_{i+1}(\boldsymbol{\theta}_{i+1},\boldsymbol{\theta}_{i})\prod_{j=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}_{i})} & =\\
p_{\epsilon}(\boldsymbol{\theta}_{i+1},\{\boldsymbol{x}_{i+1}\}_{1:m}|\boldsymbol{y})p_{\epsilon}(\boldsymbol{\theta}_{i},\{\boldsymbol{x}_{i}\}_{1:m}|\boldsymbol{y})q_{i}(\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{i+1})\prod_{j=1}^{m}p(\boldsymbol{x}_{i+1}|\boldsymbol{\theta}_{i+1})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Similarly when 
\begin_inset Formula $\alpha(i+1,i)=1$
\end_inset

.
\begin_inset Note Note
status open

\begin_layout Plain Layout
Write more about conditions
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Metropolis-Hastings ratio without likelihood
\end_layout

\begin_layout Standard
The likelihood function, 
\begin_inset Formula $p(\boldsymbol{\boldsymbol{x}}|\boldsymbol{\theta})$
\end_inset

, appears in the Metropolis-Hastings ratio above, but we cannot evaluate
 it.
 It is here we can use the result in equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:proportional_distributions"

\end_inset

, by replacing the MH-ratio with an equivalent one:
\begin_inset Formula 
\begin{multline*}
\min\left(\frac{p_{\epsilon}(\boldsymbol{\theta}_{i+1},\{\boldsymbol{x}_{i+1}\}_{1:m}|\boldsymbol{y})q_{i+1}(\boldsymbol{\theta}_{i+1},\boldsymbol{\theta}_{i})\prod_{j=1}^{m}p(\boldsymbol{x}_{i}^{(j)}|\boldsymbol{\theta}_{i})}{p_{\epsilon}(\boldsymbol{\theta}_{i},\{\boldsymbol{x}_{i}\}_{1:m}|\boldsymbol{y})q_{i}(\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{i+1})\prod_{j=1}^{m}p(\boldsymbol{x}_{i+1}^{(j)}|\boldsymbol{\theta}_{i+1})}\right)=\\
\text{insert expression from \ref{eq:proportional_distributions}}\\
\min\left(\frac{(\frac{1}{m}\sum_{j=1}^{m}I_{\epsilon,\boldsymbol{y}}(\boldsymbol{x}_{i+1}))(\prod_{j=1}^{m}p(\boldsymbol{x}_{i+1}^{(j)}|\boldsymbol{\theta}_{i+1}))p(\boldsymbol{\theta}_{i+1})q_{i+1}(\boldsymbol{\theta}_{i+1},\boldsymbol{\theta}_{i})\prod_{j=1}^{m}p(\boldsymbol{x}_{i}^{(j)}|\boldsymbol{\theta}_{i})}{(\frac{1}{m}\sum_{j=1}^{m}I_{\epsilon,\boldsymbol{y}}(\boldsymbol{x}_{i}^{(j)}))(\prod_{j=1}^{m}p(\boldsymbol{x}_{i}^{(j)}|\boldsymbol{\theta}))p(\boldsymbol{\theta})q_{i}(\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{i+1})\prod_{j=1}^{m}p(\boldsymbol{x}_{i+1}^{(j)}|\boldsymbol{\theta}_{i+1})}\right)=\\
\min\left(1,\frac{\sum_{j=1}^{m}\mathrm{I}_{\epsilon_{i},y}(\boldsymbol{x}_{i+1}^{(j)})q_{i}(\boldsymbol{\theta}_{i+1},\boldsymbol{\theta})p(\boldsymbol{\theta}_{i+1})}{\sum_{j=1}^{m}\mathrm{I}_{\epsilon_{i},y}(\boldsymbol{x}_{i}^{(j)})q_{i}(\boldsymbol{\theta},\boldsymbol{\theta}_{i+1})p(\boldsymbol{\theta})}\right)
\end{multline*}

\end_inset


\end_layout

\begin_layout Standard
Intuitively we can see ratio is doing: If more of the samples generated
 at step 
\begin_inset Formula $i+1$
\end_inset

 lie within 
\begin_inset Formula $\epsilon_{i}$
\end_inset

 of 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 than the ones generated at step 
\begin_inset Formula $i$
\end_inset

, the update will be accepted.
 If fewer particles lie within this radius, there is less of a chance of
 the update being accepted.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Expression for variance of theta
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Algorithm
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Transition to how this is implemented in the code example
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
SMC in ABC
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithmic}
\end_layout

\begin_layout Plain Layout


\backslash
Require $
\backslash
epsilon_{stop},
\backslash
alpha,
\backslash
beta,N$
\end_layout

\begin_layout Plain Layout


\backslash
State $
\backslash
epsilon 
\backslash
leftarrow 
\backslash
infty$
\end_layout

\begin_layout Plain Layout


\backslash
State $ess 
\backslash
leftarrow N$
\end_layout

\begin_layout Plain Layout


\backslash
State $
\backslash
boldsymbol{
\backslash
theta}_{n} 
\backslash
leftarrow$ $N$ samples from $p(
\backslash
boldsymbol{
\backslash
theta})$
\end_layout

\begin_layout Plain Layout


\backslash
State $particles 
\backslash
leftarrow $ $N$ samples from $p(
\backslash
boldsymbol{x}|
\backslash
boldsymbol{
\backslash
theta})$
\end_layout

\begin_layout Plain Layout


\backslash
State $
\backslash
boldsymbol{W}_{n}
\backslash
leftarrow [
\backslash
frac{1}{N},...,
\backslash
frac{1}{N}]$
\end_layout

\begin_layout Plain Layout


\backslash
While{$
\backslash
epsilon 
\backslash
geq 
\backslash
epsilon_{stop}$}
\end_layout

\begin_layout Plain Layout


\backslash
State $
\backslash
epsilon 
\backslash
leftarrow FindNextEpsilon(
\backslash
epsilon,
\backslash
boldsymbol{W}_{n})$
\end_layout

\begin_layout Plain Layout


\backslash
If{$ess < 
\backslash
beta N$}
\end_layout

\begin_layout Plain Layout


\backslash
State $(
\backslash
boldsymbol{
\backslash
theta}, particles) 
\backslash
leftarrow 
\backslash
mathrm{Resample}$
\backslash
Comment{Resampling}
\end_layout

\begin_layout Plain Layout


\backslash
EndIf
\end_layout

\begin_layout Plain Layout


\backslash
For{$i
\backslash
leftarrow[1,..,N]$}
\end_layout

\begin_layout Plain Layout


\backslash
State $(
\backslash
boldsymbol{
\backslash
theta}_{n}^{(i)}, particles^{(i)})
\backslash
leftarrow 
\backslash
mathrm{Mutate}(
\backslash
epsilon, particles^{(i)}, W_{n-1}^{(i)}, 
\backslash
boldsymbol{
\backslash
theta}^{(i)})$
\end_layout

\begin_layout Plain Layout


\backslash
EndFor
\end_layout

\begin_layout Plain Layout


\backslash
EndWhile
\end_layout

\begin_layout Plain Layout


\backslash
newline
\end_layout

\begin_layout Plain Layout


\backslash
Function{ESS}{$
\backslash
boldsymbol{W_{n}}$}
\end_layout

\begin_layout Plain Layout


\backslash
State 
\backslash
textbf{return} $(
\backslash
sum_{i=1}^{N}W_{n}^{(i)})^{-1}$
\end_layout

\begin_layout Plain Layout


\backslash
EndFunction
\end_layout

\begin_layout Plain Layout


\backslash
newline
\end_layout

\begin_layout Plain Layout


\backslash
Function{FindNextEpsilon}{$
\backslash
epsilon_{n-1},
\backslash
boldsymbol{w_{n-1}}$} 
\end_layout

\begin_layout Plain Layout


\backslash
State Solve $ESS(
\backslash
frac{I_{
\backslash
epsilon_{n}}(
\backslash
boldsymbol{x}_{k})}{I_{
\backslash
epsilon_{n-1}}(
\backslash
boldsymbol{x}_{k})})=
\backslash
alpha ESS(
\backslash
boldsymbol{w_{n-1}})$ for $
\backslash
epsilon_{n}$
\end_layout

\begin_layout Plain Layout


\backslash
State 
\backslash
textbf{return} $
\backslash
epsilon_{n}$
\end_layout

\begin_layout Plain Layout


\backslash
EndFunction
\end_layout

\begin_layout Plain Layout


\backslash
newline
\end_layout

\begin_layout Plain Layout


\backslash
Function{Mutate}{$
\backslash
epsilon,particle,
\backslash
boldsymbol{w},
\backslash
boldsymbol{
\backslash
theta}_{old}$}
\end_layout

\begin_layout Plain Layout


\backslash
State $
\backslash
boldsymbol{
\backslash
theta}_{new} 
\backslash
leftarrow$ Sample from $q(
\backslash
boldsymbol{
\backslash
theta}|
\backslash
boldsymbol{
\backslash
theta}_{old})$
\end_layout

\begin_layout Plain Layout


\backslash
State $particle_{new} 
\backslash
leftarrow$ Sample from $p(
\backslash
boldsymbol{x}|
\backslash
boldsymbol{
\backslash
theta}_{new})$
\end_layout

\begin_layout Plain Layout


\backslash
State $r 
\backslash
leftarrow 
\backslash
min(1,
\backslash
frac{I_{
\backslash
epsilon_{n}}(particle_{new})}{I_{
\backslash
epsilon_{n}}(particle)})$
\end_layout

\begin_layout Plain Layout


\backslash
If{$r < $ Sample from $Uniform(0, 1)$}
\backslash
Comment{Metropolis-Hastings step}
\end_layout

\begin_layout Plain Layout


\backslash
State 
\backslash
textbf{return} $(
\backslash
boldsymbol{
\backslash
theta},particle)$
\end_layout

\begin_layout Plain Layout


\backslash
Else
\end_layout

\begin_layout Plain Layout


\backslash
State 
\backslash
textbf{return} $(
\backslash
boldsymbol{
\backslash
theta}_{new},particle_{new})$
\end_layout

\begin_layout Plain Layout


\backslash
EndIf
\end_layout

\begin_layout Plain Layout


\backslash
EndFunction
\end_layout

\begin_layout Plain Layout


\backslash
newline
\end_layout

\begin_layout Plain Layout


\backslash
Function{Resample}{$
\backslash
boldsymbol{
\backslash
theta}, particles, 
\backslash
boldsymbol{w}$, N}
\end_layout

\begin_layout Plain Layout


\backslash
State Sample indices from a multinomial distribution $f(x_{1},...x_{N};N,w_{1},...,w_{
N})$
\end_layout

\begin_layout Plain Layout


\backslash
State 
\backslash
textbf{return} $(
\backslash
theta_{1}^{(1)},...,
\backslash
theta_{1}^{(x_{1})},...,
\backslash
theta_{N}^{(1)},...,
\backslash
theta_{N}^{(x_{N})},particles_{1}^{(1)},...,particles_{N}^{(x_{N})})$
\end_layout

\begin_layout Plain Layout


\backslash
EndFunction
\end_layout

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Section on kernels.
 Update schedules
\end_layout

\end_inset


\end_layout

\begin_layout Section
Examples
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
pagebreak
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "references"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
