#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\begin_preamble
% Først spesifiserer vi hvilken dokumentklasse vi vil ha og noen 
% globale opsjoner. Bytt ut 'article' med 'book' hvis du vil ha 
% med kapitler.
%\documentclass[a4paper, twoside, titlepage, 11pt]{article}

% Så sier vi fra om hvilke tilleggspakker vi trenger
% til dokumentet vårt. De som du ikke trenger (se kommentaren) 
% kan det være en fordel å kommentere ut (sett prosenttegn foran),
% da vil kompilering gå raskere.

%\usepackage[norsk]{babel}	% norske navn rundt omkring
\usepackage[T1]{fontenc}		% norsk tegnsett (æøå)
%\usepackage[utf8]{inputenc}	% norsk tegnsett
\usepackage{geometry}		% anbefalt pakke for å styre marger.

\usepackage{amsmath,amsfonts,amssymb} % matematikksymboler
\usepackage{amsthm}                   % for å lage teoremer og lignende.
\usepackage{graphicx}                 % inkludering av grafikk
\usepackage{subfig}                   % hvis du vil kunne ha flere
                                      % figurer inni en figur
\usepackage{listings}                 % Fin for inkludering av kildekode

%\usepackage{hyperref}                % Lager hyperlinker i evt. pdf-dokument
                                      % men har noen bugs, så den er kommentert
                                      % bort her.
                                 
% Indeksgenerering er kommentert ut her. Ta bort prosenttegnene
% hvis du vil ha en indeks:
%\usepackage{makeidx}     
%\makeindex              

% Needed to make authors appear in citations
\bibliographystyle{plainnat}

\usepackage{placeins}

\usepackage{algpseudocode}

\usepackage{tikz}
\usetikzlibrary{arrows}
\usetikzlibrary{shapes,snakes}

\usepackage{tkz-graph}

% \begin{document}

\pagestyle{empty}
\pagenumbering{roman}

% Inkluder forsida:
%\input{forside}


% Romerske tall på alt før selve rapporten starter er pent.
\pagenumbering{roman}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding utf8-plain
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine natbib_authoryear
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\notefontcolor #0000ff
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\listings_params "breaklines=true,captionpos=b,frame=tb,language=R"
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand include
filename "forside.tex"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
pagestyle{headings}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
pagenumbering{arabic} 
\end_layout

\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Approximate Bayesian Computation (ABC) is a term used for methods that in
 a Bayesian setting estimate the posterior without evaluating the likelihood
 function.
 Because the likelihood function is not evaluated, ABC methods are also
 known as 
\shape italic
likelihood-free
\shape default
 methods.
 The first such were developed in the field of population genetics in the
 late 1990s, and has since found use in other areas, notably in those with
 a relation to biology, see sections 3 and 7 in 
\begin_inset CommandInset citation
LatexCommand cite
key "1ef20ace6466467899d76e9976c9b6fa"

\end_inset

 for a history and examples.
 There are also examples of use in other fields, for instance image analysis
 
\begin_inset CommandInset citation
LatexCommand citet
key "Moores2014"

\end_inset

 and dynamical model selection 
\begin_inset CommandInset citation
LatexCommand cite
key "Toni187"

\end_inset

.
\end_layout

\begin_layout Standard
There is research being done on several aspects of ABC, see 
\begin_inset CommandInset citation
LatexCommand cite
key "approx_bayes_comp"

\end_inset

 for an overview.
 In this report we focus on explaining one computational strategy that there
 are several variations on in the ABC literature: Use of what is called
 Sequential Monte Carlo (SMC) when obtaining samples from the approximation
 to the posterior.
 More specifically we will focus on the work done in 
\begin_inset CommandInset citation
LatexCommand cite
key "adaptive_smc_for_abc"

\end_inset

 in detail.
\end_layout

\begin_layout Standard
We start with a quick look at the basics of Bayesian inference, and point
 out that there can often be a problem in evaluating the posterior probability.
 From here we look at some strategies for approximating the posterior, before
 we move on to the situation where we cannot evaluate the likelihood function,
 and it is here ABC becomes an alternative.
 We then describe ABC in general, before looking at the mentioned SMC in
 ABC approach for obtaining samples.
\end_layout

\begin_layout Section
Bayesian inference
\end_layout

\begin_layout Standard
We start with a quick overview of the basics of Bayesian inference to better
 our understanding of the problems that led to the development of ABC methods.
\end_layout

\begin_layout Standard
Our main goal here is to fit a model we have specified to some dataset,
 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, we have observed.
 The model will have parameters, and we would like to be able to say which
 ranges of the parameters are the most probable given the data.
\end_layout

\begin_layout Standard
To estimate the model parameters we use functions of the observed data.
 We call a such functions of the data statistics, and will denote it 
\begin_inset Formula $S(\boldsymbol{y})$
\end_inset

.
 We want to choose statistics that estimate the model parameters, which
 we denote 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

.
 We assume that 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 is a sample from a random vector, 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

.
 A random vector is a function from the sample space to 
\begin_inset Formula $\mathbb{R}^{n}$
\end_inset

, and a statistic is then in turn defined to be a function on a random variable/
vector.
 For a more thorough look at the definitions see chapter 5 of 
\begin_inset CommandInset citation
LatexCommand cite
key "CaseBerg:01"

\end_inset

.
\end_layout

\begin_layout Standard
To make it more concrete, 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 could be the heights of 50 people, and then the random variable 
\begin_inset Formula $\boldsymbol{X}$
\end_inset

 would be a function from the sample space, which here would the set of
 all permutations of 50 people in the population, into 
\begin_inset Formula $\mathbb{R}^{50}$
\end_inset

.
 A statistic of interest could be the average height of the population,
 and to estimate it we could define 
\begin_inset Formula $\hat{\theta}=\frac{1}{50}\sum_{i=1}^{50}Y_{i}$
\end_inset

, where 
\begin_inset Formula $\hat{\theta}$
\end_inset

 is an estimate of the population average, 
\begin_inset Formula $\theta$
\end_inset

, using the smaller sample set.
\end_layout

\begin_layout Standard
There are two approaches to viewing 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

.
 One is called the frequentist approach, where 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 is viewed as a vector of fixed numbers.
 That is: For the height example, 
\begin_inset Formula $\theta$
\end_inset

 is the average of all members of the population, which is a fixed number,
 but one that we can not compute without much effort: Gathering all the
 individuals and measuring their heights.
 So we instead make inferences using the smaller sample set, 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, and try to answer questions like: What is the probability that the interval
 
\begin_inset Formula $[175,185]$
\end_inset

 centimeters cover the true value 
\begin_inset Formula $\theta$
\end_inset

?
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
Insert figure
\end_layout

\end_inset


\end_layout

\begin_layout Standard
A different approach is to view 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 as a random vector.
 Here we say that for the purposes of analysis 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 is allowed to take on values from a set, but that some values may be more
 likely than others.
 This changes the form of the answer we give to our goal from that of the
 frequentist approach.
 We now answer questions of the type: How likely is 
\begin_inset Formula $\boldsymbol{\theta}_{1}$
\end_inset

, say, as a value of 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 given the data 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

.
 This question would not make sense in the frequentist setting, since there
 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 is fixed, and either 
\begin_inset Formula $\boldsymbol{\theta}_{1}=\boldsymbol{\theta}$
\end_inset

 or 
\begin_inset Formula $\boldsymbol{\theta}_{1}\neq\boldsymbol{\theta}$
\end_inset

, resulting in probability 1 or 0 respectively
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
Make more clear
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
Viewing 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 as a random vector gives us what is termed the Bayesian approach to inference.
 In a data analysis setting we can view this inference process to consist
 of three steps (see 
\begin_inset CommandInset citation
LatexCommand cite
key "gelman2013bayesian"

\end_inset

 for a full treatment on all aspects of Bayesian data analysis):
\end_layout

\begin_layout Enumerate
Setting up a full probability model.
 This means formulating a joint probability model for 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

: 
\begin_inset Formula $p(\boldsymbol{\theta},\boldsymbol{y})$
\end_inset

.
 Note again that we can do this is because 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 is a random vector, as opposed to the frequentist approach.
\end_layout

\begin_layout Enumerate
Conditioning on the observed data.
 This means evaluating 
\begin_inset Formula $p(\boldsymbol{\theta}|\boldsymbol{y})$
\end_inset

.
\end_layout

\begin_layout Enumerate
Evaluating the model.
 If the model does not fit the observed data, it can be changed, and the
 process starts from step 1 again.
\end_layout

\begin_layout Standard
In step 2 above, we need to make inferences about 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 given the observed data 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

.
 If we condition on the observed data, we can make use of Bayes' rule and
 write the conditional distribution as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(\boldsymbol{\theta}|\boldsymbol{y})=\frac{p(\boldsymbol{\theta},\boldsymbol{y})}{p(\boldsymbol{y})}=\frac{p(\boldsymbol{y}|\boldsymbol{\theta})p(\boldsymbol{\theta})}{p(\boldsymbol{y})}
\]

\end_inset


\end_layout

\begin_layout Standard
The factor 
\begin_inset Formula $p(\boldsymbol{y})$
\end_inset

 does not depend on 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

, and since the data is given, that is; 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 does not change, 
\begin_inset Formula $p(\boldsymbol{\theta}|\boldsymbol{y})$
\end_inset

 is a function of 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 only, and we can view 
\begin_inset Formula $p(\boldsymbol{y})$
\end_inset

 as a constant.
 We can thus write:
\begin_inset Formula 
\[
p(\boldsymbol{\theta}|\boldsymbol{y})\propto p(\boldsymbol{y}|\boldsymbol{\theta})p(\boldsymbol{\theta})
\]

\end_inset


\end_layout

\begin_layout Standard
There are expressions for the two terms on the right side: 
\begin_inset Formula $p(\boldsymbol{y}|\boldsymbol{\theta})$
\end_inset

 is termed the likelihood, and noting since 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 is constant, it is a function of 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

, and 
\begin_inset Formula $p(\boldsymbol{\theta})$
\end_inset

 is termed the prior distribution.
 Evaluating the posterior distribution is at the core of Bayesian inference.
 If now the expression for 
\begin_inset Formula $p(\boldsymbol{\theta}|\boldsymbol{y})$
\end_inset

 has some closed form and is integrable, we are all set to start making
 inferences about 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

, but we shall see that 
\begin_inset Formula $p(\boldsymbol{\theta}|\boldsymbol{y})$
\end_inset

 is not always on such a nice form.
\end_layout

\begin_layout Subsection
Evaluating the posterior
\end_layout

\begin_layout Standard
Concentrating on the 
\begin_inset Formula $p(\boldsymbol{y}|\boldsymbol{\theta})p(\boldsymbol{\theta})$
\end_inset

 form of the joint distribution, we need to think about how to set up the
 likelihood and prior.
 The prior represents our knowledge of 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 before we have seen any experimental data.
 This knowledge may be vague, or non-existent, in which case it might make
 sense to formulate 
\begin_inset Formula $p(\boldsymbol{\theta})$
\end_inset

 as uniform distribution over all possible values 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 can take, 
\begin_inset Formula $\boldsymbol{\theta}\sim\mathrm{Uniform}(\boldsymbol{\theta}_{min},\boldsymbol{\theta}_{max})$
\end_inset

, presuming we at least know what is the possible range.
 Or it may be that we have some prior knowledge that allows us to be more
 specific.
\end_layout

\begin_layout Standard
The expression for the likelihood is also formulated as a probability distributi
on.
 Keeping with the height example we can propose: 
\begin_inset Formula $p(\boldsymbol{y}|\boldsymbol{\theta})\sim\mathrm{N}(\theta_{1},\theta_{2})$
\end_inset

, a normal distribution with mean 
\begin_inset Formula $\theta_{1}$
\end_inset

 and variance 
\begin_inset Formula $\theta_{2}$
\end_inset

, so that 
\begin_inset Formula $\boldsymbol{\theta}=[\theta_{1},\theta_{2}]$
\end_inset

.
 To illustrate a point, we will simplify the setup, and say that 
\begin_inset Formula $\theta_{2}$
\end_inset

 is known so that what we are interested in evaluating is 
\begin_inset Formula $p(\theta_{1}|\boldsymbol{y})$
\end_inset

, and that the prior is 
\begin_inset Formula $\theta_{1}\sim\mathrm{N}(\mu,\sigma^{2})$
\end_inset

, with for instance 
\begin_inset Formula $\mu=180$
\end_inset

 and 
\begin_inset Formula $\sigma=10$
\end_inset

.
 In addition we assume the observations, 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, are independent.
 We can then write:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
p(\theta_{1}|\boldsymbol{y}) & \propto p(\boldsymbol{y}|\theta_{1})p(\theta_{1})\nonumber \\
 & =\frac{1}{\sqrt{2\pi}\theta_{2}}\exp\left(-\frac{1}{2}\sum_{i=1}^{n}\frac{(y_{i}-\theta_{1})^{2}}{\theta_{2}}\right)\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{1}{2}\frac{(\theta_{1}-\mu)^{2}}{\sigma^{2}}\right)\nonumber \\
 & \propto\exp\left(-\frac{1}{2}\sum_{i=1}^{n}\frac{(y_{i}-\theta_{1})^{2}}{\theta_{2}}-\frac{1}{2}\frac{(\theta_{1}-\mu)^{2}}{\sigma^{2}}\right)\nonumber \\
 & \propto\exp\left(-\frac{1}{2}\left(\frac{n}{\theta_{2}}+\frac{1}{\sigma^{2}}\right)\left(\left(\frac{n}{\theta_{2}}+\frac{1}{\sigma^{2}}\right)^{-1}\left(\frac{n}{\theta_{2}}\overline{y}+\frac{\mu}{\sigma^{2}}\right)-\theta_{1}\right)^{2}\right)\nonumber \\
 & \text{set \ensuremath{\tau=}}\left(\frac{n}{\theta_{2}}+\frac{1}{\sigma^{2}}\right)^{-1}\nonumber \\
 & \propto\exp\left(-\frac{1}{2}\tau^{-1}\left(\tau\left(\frac{n}{\theta_{2}}\overline{y}+\frac{\mu}{\sigma^{2}}\right)-\theta_{1}\right)^{2}\right)\label{eq:conjugate_prior2}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Going from the third to the fourth line above involves a bit of algebra,
 specifially using the trick of completing the square and also using that
 terms not involving 
\begin_inset Formula $\theta_{1}$
\end_inset

 can treated as constants, and thus removed when working with equations
 that only need to be proportional to each other.
\end_layout

\begin_layout Standard
There are a couple of points of interest in Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:conjugate_prior2"

\end_inset

.
 One is that the final expression does not involve the actual data points
 in 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, only their average 
\begin_inset Formula $\overline{y}$
\end_inset

.
 This relationship between 
\begin_inset Formula $\overline{y}$
\end_inset

, which is a statistic of 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, and the mean 
\begin_inset Formula $\theta_{1}$
\end_inset

, which is the parameter we want to estimate, has a name: We say that the
 statistic 
\begin_inset Formula $\overline{y}$
\end_inset

 is 
\shape italic
sufficient
\shape default
 for the mean 
\begin_inset Formula $\theta_{1}$
\end_inset

.
 Later we will touch upon this concept again, but see chapter 6 of 
\begin_inset CommandInset citation
LatexCommand cite
key "CaseBerg:01"

\end_inset

 for a more in-depth discussion.
\end_layout

\begin_layout Standard
The other point is that the final expression has the form of the probability
 density function of a normal distribution (we only need to add an appropriate
 constant in front).
 So we have shown that the posterior is a normal distribution.
 When the posterior distribution follows the same form as the prior distribution
, we call that property conjugacy.
 That it followed the same form depended on the fact that we chose the likelihoo
d to be a normal distribution, so we say that the normal prior distribution
 is a conjugate family for normal likelihood.
 Several such couplings exist, for instance the beta prior distribution
 is a conjugate family for the binomial likelihood.
\end_layout

\begin_layout Standard
Using the conjugacy property makes the posterior have a closed form, which
 makes it easy to work with.
 The problem is that we cannot always use this property.
 It may be that the chosen prior and/or likelihood has a form where the
 posterior will be a non-standard distribution or not a closed expression.
 To evaluate the posterior in such cases we need to look at other techniques
 where we instead compute an approximation to it.
\end_layout

\begin_layout Subsection
Approximating the posterior
\end_layout

\begin_layout Standard
To get a feel for what the evaluation problem is, consider the following:
 We might have a closed expression for the probability density function,
 which means a formula with no inifinte series involved, for the distribution,
 but still not be able to easily compute statistics involving it.
 Look at the equality of the expected value of some function of a parameter
 
\begin_inset Formula $\theta$
\end_inset

 shown below:
\begin_inset Formula 
\begin{equation}
\mathrm{E}(h(\theta)|y)=\int h(\theta)p(\theta|y)d\theta\label{eq:expected_value}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Assuming we cannot compute the integral in (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:expected_value"

\end_inset

), we cannot compute the expected value.
 In our one-dimensional example where there is only one parameter to estimate,
 this might not seem like a big problem to handle: The integral can be estimated
 to the required level of accuracy using some numerical procedure.
 However, in more real settings one can be confronted with much larger models
 with many unknown parameters, resulting in a much more complicated high-dimensi
onal integral which will be more difficult to estimate.
\begin_inset Formula 
\begin{equation}
\mathrm{E}(h(\theta)|y)\approx\frac{1}{N}\sum_{n=1}^{N}h(\hat{\theta}_{n})\label{eq:expected_value_approximation}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
In (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:expected_value_approximation"

\end_inset

) we show a method for approximating the expected value without evaluating
 the integral.
 In the formula 
\begin_inset Formula $\hat{\theta}_{n}$
\end_inset

 denotes a simulated sample, that is: It is a draw from 
\begin_inset Formula $p(\theta|y$
\end_inset

).
 Intuitively if we have a large collection of samples, 
\begin_inset Formula $\hat{\boldsymbol{\theta}}=\{\hat{\theta}_{1},...,\hat{\theta}_{N}\}$
\end_inset

, and compute the average of 
\begin_inset Formula $h(\hat{\boldsymbol{\theta}})$
\end_inset

, we expect to get an approximation to the expected value.
 This method of approximating an integral is called Monte Carlo integration.
 When the term Monte Carlo is used in a statistical method, it means that
 there is some use of random sampling involved, in this the case drawing
 from 
\begin_inset Formula $p(\theta|y)$
\end_inset

.
 Monte Carlo integration provides an alternative to non-stochastic methods
 for approximating an integral, such as quadrature methods.
 Which method that is best is dependent on the problem at hand, we just
 mention in passing that Monte Carlo in practice scales better to high-dimension
al settings, which are often encountered in Bayesian analysis, than quadrature
 methods, and is one explanation for their popularity, see chapter 6 of
 
\begin_inset CommandInset citation
LatexCommand citet
key "givens2012computational"

\end_inset

.
\end_layout

\begin_layout Standard
We can carry this idea about using random sampling further: With sample
 draws we can get an estimate of any aspect of the distribution 
\begin_inset Formula $p(\theta|y)$
\end_inset

, including the distribution itself, see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Approximations-to-normal"

\end_inset

 for an illustration.
 The figure shows that with enough samples we are able to construct the
 shape of the probability density function, and thus have complete information
 about the distribution.
\end_layout

\begin_layout Standard
If we now had a method of generating samples from an arbitrary distribution,
 it would be a very useful tool.
 In the next section we will describe the foundations of a popular set of
 methods that do just this and go under the collective term Markov Chain
 Monte Carlo (MCMC) methods.
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/sample_approximations.png
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Approximations to a normal distribution using samples.
 The solid lines show the true distribution, and the bars are a histogram
 of the samples.
\begin_inset CommandInset label
LatexCommand label
name "fig:Approximations-to-normal"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
MCMC methods are ubiquitous in Bayesian computation, but it is worth remembering
 they are not the only stochastic methods available for approximating a
 probability distribution.
 We touch upon another method, importance sampling, later on since it is
 an ingredient in the SMC method which is our main focus.
 
\end_layout

\begin_layout Standard
Another method is to try to approximate the distribution by using mixtures
 of more tractable ones, for instance normal distributions.
 Yet another strategy is to look at marginals of subsets of the parameters
 involved, try to approximate those and then combining them to approximate
 the full posterior.
 For instance:
\begin_inset Formula 
\[
p(\boldsymbol{\theta}|\boldsymbol{y})\propto p(\boldsymbol{y}|\theta_{1},\theta_{2})p(\theta_{1},\theta_{2}|\theta_{3})p(\theta_{3})
\]

\end_inset


\end_layout

\begin_layout Standard
Say 
\begin_inset Formula $\boldsymbol{\theta}=[\theta_{1},\theta_{2},\theta_{3}]$
\end_inset

 represents three parameters and 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 some observed data, and assume
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $p(\boldsymbol{y}|\theta_{1},\theta_{2})$
\end_inset

, 
\begin_inset Formula $p(\theta_{1},\theta_{2}|\theta_{3})$
\end_inset

 and 
\begin_inset Formula $p(\theta_{3})$
\end_inset

 can each be sufficiently approxmiated by some mixture of normal distributions.
 We could then by drawing samples from different normal distributions, which
 can easily be done, approximate 
\begin_inset Formula $p(\boldsymbol{\theta}|\boldsymbol{y}$
\end_inset

).
 This approach also illustrates a point we will return to: Splitting the
 big problem of approximating 
\begin_inset Formula $p(\boldsymbol{\theta}|\boldsymbol{y})$
\end_inset

 into a series of smaller subproblems.
\end_layout

\begin_layout Standard
Suffice to say the field dealing with how to approximate a distribution
 is huge, and we again refer to 
\begin_inset CommandInset citation
LatexCommand cite
key "gelman2013bayesian"

\end_inset

 which provides an overview of both MCMC and other methods (see especially
 chapter 13 of that text for non-MCMC methods).
\end_layout

\begin_layout Subsection
Markov Chain Monte Carlo
\end_layout

\begin_layout Standard
Even though the method we will focus on later is not an MCMC method, it
 does use some of the underlying theory, so we quickly go through some of
 the basics that we will need to understand the later discussion.
 We do not give proofs for many of the results presented, and instead reference
 the reader to other texts, for instance 
\begin_inset CommandInset citation
LatexCommand cite
key "gamerman2006markov"

\end_inset

, for more detailed discussions.
\end_layout

\begin_layout Standard
The core idea of an MCMC method is to use what is called a Markov chain,
 which is a form of stochastic process, to generate samples from some distributi
on.
 To start us off we define what a stochastic process is: A stochastic process
 is a collection of indexed random variables, 
\begin_inset Formula $X(t)$
\end_inset

, where 
\begin_inset Formula $t$
\end_inset

 is a member of some countable set.
 For instance tossing a coin multiple times could be viewed as a stochastic
 process.
 Let 
\begin_inset Formula $t$
\end_inset

 denote toss number, and let 
\begin_inset Formula $X(t)$
\end_inset

 be 1 if the coin turns up heads, and 0 if tails, at toss 
\begin_inset Formula $t$
\end_inset

.
 Assuming the coin is fair we have 
\begin_inset Formula $P(X(t))=\frac{1}{2}$
\end_inset

 for all 
\begin_inset Formula $t$
\end_inset

.
\end_layout

\begin_layout Standard
A Markov chain is a stochastic process that posesses what is called the
 Markov property:
\begin_inset Formula 
\begin{align*}
P(X(t)=x_{t}|P(X(t-1)_{t-1},P(X(t-2)_{t-2},...)= & P(X(t)=x_{t}|P(X(t-1)=x_{t-1})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The state of the process given its history, depends only on the state at
 the previous step.
 If we assume that the toin tosses mentioned above are independent, this
 process fulfills the Markov property.
 Actually, it more than fulfills it since we have 
\begin_inset Formula $P(X(t)=x_{t}|X(t-1)=x_{t-1})=P(X(t)=x_{t})$
\end_inset

.
\end_layout

\begin_layout Standard
We need to introduce some more terms related to Markov processes.
 Associated with a process there is the transition probability.
 This is the probability of the process going from a state at step 
\begin_inset Formula $t$
\end_inset

 to to next state at step 
\begin_inset Formula $t+1$
\end_inset

.
 For the coin toss example, we have two states, heads and tails, which we
 denote 
\begin_inset Formula $H$
\end_inset

 and 
\begin_inset Formula $T$
\end_inset

, and the probability of going between the different states can be visualised
 simply in matrix form:
\begin_inset Formula 
\[
\begin{array}{ccc}
 & H & T\\
H & \frac{1}{2} & \frac{1}{2}\\
T & \frac{1}{2} & \frac{1}{2}
\end{array}
\]

\end_inset


\end_layout

\begin_layout Standard
Let the rows be the state at time 
\begin_inset Formula $t$
\end_inset

, and the columns the state at time 
\begin_inset Formula $t+1$
\end_inset

.
 To see the probability of going from 
\begin_inset Formula $T$
\end_inset

 to 
\begin_inset Formula $H$
\end_inset

, look at the entry in row 2 and column1 for instance.
 Let us denote the matrix with the transition probabilities 
\begin_inset Formula $P$
\end_inset

.
 Continuing with the coin toss example we can use 
\begin_inset Formula $P$
\end_inset

 to generate a sequence of possible outcomes of throws.
 Say that the first throw was heads, 
\begin_inset Formula $H$
\end_inset

.
 From the 
\begin_inset Quotes eld
\end_inset

heads state
\begin_inset Quotes erd
\end_inset

 we see from the first row of 
\begin_inset Formula $P$
\end_inset

, that there is an equal probability of going to either heads or tails.
 The next state can be determined by choosing it a random given the probabilitie
s in the first row: There is a 
\begin_inset Formula $\frac{1}{2}$
\end_inset

 probability of going to 
\begin_inset Formula $H$
\end_inset

, and a 
\begin_inset Formula $\frac{1}{2}$
\end_inset

 probability of going to 
\begin_inset Formula $T$
\end_inset

.
 Say the next state is tails, 
\begin_inset Formula $T$
\end_inset

, now the process starts over again, but this time looking at the second
 row of 
\begin_inset Formula $P$
\end_inset

.
 We can continue this process indefinitely, producing a large a sequence
 representing one string of outcomes.
\end_layout

\begin_layout Standard
When we toss a coin we are in effect doing a sampling from a Bernoulli-distribut
ion, and assuming the coin is fair it will have parameter 
\begin_inset Formula $p=\frac{1}{2}$
\end_inset

.
 Notice that in the above however, we do not actually throw the coin, we
 look at 
\begin_inset Formula $P$
\end_inset

 to determine what the next outcome could be.
\end_layout

\begin_layout Standard
Now we ask the question: Which probability distribution does a large sequence
 of our simulated coin tosses appear to come from? The probability of going
 to heads or tails is the same, so the large sequence of tosses appears
 to come from the Bernoulli distribution with 
\begin_inset Formula $p=\frac{1}{2}$
\end_inset

.
 This is the same result we would get if we actually tossed the coin a large
 number of times.
\end_layout

\begin_layout Standard
This very simple example does contain a key idea that we will develop: We
 have a random variable, in this case a coin toss, 
\begin_inset Formula $X(t)$
\end_inset

, distributed accoring to a Bernoulli distribution, and we have the transition
 probabilities in 
\begin_inset Formula $P$
\end_inset

.
 We were able to generate a sample set coming from the Bernoulli distribution
 by abstaining from sampling from 
\begin_inset Formula $X(t)$
\end_inset

, only using the transition probabilities 
\begin_inset Formula $P$
\end_inset

.
\end_layout

\begin_layout Standard
This is what we will expand on.
 Given some probability distribution, 
\begin_inset Formula $\boldsymbol{\pi}$
\end_inset

, we will define transition probabilities so that we can generate a sequence
 of samples that come from 
\begin_inset Formula $\boldsymbol{\pi}_{t}$
\end_inset

, without actually doing any sampling from the distribution.
 Note that we will need to be able to evaluate the probability of a sample,
 
\begin_inset Formula $p_{\boldsymbol{\pi}}(\boldsymbol{x})$
\end_inset

, though.
\end_layout

\begin_layout Subsubsection
Stationary probability of a Markov process
\end_layout

\begin_layout Standard
Before explaining how to set up 
\begin_inset Formula $P$
\end_inset

, we need to explain the concept of stationary probabilities for a Markov
 process.
 Continuing with the coin example, we note that the system can be in one
 of two states: Either the last state was heads, or it was tails.
 Let us represent this state as a vector, calling it 
\begin_inset Formula $\boldsymbol{\pi}_{t}$
\end_inset

.
 The state vector has two elements, indicating the probability of either
 heads or tails.
 We have 
\begin_inset Formula $\sum_{i\in\{H,T\}}\boldsymbol{\pi}_{t}(i)=1$
\end_inset

 since it is a probability distribution.
 Say that we observed the state of the system at time 
\begin_inset Formula $t$
\end_inset

, and it was heads, the state is then 
\begin_inset Formula $\boldsymbol{\pi}_{t}=\left[1,0\right]^{T}$
\end_inset

.
 Using the transition matrix 
\begin_inset Formula $P$
\end_inset

 we can now determine the probability of the different states at later time
 steps in the following manner:
\begin_inset Formula 
\begin{align*}
P\boldsymbol{\pi}_{t} & =\left[\begin{array}{cc}
\frac{1}{2} & \frac{1}{2}\\
\frac{1}{2} & \frac{1}{2}
\end{array}\right]\left[\begin{array}{c}
1\\
0
\end{array}\right]\\
 & =\left[\begin{array}{c}
\frac{1}{2}\\
\frac{1}{2}
\end{array}\right]\\
 & =\boldsymbol{\pi}_{t+1}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We do not give any proofs that this gives the correct distribution here,
 only appeal to intuition and refer to for instance to chaper 4 of 
\begin_inset CommandInset citation
LatexCommand cite
key "ross2010probability"

\end_inset

 for a more rigorous treatment.
 Now note the following:
\begin_inset Formula 
\begin{align*}
P\boldsymbol{\pi}_{t+1} & =\left[\begin{array}{cc}
\frac{1}{2} & \frac{1}{2}\\
\frac{1}{2} & \frac{1}{2}
\end{array}\right]\left[\begin{array}{c}
\frac{1}{2}\\
\frac{1}{2}
\end{array}\right]\\
 & =\left[\begin{array}{c}
\frac{1}{2}\\
\frac{1}{2}
\end{array}\right]\\
 & =\boldsymbol{\pi}_{t+2}=\boldsymbol{\pi}_{t+1}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The distribution stays the same as we iterate.
 Given a transition matrix, if we have a distribution, 
\begin_inset Formula $\boldsymbol{\pi}$
\end_inset

, that does not change as change as we multiply with 
\begin_inset Formula $P$
\end_inset

, we say that the distribution is stationary.
 Since the distribution does not change we can drop the 
\begin_inset Formula $t$
\end_inset

 subscript and just write:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P\boldsymbol{\pi}=\boldsymbol{\pi}\label{eq:stationary_distribution}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
So if we can find a 
\begin_inset Formula $P$
\end_inset

 such that the distribution we want to sample from, 
\begin_inset Formula $\boldsymbol{\pi}$
\end_inset

, is the stationary distribution of a Markov chain, we have a way to generate
 samples from 
\begin_inset Formula $\boldsymbol{\pi}$
\end_inset

 without actually having to draw samples from the distribution.
 We start with a realisation from 
\begin_inset Formula $\boldsymbol{\pi}$
\end_inset

 and then choose the next realisation using 
\begin_inset Formula $P$
\end_inset

.
 The probability distribution for the next realisation will be 
\begin_inset Formula $\boldsymbol{\pi}$
\end_inset

 because of the stationarity.
 This is what we described in the previous section.
 
\end_layout

\begin_layout Subsubsection
Metropolis-Hastings algorithm
\end_layout

\begin_layout Standard
We now proceed to describe the construction a transition matrix that will
 allow us to obtain samples from an arbitrary distribution.
 This will result in what is called the Metropolis-Hastings algorithm.
 We stick to the discrete case for the time being, and later describe how
 the results carry over to the situation when we want to sample from a coninuous
 distribution.
\end_layout

\begin_layout Standard
The elements of the transition matrix are given as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P(i,j)=\begin{cases}
Q(i,j)\alpha(i,j) & i\neq j\\
Q(i,i)+\sum_{k\neq i}Q(i,k)(1-\alpha(i,k)) & i=j
\end{cases}\label{eq:transition_probabilities}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $Q$
\end_inset

 is a matrix, and 
\begin_inset Formula $\alpha(i,j)$
\end_inset

 is better viewed as a function.
 Both give a probability of going from state 
\begin_inset Formula $i$
\end_inset

 to state 
\begin_inset Formula $j$
\end_inset

.
 We need to impose some conditions on 
\begin_inset Formula $Q$
\end_inset

: It needs to be an irreducible transition matrix.
 What this means is that we for any state 
\begin_inset Formula $i$
\end_inset

 have a positive probability that it will enter any other state 
\begin_inset Formula $j$
\end_inset

 in some number of steps.
 This is written as 
\begin_inset Formula $P^{n}(i,j)>0$
\end_inset

 for some 
\begin_inset Formula $n\geq0$
\end_inset

.
\end_layout

\begin_layout Standard
We now define 
\begin_inset Formula $\alpha(i,j)$
\end_inset

:
\begin_inset Formula 
\[
\alpha(i,j)=\min\left(\frac{Q(j,i)\boldsymbol{\pi}(j)}{Q(i,j)\boldsymbol{\pi}(i)},1\right)
\]

\end_inset


\end_layout

\begin_layout Standard
A Markov chain where the following holds is called time reversible:
\begin_inset Formula 
\begin{equation}
P(i,j)\boldsymbol{\pi}(i)=P(j,i)\boldsymbol{\pi}(j),\forall i,j\label{eq:time_reversible}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Such a chain will have stationary probability 
\begin_inset Formula $\boldsymbol{\pi}$
\end_inset

.
 We see this intuitively, if the probability of going from 
\begin_inset Formula $i$
\end_inset

 to 
\begin_inset Formula $j$
\end_inset

 is the same as going from 
\begin_inset Formula $j$
\end_inset

 to 
\begin_inset Formula $i$
\end_inset

, the state distribution should not change as the process iterates.
 Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:time_reversible"

\end_inset

 is also called the detailed balance equation.
\end_layout

\begin_layout Standard
Looking at the case 
\begin_inset Formula $i\ne j$
\end_inset

 first and inserting Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:transition_probabilities"

\end_inset

 into Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:time_reversible"

\end_inset

 we get:
\begin_inset Formula 
\[
Q(i,j)\alpha(i,j)\boldsymbol{\pi}(i)=Q(j,i)\alpha(j,i)\boldsymbol{\pi}(j)
\]

\end_inset


\end_layout

\begin_layout Standard
Now assume 
\begin_inset Formula $Q(i,j)\boldsymbol{\pi}(i)>Q(j,i)\boldsymbol{\pi}(j)$
\end_inset

:
\begin_inset Formula 
\begin{align*}
Q(i,j)\frac{Q(j,i)\boldsymbol{\pi}(j)}{Q(i,j)\boldsymbol{\pi}(i)}\boldsymbol{\pi}(i) & =Q(j,i)\boldsymbol{\pi}(j)\\
Q(j,i)\boldsymbol{\pi}(j) & =Q(j,i)\boldsymbol{\pi}(j)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
If 
\begin_inset Formula $Q(i,j)\boldsymbol{\pi}(i)<Q(j,i)\boldsymbol{\pi}(j)$
\end_inset

 we have a similar result, and if 
\begin_inset Formula $i=j$
\end_inset

 Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:time_reversible"

\end_inset

 is trivially satisfied.
 So we see that by choosing 
\begin_inset Formula $P(i,j)$
\end_inset

 in this manner 
\begin_inset Formula $\boldsymbol{\pi}$
\end_inset

 will be a stationary distribution for the Markov chain.
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithmic}
\end_layout

\begin_layout Plain Layout


\backslash
Require $x_{init},N$
\end_layout

\begin_layout Plain Layout


\backslash
State $samples 
\backslash
leftarrow 
\backslash
text{empty array}$
\end_layout

\begin_layout Plain Layout


\backslash
State $counter 
\backslash
leftarrow 1$
\end_layout

\begin_layout Plain Layout


\backslash
State $x_{prev} 
\backslash
leftarrow x_{init}$
\end_layout

\begin_layout Plain Layout


\backslash
While{$counter<N$}
\end_layout

\begin_layout Plain Layout


\backslash
State Sample $x$ from $Q(x|x_{prev})$
\end_layout

\begin_layout Plain Layout


\backslash
State $
\backslash
alpha(x_{prev},x) 
\backslash
leftarrow 
\backslash
min
\backslash
left(
\backslash
frac{Q(x,x_{prev})
\backslash
boldsymbol{
\backslash
pi}(x)}{Q(x_{prev},x)
\backslash
boldsymbol{
\backslash
pi}(x_{prev})},1
\backslash
right)$
\end_layout

\begin_layout Plain Layout


\backslash
State $samples[counter] 
\backslash
leftarrow x_{prev}$
\end_layout

\begin_layout Plain Layout


\backslash
State $counter 
\backslash
leftarrow counter + 1$
\end_layout

\begin_layout Plain Layout


\backslash
State Set $x_{prev} 
\backslash
leftarrow x$ with probability $
\backslash
alpha(x_{prev},x)$
\end_layout

\begin_layout Plain Layout


\backslash
EndWhile
\end_layout

\begin_layout Plain Layout


\backslash
State 
\backslash
textbf{return} $samples$
\end_layout

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Metropolis-Hastings
\begin_inset CommandInset label
LatexCommand label
name "alg:Metropolis-Hastings"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Even if a proposed 
\begin_inset Formula $x$
\end_inset

 in Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:Metropolis-Hastings"

\end_inset

 is rejected, it still counts as a draw.
 The probabilities do come out correct because of the form of the case 
\begin_inset Formula $i=j$
\end_inset

 in Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:transition_probabilities"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Required properties for the Markov chain
\end_layout

\begin_layout Standard
In the above some details have been glossed over in order to get the main
 idea over quickly.
 One question not addressed is whether a Markov chain can have multiple
 stationary distributions.
 Unless we impose restrictions on the Markov chain it can.
 For there to be a unique stationary distribution we require the chain to
 be irreducible, which we defined previously, and what is called aperiodic
 and not transient.
\end_layout

\begin_layout Standard
A state, 
\begin_inset Formula $i$
\end_inset

, has period 
\begin_inset Formula $d$
\end_inset

 if 
\begin_inset Formula $P_{ii}^{n}=0$
\end_inset

 whenever 
\begin_inset Formula $n$
\end_inset

 is not divisible by 
\begin_inset Formula $d$
\end_inset

.
 In other words it is impossible to return to state 
\begin_inset Formula $i$
\end_inset

 after leaving it for at least 
\begin_inset Formula $n$
\end_inset

 steps.
 That a Markov chain is aperiodic means that all states have period 1, so
 the jump 
\begin_inset Formula $i\to i$
\end_inset

 has some positive probability.
 That it is not transient, also called positive recurrent, means that for
 each state 
\begin_inset Formula $i$
\end_inset

 number of steps until it returns to that state is finite.
 A Markov chain where the states are aperiodic and positive recurrent is
 called ergodic.
\end_layout

\begin_layout Standard
There is also the question of what to do if we cannot obtain the initial
 sample from the target distribution.
 An initial starting value can be choosen at random, but do we then know
 if the chain will produce correct value always? Assuming the chain is irreducib
le and ergodic we have the following: Define what is called the limiting
 probability for a state in the Markov chain: 
\begin_inset Formula $\boldsymbol{\pi}(j)=\lim_{n\to\infty}P_{ij}^{n}$
\end_inset

.
 This probability will exist for all states and will be independent of the
 initial state of the chain assuming it is irreducible and ergodic.
 Note that the limiting probability will also be the stationary probability.
\end_layout

\begin_layout Standard
This means we can start the chain from any state and know that it will go
 towards the stationary probability.
 We do not say anything about how many steps is required for the probability
 to come reasonably close to the stationary probability.
 In practice it is common to discard the initial states of the chain when
 the approximation is presumably bad.
 This period when the states are discarded is termed the burn-in period
 of the chain.
\end_layout

\begin_layout Subsubsection
Continuous distribution
\end_layout

\begin_layout Standard
In the above we have assumed that the state space was discrete, but we could
 imagine a process where a state vector is defined as 
\begin_inset Formula $\pi\sim\mathrm{N}(0,1)$
\end_inset

.
 The notation we have used in Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:stationary_distribution"

\end_inset

 breaks down when going to the continuous case however if we continue to
 view 
\begin_inset Formula $P$
\end_inset

 as a matrix.
 Instead we view 
\begin_inset Formula $P$
\end_inset

 as what is called a kernel, and keep using the notation in 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:stationary_distribution"

\end_inset

.
 Without going into details, what the kernel does is to give a probability
 of going from a state, say 
\begin_inset Formula $i$
\end_inset

, to another state 
\begin_inset Formula $j$
\end_inset

, just like the transition probability matrix does in the discrete case.
\end_layout

\begin_layout Standard
The results for the discrete case do carry over to the continuous one.
 The proofs need need adjustments to deal with a continuous state space,
 but suffice to say that it is still irreducibility and ergodicity that
 we require from the Markov chain.
 For details on how the results carry over see chapter 4.7 of 
\begin_inset CommandInset citation
LatexCommand cite
key "gamerman2006markov"

\end_inset

.
\end_layout

\begin_layout Subsection
Sampling importance resampling algorithm
\begin_inset CommandInset label
LatexCommand label
name "sub:Sampling-importance-resampling"

\end_inset


\end_layout

\begin_layout Standard
Here we illustrate a different method of obtaining samples from some distributio
n, and one that is part of the basis for the method which is the main focus
 of this report.
 Suppose we have a 
\begin_inset Formula $k$
\end_inset

-dimensional random variable 
\begin_inset Formula $\boldsymbol{X'}$
\end_inset

 coming from a distribution with probability density function 
\begin_inset Formula $p(\boldsymbol{x})$
\end_inset

, and that we are unable to generate samples from it, say because it is
 computationally intractable to do so.
 Suppose further that we have another density defined on the same probability
 space that we are able to generate samples from, call a random variable
 from this distribution 
\begin_inset Formula $\boldsymbol{X}$
\end_inset

 and its probability density function 
\begin_inset Formula $g(\boldsymbol{x})$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/targetAndProposalIllustration.png
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption

\begin_layout Plain Layout
Illustration of what could a be a target and proposal distribution.
 The function 
\begin_inset Formula $g(\boldsymbol{x})$
\end_inset

 is the probability density function of the distribution 
\begin_inset Formula $\mathrm{N}(2.3,0,4)$
\end_inset

, which is used for proposals.
 The target density with probability density function 
\begin_inset Formula $p(\boldsymbol{x})$
\end_inset

 is 
\begin_inset Formula $\mathrm{Beta}(2,5)$
\end_inset

 shifted by 
\begin_inset Formula $-2$
\end_inset

.
 To ensure good performance the distributions should be as similar to each
 other as possible.
 It is also important that the tails of 
\begin_inset Formula $g(\boldsymbol{x})$
\end_inset

 should cover the tails of 
\begin_inset Formula $f(\boldsymbol{x})$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "fig:Target-and-proposal"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
We can use the relationship between the two distributions, to give the samples
 we using 
\begin_inset Formula $g(\boldsymbol{x})$
\end_inset

, a weight based on how probable this sample is under 
\begin_inset Formula $p(\boldsymbol{x})$
\end_inset

, and then use these samples and weights to generate samples that approximate
 the distribution of 
\begin_inset Formula $\boldsymbol{X}'$
\end_inset

.
 Since we are drawing samples 
\begin_inset Formula $g(\boldsymbol{x})$
\end_inset

 we call its corresponding distribution the proposal distribution.
 
\end_layout

\begin_layout Standard
To see how this relationship lets us approximate the distribution of 
\begin_inset Formula $\boldsymbol{X}'$
\end_inset

, we start by defining a quantity known as the weight for a sample:
\begin_inset Formula 
\begin{equation}
w(\boldsymbol{x}_{i})=\frac{p(\boldsymbol{x}_{i})}{g(\boldsymbol{x}_{i})}\label{eq:unnormalised_weights}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
We also define 
\begin_inset Formula $\boldsymbol{x}_{1},...,\boldsymbol{x}_{n}$
\end_inset

 to be draws from the distribution of 
\begin_inset Formula $g(\boldsymbol{x})$
\end_inset

.
 Now consider the following algorithm:
\end_layout

\begin_layout Enumerate
Sample 
\begin_inset Formula $\boldsymbol{x}_{1},...,\boldsymbol{x}_{n}$
\end_inset

 using 
\begin_inset Formula $g(\boldsymbol{x})$
\end_inset

.
 
\end_layout

\begin_layout Enumerate
Calculate the weights, 
\begin_inset Formula $w(\boldsymbol{x}_{i})$
\end_inset

.
\end_layout

\begin_layout Enumerate
Resample from the set 
\begin_inset Formula $\boldsymbol{x}_{1},...,\boldsymbol{x}_{n}$
\end_inset

 
\begin_inset Formula $m$
\end_inset

 times with probabilities for drawing 
\begin_inset Formula $\boldsymbol{x}_{i}$
\end_inset

 being proportional to the weight 
\begin_inset Formula $w(\boldsymbol{x}_{i})$
\end_inset

.
 Denote this resampled set as 
\begin_inset Formula $\boldsymbol{\tilde{x}}_{1},...,\boldsymbol{\tilde{x}}_{m}$
\end_inset

.
\end_layout

\begin_layout Standard
A vector in the resampled set has a distribution such that 
\begin_inset Formula $P(\tilde{\boldsymbol{X}}=\boldsymbol{x}_{i})=\frac{w(\boldsymbol{x}_{i})}{\sum_{j=1}^{n}w(\boldsymbol{x}_{j})}$
\end_inset

.
 We now claim that when 
\begin_inset Formula $n\to\infty$
\end_inset

 the random vector 
\begin_inset Formula $\tilde{\boldsymbol{X}}$
\end_inset

 has a distribution density function that is equal to 
\begin_inset Formula $p(\boldsymbol{x})$
\end_inset

.
 Following a similar route as found in 
\begin_inset CommandInset citation
LatexCommand citet
key "givens2012computational"

\end_inset

 and 
\begin_inset CommandInset citation
LatexCommand cite
after "pp. 293-295"
key "ross2013simulation"

\end_inset

, we prove this by first noting that:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
P(\tilde{\boldsymbol{X}}\in A|\boldsymbol{X}_{1},...,\boldsymbol{X}_{n}) & =\frac{\sum_{i=1}^{n}I(\boldsymbol{X}_{i}\in A)w(\boldsymbol{X}_{i})}{\sum_{i=1}^{n}w(\boldsymbol{X}_{i})}\\
 & =\frac{\frac{1}{n}\sum_{i=1}^{n}I(\boldsymbol{X}_{i}\in A)w(\boldsymbol{X}_{i})}{\frac{1}{n}\sum_{i=1}^{n}w(\boldsymbol{X}_{i})}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $A$
\end_inset

 is a set of vectors, and 
\begin_inset Formula $I(\cdot)$
\end_inset

 an indicator function which is 1 if 
\begin_inset Formula $\boldsymbol{x}\in A$
\end_inset

, and 0 otherwise.
 By the strong law of large numbers we get for the nominator:
\begin_inset Formula 
\begin{align*}
\lim_{n\to\infty}\sum_{i=1}^{n}\frac{1}{n} & I(\boldsymbol{X}_{i}\in A)w(\boldsymbol{X}_{i})=\\
 & =\mathrm{E}(I(\boldsymbol{X}\in A)w(\boldsymbol{X}))\\
 & =\mathrm{E}(I(\boldsymbol{X}\in A)w(\boldsymbol{X})|I(\boldsymbol{X}\in A))P(I(\boldsymbol{X}\in A)\\
 & =\mathrm{E}(w(\boldsymbol{X})|\boldsymbol{X}\in A)P(\boldsymbol{X}\in A)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
For the denominator we have:
\begin_inset Formula 
\begin{align*}
\lim_{n\to\infty}\sum_{i=1}^{n}\frac{1}{n}w(\boldsymbol{X}_{i}) & =\mathrm{E}(w(\boldsymbol{X}))\\
 & =\mathrm{E}(\frac{p(\boldsymbol{X})}{g(\boldsymbol{X})})\\
 & =\int\frac{p(\boldsymbol{x})}{g(\boldsymbol{x})}g(\boldsymbol{x})d\boldsymbol{x}\\
 & =\int p(\boldsymbol{x})d\boldsymbol{x}\\
 & =1
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Inserting these expressions into the fraction:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{alignat}{1}
\lim_{n\to\infty}P(\tilde{\boldsymbol{X}}\in A|\boldsymbol{X}_{1},...,\boldsymbol{X}_{n}) & =\mathrm{E}(w(\boldsymbol{X})|\boldsymbol{X}\in A)P(\boldsymbol{X}\in A)\nonumber \\
 & =\int_{\boldsymbol{x}\in A}\frac{p(\boldsymbol{x})}{g(\boldsymbol{x})}g(\boldsymbol{x})d\boldsymbol{x}\nonumber \\
 & =\int_{\boldsymbol{x}\in A}p(\boldsymbol{x})d\boldsymbol{x}\label{eq:limit_fraction}
\end{alignat}

\end_inset


\end_layout

\begin_layout Standard
Using a theorem known as Lebesgue's dominated convergence theorem, we can
 now write the following:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
P(\tilde{\boldsymbol{X}}\in A) & =\\
 & \text{by law of double expectation}\\
\mathrm{E}(P(\tilde{\boldsymbol{X}}\in A)|\boldsymbol{X}_{1},...\boldsymbol{X}_{n}) & =\\
 & \text{by dominated convergence theorem applied to (\ref{eq:limit_fraction})}\\
\int_{\boldsymbol{x}\in A}p(\boldsymbol{x})d\boldsymbol{x}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
What we have shown here is that the probability 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $P(\tilde{\boldsymbol{X}}\in A$
\end_inset

), which we approximate through 
\begin_inset Formula $P(\tilde{\boldsymbol{X}}\in A|\boldsymbol{X}_{1},...,\boldsymbol{X}_{n})$
\end_inset

 for some fixed 
\begin_inset Formula $n$
\end_inset

, is the same as 
\begin_inset Formula $P(\boldsymbol{X}'\in A)$
\end_inset

, where 
\begin_inset Formula $\boldsymbol{X}'$
\end_inset

 is the random vector with associated probability density function 
\begin_inset Formula $p(\boldsymbol{x})$
\end_inset

 if we let 
\begin_inset Formula $n\to\infty$
\end_inset

.
 In other words: Drawing samples from the distribution associated with
\begin_inset Formula $\tilde{\boldsymbol{X}}$
\end_inset

, is the same as drawing samples from the target distribution when 
\begin_inset Formula $n\to\infty$
\end_inset

.
\end_layout

\begin_layout Standard
We see that when 
\begin_inset Formula $n$
\end_inset

 is large and the ratio 
\begin_inset Formula $m/n$
\end_inset

 small, we get a good approximation to the distribution.
 The algorithm is known as the Sampling Importance Resampling (SIR) algorithm.
\end_layout

\begin_layout Standard
In what follows we will encounter distributions where we only know the probabili
ty density function up to a constant.
 That is, we know that it has a form 
\begin_inset Formula $\mathrm{c}f(\boldsymbol{x})$
\end_inset

, where we know 
\begin_inset Formula $f(\boldsymbol{x})$
\end_inset

 but not 
\begin_inset Formula $\mathrm{c}$
\end_inset

.
 We can still use the SIR algorithm to generate samples from a distribution
 that is proportional to the target distribution, but we then have to use
 standardised weights:
\begin_inset Formula 
\[
w(\boldsymbol{x}_{i})=\frac{p(\boldsymbol{x}_{i})/g(\boldsymbol{x}_{i})}{\sum_{i=1}^{n}p(\boldsymbol{x}_{i})/g(\boldsymbol{x}_{i})}
\]

\end_inset


\end_layout

\begin_layout Standard
The reason why we standardise the weights, is that we then do not have to
 think about 
\begin_inset Formula $\mathrm{c}$
\end_inset

, since it will cancel in the nominator and denominator.
 The proof that the algorithm works in this case as well is similar to what
 we already have shown.
\end_layout

\begin_layout Standard
A potential problem that is especially prone to appear in the tails of the
 distributions, is that is if 
\begin_inset Formula $g(\boldsymbol{x})$
\end_inset

 is close to 0 at some point, and less than 
\begin_inset Formula $p(\boldsymbol{x})$
\end_inset

, a draw from that point will receive a very large weight, causing it to
 be drawn too often in the resampling step, and thus our approximation to
 the target distribution will be skewed away from the true target distribution.
 One solution, apart from the one of trying a different proposal distribution,
 is to do the final resampling step without replacement, to ensure excessive
 duplication (see 6.3.1 of 
\begin_inset CommandInset citation
LatexCommand citet
key "givens2012computational"

\end_inset

).
\end_layout

\begin_layout Subsection
Sequential Importance Sampling
\begin_inset CommandInset label
LatexCommand label
name "sub:Sequential-Importance-Sampling"

\end_inset


\end_layout

\begin_layout Standard
We now expand on the ideas from the previous section and show a method of
 computing the weights recursively that will be become central later.
 Using unnormalized weights, 
\begin_inset Formula $w(\boldsymbol{x})=\frac{p(\boldsymbol{x})}{g(\boldsymbol{x})}$
\end_inset

, in the following discussion we see that 
\begin_inset Formula $w(\boldsymbol{x})$
\end_inset

 can be rewritten as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
w(\boldsymbol{x})=\frac{p(x_{1})p(x_{2}|x_{1})p(x_{3}|x_{1},x_{2})...p(x_{k}|x_{1},...,x_{k-1})}{g(x_{1})g(x_{2}|x_{1})g(x_{3}|x_{1},x_{2})...g(x_{k}|x_{1},...,x_{k-1})}\label{eq:weight_decomposition}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Assuming 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

 is a vector of 
\begin_inset Formula $k$
\end_inset

 elements.
 If we define 
\begin_inset Formula $\boldsymbol{x}_{t}=(x_{1},...,x_{t})$
\end_inset

, the above can be written recursively as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
w_{t}(\boldsymbol{x}_{t})=w_{t-1}(\boldsymbol{x}_{t-1})\frac{p(x_{t}|\boldsymbol{x}_{t-1})}{g(x_{t}|\boldsymbol{x}_{t-1})}
\]

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $1\leq t\leq k$
\end_inset

, and we define 
\begin_inset Formula $w(\boldsymbol{x})=w_{k}(\boldsymbol{x}_{k})$
\end_inset

.
 Doing such a decomposition has some advantages when dealing with high-dimension
al problems where it is difficult to find a good proposal distribution
\begin_inset CommandInset citation
LatexCommand cite
after "pp. 46-47"
key "liu2001monte"

\end_inset

: It lets us stop calculation of the weights early if we see some of them
 becoming 0, and we can also make use of 
\begin_inset Formula $p(x_{t}|\boldsymbol{x}_{t-1})$
\end_inset

 when setting up the proposal distribution 
\begin_inset Formula $g(x_{t}|\boldsymbol{x}_{t-1})$
\end_inset

.
\end_layout

\begin_layout Standard
There is however a problem in that we need the marginal distributions, 
\begin_inset Formula $p(x_{1})$
\end_inset

,
\begin_inset Formula $p(x_{1},x_{2})$
\end_inset

,..., to get expressions for the conditional distributions.
 To get the marginal distributions there is a need to integrate out variables.
 For instance, we need 
\begin_inset Formula $p(x_{k}|x_{1},...,x_{k-1})=p(x_{k}|\boldsymbol{x}_{k-1})p(\boldsymbol{x}_{k-1})$
\end_inset

 in the recursion and we have:
\begin_inset Formula 
\begin{equation}
p(x_{k}|\boldsymbol{x}_{k-1})=\frac{p(\boldsymbol{x}_{k})}{p(\boldsymbol{x}_{k-1})}\label{eq:conditional_probability}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
We are give the full distribution, 
\begin_inset Formula $p(\boldsymbol{x}_{k})=p(\boldsymbol{x})$
\end_inset

, but to find 
\begin_inset Formula $p(\boldsymbol{x}_{k-1})$
\end_inset

 we must integrate out variables:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(\boldsymbol{x}_{k-1})=\int...\int p(x_{1},x_{2},...,x_{k})\mathrm{d}x_{k}
\]

\end_inset


\end_layout

\begin_layout Standard
And similarly for the other elements in the recursion.
 This integration may be difficult or impossible to perform, and to get
 around this problem we introduce another layer of complexity and look for
 a sequence of marginal distributions that are approximations to 
\begin_inset Formula $p(\boldsymbol{x})$
\end_inset

: 
\begin_inset Formula $\hat{p}(x_{1})$
\end_inset

, 
\begin_inset Formula $\hat{p}(x_{1},x_{2})$
\end_inset

,...,
\begin_inset Formula $p(x_{1},x_{2},...,x_{k})$
\end_inset

.
 Note that the last step in the sequence of approximations, is actually
 not an approximation but the full joint distribution, 
\begin_inset Formula $p(\boldsymbol{x})$
\end_inset

.
 By rewriting the recursion like so (by using a calculation like in (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:conditional_probability"

\end_inset

)):
\begin_inset Formula 
\begin{align*}
w_{t}(\boldsymbol{x}_{t}) & =w_{t-1}(\boldsymbol{x}_{t-1})\frac{\hat{p}(\boldsymbol{x}_{t})}{\hat{p}(\boldsymbol{x}_{t-1})g(x_{t}|\boldsymbol{x}_{t-1})}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
And using the fact that 
\begin_inset Formula $\hat{p}(\boldsymbol{x}_{k})=p(\boldsymbol{x}_{k})$
\end_inset

, we see how the approximations can be used in the weight update: The approximat
ions will cancel and in the final step we will have 
\begin_inset Formula $w(\boldsymbol{x}_{k})=\frac{p(\boldsymbol{x}_{k})}{g(\boldsymbol{x}_{k})}$
\end_inset

 as required.
 To ease the notation we define 
\begin_inset Formula $u_{t}(\boldsymbol{x}_{t-1})=\frac{p(\boldsymbol{x}_{t})}{p(x_{t}|\boldsymbol{x}_{t-1})g(x_{t}|\boldsymbol{x}_{t-1})}$
\end_inset

 and call it the weight update.
 
\end_layout

\begin_layout Standard
In summary we are faced with two challenges when setting up the sequential
 importance sampling: Finding good proposal distributions, 
\begin_inset Formula $g(x_{t}|\boldsymbol{x}_{t-1})$
\end_inset

, and possibly approximations 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\hat{p}(\boldsymbol{x}_{t})$
\end_inset

 to the true marginal distributions 
\begin_inset Formula $p(\boldsymbol{x}_{t})$
\end_inset

.
 In addition when updating the weights there is a danger that a small fraction
 of the particles will receive most of the weighting, something which may
 yield a poor approximation to the target distribution.
 When this occurs it is called weight degeneracy.
\end_layout

\begin_layout Subsubsection
Weight degeneracy
\end_layout

\begin_layout Standard
When updating the weights, their variance will increase, that is: They will
 spread out.
 It may happen that a proportion of the weights tend toward 0.
 This does not mean that the particles with these weights are stuck in a
 low weight region forever, but in practice we would like to avoid spending
 too much computational resources on updating particles that do not appear
 to contribute to our approximation of 
\begin_inset Formula $p(\boldsymbol{x})$
\end_inset

.
 A low weight means a low probability of drawing that particle in the final
 resampling step of the algorithm, and so entails a low impact on the final
 result.
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/weight_plot_resample0.png
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Illustration of weight degeneracy.
 These plots come from an example we will revisit.
 The graph on the left shows the weight of the particles, the middle one
 a histogram based on a sampling from the weighted particles and the one
 on the the left the evolution of effective sample size over the iterations.
 The true distribution is superimposed on the histogram as a green line.
 Note that only what appear to be two particles have non-zero weights, meaning
 these are the only ones having any probability of being drawn in the sampling
 at the end of the run.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
A strategy to better utilize the computational resources is to insert a
 resampling step in the incremental weight update process if a high proportion
 of the particles get stuck with low weights.
 Note that resampling is not the only method of dealing with vanishing weights
 in sequential Monte Carlo methods, see chapter 3 of 
\begin_inset CommandInset citation
LatexCommand cite
key "liu2001monte"

\end_inset

 for more information, which also includes some variations on how the actual
 resampling can be done.
\end_layout

\begin_layout Standard
In short the resampling creates a new sample set that has a better distribution
 of the weights, by picking particles from the existing sample set and favouring
 those with high weights.
 When a resampling is done we draw 
\begin_inset Formula $n$
\end_inset

 samples, where 
\begin_inset Formula $n$
\end_inset

 is the number of samples we started out with, from a multinomial distribution
 where each particle has a probability of being drawn that is proportional
 to its weight.
 If the weights are normalised, we just use them as the probabilities in
 the multinomial distribution.
 Writing this a bit more mathematically we have: Let 
\begin_inset Formula $x_{1},...,x_{n}$
\end_inset

 be the particles, and 
\begin_inset Formula $w_{1},...,w_{n}$
\end_inset

 the corresponding normalised weights, and let 
\begin_inset Formula $1\leq k\leq n$
\end_inset

.
 Let 
\begin_inset Formula $K$
\end_inset

 be the random variable denoting the probability of choosing particle 
\begin_inset Formula $x_{k}$
\end_inset

 in the resampling step.
 Then we have: 
\begin_inset Formula 
\[
K\sim\mathrm{Multin}(n,w_{1},...,w_{n})
\]

\end_inset


\end_layout

\begin_layout Standard
After the resampling has been done, all the weights are set to be 
\begin_inset Formula $\frac{1}{n}$
\end_inset

.
 We do not want to do resampling too often however, both because of the
 computations involved, and also because it will have an effect on variance
 on the estimator which is the final product of the SMC method: Imagine
 running the method several times, the resampling steps may contribute to
 different parts of the parameter space getting focus from run to run, causing
 the variance to increase.
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/weight_plot_resample05.png
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Here the resampling procedure has been implemented.
 When the ESS drops below a given threshold a resampling is done.
 More particles have non-zero weights, and the histogram shows the sample
 distribution to lie closer to the true distribution.
 A resampling was done just before the weight plot and histogram was generated,
 and explains why all the weights seem to be the same here.
 Because normalized weighs are used all the particles have a weight close
 to 0 at this point.
 Note the approximation is still not good because of the low number of particles
, 50, we have used here.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Effective Sample Size
\end_layout

\begin_layout Standard
A question we need to answer is when we should do a resampling.
 To determine this we will look at a quantity called the Effective Sample
 Size (ESS) as the weights are updated.
 The concept of the ESS is defined to be the equivalent number of independent
 samples from the actual target distribution our sample set from the SMC
 method is 
\begin_inset Quotes eld
\end_inset

worth.
\begin_inset Quotes erd
\end_inset

 This concept can also be used in MCMC settings, not just SMC.
 There are several measures for the ESS, and we look at widely used definition
 from 
\begin_inset CommandInset citation
LatexCommand cite
key "liu2001monte"

\end_inset

 that we will manipulate a bit:
\begin_inset Formula 
\begin{equation}
\mathrm{ESS}(n)=\frac{n}{1+\mathrm{var}_{g}(w(\boldsymbol{X}))}\label{eq:ess}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $n$
\end_inset

 is the number of samples and 
\begin_inset Formula $\mathrm{var}_{g}(w(\boldsymbol{X}))$
\end_inset

 the variance of the normalised weights with respect to the proposal distributio
n.
 We interpret it to mean that 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $n$
\end_inset

 weighted samples are worth as much as 
\begin_inset Formula $\mathrm{ESS}(n)$
\end_inset

 independent and identically drawn samples from the target distribution
 
\begin_inset Formula $p$
\end_inset

(
\begin_inset Formula $\boldsymbol{X})$
\end_inset

.
\begin_inset Quotes erd
\end_inset

 Looking at (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ess"

\end_inset

) we see that the max value for 
\begin_inset Formula $\mathrm{ESS}(n)$
\end_inset

 is 
\begin_inset Formula $n$
\end_inset

, and it occurs when the variance is 0.
 For instance if we set 
\begin_inset Formula $g(\boldsymbol{X})=p(\boldsymbol{X})$
\end_inset

, proposal equals target distribution, this will occur, and it makes sense
 since then we are actually sampling from the target distribution.
 It could also occur if all the weights were equally bad, say all ratios
 weigths were 
\begin_inset Formula $\frac{1}{1000}$
\end_inset

, so it is not a perfect measure.
 See for instance 
\begin_inset CommandInset citation
LatexCommand citet
key "1602.03572"

\end_inset

 for a discussion of this, and some alternative measures of ESS.
\end_layout

\begin_layout Standard
We now provide some justification for why (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ess"

\end_inset

) looks the way is does.
 The notion comes from a technical report 
\begin_inset CommandInset citation
LatexCommand cite
key "kong1992ImportanceSampling"

\end_inset

, who examined the efficiency between two estimators for the expected value
 of a random variable:
\begin_inset Formula 
\[
\mu=\mathrm{E}_{p}(h(\boldsymbol{X}))=\int h(\boldsymbol{x})p(\boldsymbol{x})d\boldsymbol{x}
\]

\end_inset


\end_layout

\begin_layout Standard
One estimator is the mean:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{\mu}=\frac{1}{n}\sum_{i=1}^{n}h(\boldsymbol{x}_{i})
\]

\end_inset


\end_layout

\begin_layout Standard
Another one is a weighted mean, where the weigths have been normalised:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\tilde{\mu}=\frac{w_{1}h(\boldsymbol{x}_{1})+...+w_{n}h(\boldsymbol{x}_{n})}{w_{1}+...+w_{n}}
\]

\end_inset


\end_layout

\begin_layout Standard
When comparing the efficiencies of estimators, a common approach is to look
 at the ratio between them:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\frac{\mathrm{var}_{g}(\tilde{\mu})}{\mathrm{var}_{p}(\hat{\mu})}\approx1+\mathrm{var}_{g}\left(\frac{p(\boldsymbol{X})}{g(\boldsymbol{X})}\right)=1+\mathrm{var}_{g}(w(\boldsymbol{X}))\label{eq:ratio_approximation}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $\tilde{\mu}$
\end_inset

 is using samples from 
\begin_inset Formula $p(\boldsymbol{x})$
\end_inset

 and 
\begin_inset Formula $\hat{\mu}$
\end_inset

 from 
\begin_inset Formula $g(\boldsymbol{x})$
\end_inset

.
 Low variance is a desirable property of an estimator, so a large ratio
 is in favour of 
\begin_inset Formula $\hat{\mu}$
\end_inset

, and a low in favour of 
\begin_inset Formula $\tilde{\mu}$
\end_inset

.
 
\end_layout

\begin_layout Standard
The approximation in (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ratio_approximation"

\end_inset

) is the main result of the technial report, and 
\begin_inset CommandInset citation
LatexCommand cite
key "liu2001monte"

\end_inset

 then uses this approximation to justify the following:
\begin_inset Formula 
\[
\frac{\mathrm{var}_{p}(h(\boldsymbol{X}))}{\mathrm{var}_{g}(w(\boldsymbol{X})h(\boldsymbol{X}))}\approx\frac{1}{1+\mathrm{var}_{g}(w(\boldsymbol{X}))}
\]

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $h(\cdot)$
\end_inset

 is some function of 
\begin_inset Formula $\boldsymbol{X}$
\end_inset

, and for our purposes we can take it to be the identity function.
 This expression is interpreted to mean that one sample from 
\begin_inset Formula $p(\boldsymbol{X})$
\end_inset

, is worth about 
\begin_inset Formula $1+\mathrm{var}_{g}(w(\boldsymbol{X}))$
\end_inset

 weighted sample.
 If there are 
\begin_inset Formula $n$
\end_inset

 samples, we multiple the expression by 
\begin_inset Formula $n$
\end_inset

 and get (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ess"

\end_inset

).
 Note that in practice we need to estimate 
\begin_inset Formula $\mathrm{var}_{g}(w(\boldsymbol{X}))$
\end_inset

 by using the sample variance.
 
\end_layout

\begin_layout Standard
The justification of the above assumes that the weights, 
\begin_inset Formula $w(\boldsymbol{X})$
\end_inset

, refer to the unnormalised weights.
 This is a problem if we do not know the constant 
\begin_inset Formula $\mathrm{c}$
\end_inset

 in (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:importance_sampling"

\end_inset

).
 In that case we can use a different expression to give a measure of the
 variability instead of 
\begin_inset Formula $\mathrm{var}(w(\boldsymbol{X})$
\end_inset

, called the coefficient of variation:
\begin_inset Formula 
\begin{equation}
\mathrm{cv}^{2}(w(\boldsymbol{x}))=\frac{\sum_{i=1}^{n}(w_{i}(\boldsymbol{x})-\bar{w}(\boldsymbol{x}))^{2}}{n\bar{w}(\boldsymbol{x})^{2}}\label{eq:coefficient_of_variation}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $\bar{w}=\frac{1}{n}\sum_{i=1}^{n}w_{i}(\boldsymbol{x})$
\end_inset

 is the sample average.
 Using this expression cancels the constant as we shall we.
 Note that 
\begin_inset CommandInset citation
LatexCommand citet
key "liu2001monte"

\end_inset

 operates with 
\begin_inset Formula $n-1$
\end_inset

 in the denominator.
 Inserting (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:coefficient_of_variation"

\end_inset

) into (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ess"

\end_inset

) we get:
\begin_inset Formula 
\begin{align}
\frac{n}{1+\mathrm{cv}^{2}(w(\boldsymbol{x}))} & =\frac{n}{1+\frac{\sum_{i=1}^{n}(w_{i}(\boldsymbol{x})-\bar{w}(\boldsymbol{x}))^{2}}{n\bar{w}(\boldsymbol{x})^{2}}}\nonumber \\
 & =\frac{n^{2}}{n+\sum_{i=1}^{n}\left(\frac{w_{i}(\boldsymbol{x})-\bar{w}(\boldsymbol{x})}{\bar{w}(\boldsymbol{x})}\right)^{2}}\nonumber \\
 & =\frac{n^{2}}{n+\sum_{i=1}^{n}\left(\frac{w_{i}(\boldsymbol{x})}{\bar{w}(\boldsymbol{x})}\right)^{2}-\frac{2}{\bar{w}(\boldsymbol{x})}\sum_{i=1}^{n}w_{i}(\boldsymbol{x})+\sum_{i=1}^{n}\left(\frac{\bar{w}(\boldsymbol{x})}{\bar{w}(\boldsymbol{x})}\right)^{2}}\nonumber \\
 & =\frac{n^{2}}{n+n^{2}\sum_{i=1}^{n}\underbar{w}_{i}(\boldsymbol{x})^{2}-2n+n}\nonumber \\
 & =\frac{n^{2}}{n^{2}\sum_{i=1}^{n}\underbar{w}_{i}(\boldsymbol{x})^{2}}\nonumber \\
 & =\frac{1}{\sum_{i=1}^{n}\underbar{w}_{i}(\boldsymbol{x})^{2}}\label{eq:normalized_ess}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $\underbar{w}_{i}(\boldsymbol{x})$
\end_inset

 denotes the normalized weight for particle 
\begin_inset Formula $i$
\end_inset

.
 This expression for the ESS is a common one in the literature, and is the
 one we will use here as well.
 A resampling step is triggered when it drops below a given threshold to
 be specified later.
 The rationale being that the weights at that point have spread out so much,
 that we are wasting computations on particles that are in low probably
 regions of the probability space, and should instead concentrate more on
 the regions were the particles with higher weights are located.
\end_layout

\begin_layout Standard
In deriving the expression for the ESS we will use, we went through two
 approximations, and it is worth keeping in mind that we do not rely on
 stringent theoretical properties involving it.
 Indeed the ESS is described as a 
\begin_inset Quotes eld
\end_inset

rule of thumb
\begin_inset Quotes erd
\end_inset

 that can be used to give an indication of how much the weighted sampled
 is worth.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
FloatBarrier
\end_layout

\end_inset


\end_layout

\begin_layout Section
Approximate Bayesian Computation
\end_layout

\begin_layout Standard
Having described some problems that can arise in evaluating the posterior,
 or in general any probability distribution, and two methods for obtaining
 samples from it.
 We now introduce another potential problem: The likelihood function may
 be difficult to evaluate, for instance it may be computationally intractable
 to do so, or the function does not have an analytic form.
 
\end_layout

\begin_layout Standard
In such settings what are termed likelihood-free or ABC methods can be employed
 to draw inferences.
 The name refers to the fact that the methods do not explicitly evaluate
 the likelihood function, but instead approximate it using simulations.
 In the previous methods we described there is a requirement that given
 a sample, we can evaluate its probability, and for the posterior this means
 being able to evaluate the likelihood, and the prior.
 The likelihood gets most of the attention here, since we have more freedom
 when it comes to selecting a prior.
 We could for instance use a non-informative prior if we had no good guesses
 what it should look like, while the likelihood is tied to the actual observed
 data.
\end_layout

\begin_layout Standard
Likelihood-free methods are especially popular in fields like population
 geneitcs, epidemology, biology and ecology, where it is often the case
 that the model one wants to estimate parameters for is in the form of sone
 stochastic process.
 This means that given a set of parameters it is possible to run the model
 and get a realisation, but it is not clear how to go backwards from a realisati
on of the process to find the most probable parameter values.
\end_layout

\begin_layout Subsection
The core idea
\end_layout

\begin_layout Standard
To understand how likelihood-free methods work, let us look at the posterior
 again, and introduce an auxillary variable, 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

 (see 
\begin_inset CommandInset citation
LatexCommand cite
key "Sisson2011"

\end_inset

 for more details).
 From Bayes rule we have:
\begin_inset Formula 
\begin{equation}
p(\boldsymbol{\theta},\boldsymbol{x}|\boldsymbol{y})\propto p(\boldsymbol{y}|\boldsymbol{x},\boldsymbol{\theta})p(\boldsymbol{x}|\boldsymbol{\theta})p(\boldsymbol{\theta})\label{eq:abc_sampling_distribution}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The posterior can be retrieved by integrating out 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

:
\begin_inset Formula 
\begin{align*}
p(\boldsymbol{\theta}|\boldsymbol{y}) & \propto p(\boldsymbol{\theta})\int_{Y}p(\boldsymbol{y}|\boldsymbol{x},\boldsymbol{\theta})p(\boldsymbol{x}|\boldsymbol{\theta})d\boldsymbol{x}\\
 & =p(\boldsymbol{\theta})\int_{Y}p(\boldsymbol{y},\boldsymbol{x}|\boldsymbol{\theta})d\boldsymbol{x}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
It is assumed that we have an expression for the prior, 
\begin_inset Formula $p(\boldsymbol{\theta})$
\end_inset

, and are able to generate samples from 
\begin_inset Formula $p(\boldsymbol{x}|\boldsymbol{\theta}).$
\end_inset

 If 
\begin_inset Formula $p(\boldsymbol{y}|\boldsymbol{x},\boldsymbol{\theta})$
\end_inset

 is defined to the Dirac-function with 
\begin_inset Formula $\boldsymbol{x}=\boldsymbol{y}$
\end_inset

 we get:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
p(\boldsymbol{\theta}|\boldsymbol{y}) & \propto p(\boldsymbol{\theta})\int_{Y}I(\boldsymbol{x}=\boldsymbol{y})p(\boldsymbol{x}|\boldsymbol{\theta})d\boldsymbol{x}\nonumber \\
 & =p(\boldsymbol{\theta})p(\boldsymbol{y}|\boldsymbol{\theta})\label{eq:likelihood_dirac}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
If we were able to draw samples from the likelihood function such that 
\begin_inset Formula $\boldsymbol{x}=\boldsymbol{y}$
\end_inset

, we could estimate the posterior probability.
 A simple algorithm for this is shown in Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:Likelihood-free-sampling"

\end_inset

.
 The algorithm will produce samples from the posterior, but there is a practical
 problem in the comparison 
\begin_inset Formula $\boldsymbol{x}=\boldsymbol{y}$
\end_inset

.
 For continuous probability distributions, the probability that two samples
 are exactly the same is 0, and for discrete probability distributions the
 probability for the being the same is also likely to be close to 0 in practical
 problems.
 Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:Likelihood-free-sampling"

\end_inset

 is not practically useful, since most samples being generated will be discarded.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithmic}
\end_layout

\begin_layout Plain Layout


\backslash
State $counter 
\backslash
leftarrow 0$
\end_layout

\begin_layout Plain Layout


\backslash
State $samples 
\backslash
leftarrow 
\backslash
text{empty array}$
\end_layout

\begin_layout Plain Layout


\backslash
While{$counter<N$}
\end_layout

\begin_layout Plain Layout


\backslash
State Sample $
\backslash
boldsymbol{
\backslash
theta}$ from $p(
\backslash
boldsymbol{
\backslash
theta})$ 
\end_layout

\begin_layout Plain Layout


\backslash
State Sample $
\backslash
boldsymbol{x}$ from $p(
\backslash
boldsymbol{x}|
\backslash
boldsymbol{
\backslash
theta})$
\end_layout

\begin_layout Plain Layout


\backslash
If{$
\backslash
boldsymbol{x}=
\backslash
boldsymbol{y}$}
\end_layout

\begin_layout Plain Layout


\backslash
State $samples[counter] 
\backslash
leftarrow 
\backslash
boldsymbol{
\backslash
theta}$
\end_layout

\begin_layout Plain Layout


\backslash
State $counter=counter+1$
\end_layout

\begin_layout Plain Layout


\backslash
EndIf
\end_layout

\begin_layout Plain Layout


\backslash
EndWhile
\end_layout

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Likelihood free sampling
\begin_inset CommandInset label
LatexCommand label
name "alg:Likelihood-free-sampling"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Keeping the core idea, we can make a couple of changes to make the algorithm
 more useful.
 The requirement that 
\begin_inset Formula $\boldsymbol{x}=\boldsymbol{y}$
\end_inset

 can be relaxed, and instead samples that lie within some defined distance
 of 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 are accepted: 
\begin_inset Formula $d(\boldsymbol{x},\boldsymbol{y})\leq\epsilon$
\end_inset

.
 This begs the question what 
\begin_inset Formula $\epsilon$
\end_inset

 should be, and how it affects the approximation.
 Intuitively smaller values yields better approximations, but increases
 computation time, since more samples are discarded.
 We will examine strategies to determine 
\begin_inset Formula $\epsilon$
\end_inset

 later.
\end_layout

\begin_layout Standard
We also need to make a choice for a distance function 
\begin_inset Formula $d(\boldsymbol{x},\boldsymbol{y})$
\end_inset

.
 If 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 are vectors consisting of numbers, the Euclidean distance could for instance
 be used, which may or may not be a good choice.
 In other cases the Euclidean distance measure cannot be used directly on
 the samples, if the sample for instance represents a DNA sequence, which
 does not have a clear numerical representation.
 Attention also has to be paid to the cost of evaluating 
\begin_inset Formula $d(\boldsymbol{x},\boldsymbol{y})$
\end_inset

.
 The samples can contain large amount of data, again think of a DNA sequence
 as an example.
\end_layout

\begin_layout Standard
If we cannot find a suitable distance measure that works directly on the
 samples, or if it would be computationally intractable to evaluate such
 a distance function, we can instead focus on summary statistics for the
 sample.
 Let 
\begin_inset Formula $\mathrm{S}(\boldsymbol{x})$
\end_inset

 denote the possibly vector valued summary statistic we have chosen for
 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

.
 The main point is that we assume 
\begin_inset Formula $dim(S(\boldsymbol{x}))<dim(\boldsymbol{x})$
\end_inset

 holds, and so it should be computationally cheaper to evaluate 
\begin_inset Formula $d(S(\boldsymbol{x}),S(\boldsymbol{y}))$
\end_inset

.
 Also note that the reduction in dimension in practice renders the probability
 that 
\begin_inset Formula $S(\boldsymbol{x})=S(\boldsymbol{y})$
\end_inset

 greater than that of 
\begin_inset Formula $\boldsymbol{x}=\boldsymbol{y}.$
\end_inset

 This improves the efficiency of Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:Likelihood-free-sampling"

\end_inset

, but again, probably not to such a degree to make it practically useful.
\end_layout

\begin_layout Standard
Ideally we would want 
\begin_inset Formula $\mathrm{S}(\cdot)$
\end_inset

 to be sufficient for the parameters that are being estimated, since then
 we have the following relation, again letting 
\begin_inset Formula $p(S(\boldsymbol{y})|S(\boldsymbol{x}),\boldsymbol{\theta})$
\end_inset

 be the Dirac-delta function:
\begin_inset Formula 
\begin{align*}
p(\boldsymbol{\theta},S(\boldsymbol{x})|S(\boldsymbol{y})) & \propto p(\boldsymbol{\theta})\int_{S(Y)}p(S(\boldsymbol{y})|S(\boldsymbol{x}),\boldsymbol{\theta})p(S(\boldsymbol{x})|\boldsymbol{\theta})dS(\boldsymbol{x})\\
 & =p(\boldsymbol{\theta})p(S(\boldsymbol{y})|\boldsymbol{\theta})\\
 & \text{by sufficiency}\\
 & =p(\boldsymbol{\theta})p(\boldsymbol{y}|\boldsymbol{\theta})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Several strategies have been developed for dealing with the difficulties
 in ABC: Finding suitable statistics automatically and improving the efficiency,
 being two areas where work has been done.
 See 
\begin_inset CommandInset citation
LatexCommand cite
key "approx_bayes_comp"

\end_inset

 for an overview of areas of research.
\end_layout

\begin_layout Subsection
Choice of summary statistics
\end_layout

\begin_layout Standard
From the above we see that the approximation works when we choose sufficient
 statistics.
 However, in practical problems we are likely to be unable to find sufficient
 statistics.
 Note in passing that if we define our statistic to just be the sample itself,
 
\begin_inset Formula $S(\boldsymbol{y})=\boldsymbol{y}$
\end_inset

, it is a sufficient statistic, but in a practial problem it is unlikely
 we can use the sample directly in this way for the reasons pointed to above.
\end_layout

\begin_layout Standard
Our main focus in this report is however on a computational method for generatin
g samples so that the defined distance between the statistics of the generated
 samples and the observed samples tend to 0 as we progress: 
\begin_inset Formula $d(S(\boldsymbol{x}),S(\boldsymbol{y}))\to0$
\end_inset

.
 We make an assumption that proper statistics have been chosen for the problem
 at hand, and will not have much to say about how this choice has been done.
\end_layout

\begin_layout Standard
Finding proper statistics can be a difficult problem, and it is tied to
 the specific application.
 There is however some research being done in finding good statistics semi-autom
atically, we refer again to the overview article 
\begin_inset CommandInset citation
LatexCommand cite
key "approx_bayes_comp"

\end_inset

 for more information.
 To give a little flavour of an approach that tries to generate statistics
 without being tied to a specific application, we mention the one developed
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "RePEc:bla:jorssb:v:74:y:2012:i:3:p:419-474"

\end_inset

, which also includes some general information about the problem of finding
 summary statistics, generates a large number of statistics on the simulated
 data, for instance one summary statistic may be: 
\begin_inset Formula $S(\boldsymbol{x})=[\boldsymbol{x},\boldsymbol{x}^{2},\boldsymbol{x}^{3},\boldsymbol{x}^{4}]$
\end_inset

.
 Where 
\begin_inset Formula $\boldsymbol{x}^{2}$
\end_inset

 is interpreted to mean all datapoints in 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

 in the second power, and so on.
 Then these summary statistics are regressed on the the simulated parameter
 
\begin_inset Formula $\tilde{\boldsymbol{\theta}}$
\end_inset

, that was used as basis for generating the sample set.
 The regression gives provides an estimate of 
\begin_inset Formula $\mathrm{E}(\boldsymbol{\theta}|\boldsymbol{x})$
\end_inset

.
 A large number of, randomly if wanted, summary statistics can be generated
 an be part of the regression, and the ones that best help explain 
\begin_inset Formula $\tilde{\boldsymbol{\theta}}$
\end_inset

, will be given the highest weight.
\end_layout

\begin_layout Standard
But in practice the norm is that the statistics are chosen by a domain expert,
 say a evolutionary biologist when the problem revolves around the spread
 of genes in a population for instance, and it is not possible to derive
 sound theoretical properties for convergence.
 We give a couple of practical examples below.
 In both cases the model is specified as a stochastic where it is not possible
 to find theoretical expressions for the parameters one wishes to estimate,
 and they are not directly observable from the process output either, so
 ABC-methods are utilized.
\end_layout

\begin_layout Subsubsection
Population estimation
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand citet
key "Toni187"

\end_inset

 provide several examples of ABC-applications.
 One is the problem of estimating rate parameters in a stochastic predator/prey
 model:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{alignat*}{1}
a+X\to2X\;\; & \text{with rate \ensuremath{c_{1}}}\\
X+Y\to2Y\;\; & \text{with rate \ensuremath{c_{2}}}\\
Y\to\emptyset\;\; & \text{with rate \ensuremath{c_{3}}}
\end{alignat*}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $X$
\end_inset

 is the prey population, 
\begin_inset Formula $Y$
\end_inset

 the predator population and where 
\begin_inset Formula $a$
\end_inset

 is a fixed amount of resources available to the prey.
 In the setup described a simulation is run which defines the observed data,
 from this a subset is extracted, so the 
\begin_inset Quotes eld
\end_inset

truth
\begin_inset Quotes erd
\end_inset

 is a collection of 
\begin_inset Formula $n$
\end_inset

 observations of the predator and prey populations at different times, which
 we denote as 
\begin_inset Formula $\{x_{i}^{(obs)},y_{i}^{(obs)}\},i=1,...,n$
\end_inset

.
\end_layout

\begin_layout Standard
An ABC method is then used to try to find the rates used in the first simulation.
 One summary statistic used was the sum of squared errors between the observed
 data and the simulated data:
\begin_inset Formula 
\[
d((\boldsymbol{x},\boldsymbol{y}),(\boldsymbol{x}^{(obs)},\boldsymbol{y}^{(obs)}))=\sum_{i}((x_{i}-x_{i}^{(obs)})^{2}+(y_{i}-y_{i}^{(obs)})^{2})
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Parameter estimation in small world network disease models
\end_layout

\begin_layout Standard
Walker et.
 al.
 
\begin_inset CommandInset citation
LatexCommand citet
key "RePEc:eee:phsmap:v:389:y:2010:i:3:p:540-548"

\end_inset

 used ABC-methods to estimate the parameters in what is called a small world
 network disease model fitted to data from the SARS virus outbreak in Hong
 Kong in 2013.
 The model can be viewed as a network, with nodes representing individuals.
 The parameters of the model are the probabilities of an individual infecting
 a neighbour in the network, there are both short range and long range neighbour
s, the probability of an exposed individual becoming infectious, the probability
 of an infectious individual either recovering or expiring, and the mean
 number of connections for a node.
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[node distance=2cm,auto,>=latex'] 
\end_layout

\begin_layout Plain Layout


\backslash
node[draw, circle] (a) {S}; 
\end_layout

\begin_layout Plain Layout


\backslash
node[draw, circle] (b) [right of=a] {P}; 
\end_layout

\begin_layout Plain Layout


\backslash
path[->] (a) edge node[below] {$p_{1},p_{2}$} node [above] {$
\backslash
mu$}(b);
\end_layout

\begin_layout Plain Layout


\backslash
node[draw, circle] (c) [below of=b] {I};
\end_layout

\begin_layout Plain Layout


\backslash
path[->] (b) edge  node {$r_0$} (c);
\end_layout

\begin_layout Plain Layout


\backslash
node[draw, circle] (d) [right of=c] {R};
\end_layout

\begin_layout Plain Layout


\backslash
path[->] (c) edge node {$r_1$} (d);
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
State transitions in infection model.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Given a set of parameters the model can be run as stochastic process, and
 and estimate of the number of newly infected indiviuals per day can be
 extracted.
 Here the statistic used was the Euclidean distance between a moving average
 of the number of newly infected individuals from the model and the same
 moving average from the reported data.
\end_layout

\begin_layout Subsection
MCMC in ABC
\end_layout

\begin_layout Standard
To motivate the development of the Sequential Monte Carlo method later,
 we will quickly show how MCMC can be used in an ABC setting.
 In Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:Markov-Chain-Monte-in-ABC"

\end_inset

 an early method described in 
\begin_inset CommandInset citation
LatexCommand cite
key "Marjoram23122003"

\end_inset

 is outlined.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithmic}
\end_layout

\begin_layout Plain Layout


\backslash
Require $
\backslash
boldsymbol{
\backslash
theta}_{init}, N$
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
State $counter 
\backslash
leftarrow 1$
\end_layout

\begin_layout Plain Layout


\backslash
State $samples 
\backslash
leftarrow array[N]$
\end_layout

\begin_layout Plain Layout


\backslash
State $samples[0] 
\backslash
leftarrow 
\backslash
boldsymbol{
\backslash
theta}_{init}$
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
While{$counter < N$}
\end_layout

\begin_layout Plain Layout


\backslash
State $samples[counter] 
\backslash
leftarrow 
\backslash
mathrm{DoMetropolisHastingsStep}(samples[counter - 1])$
\end_layout

\begin_layout Plain Layout


\backslash
State $counter 
\backslash
leftarrow counter + 1$
\end_layout

\begin_layout Plain Layout


\backslash
EndWhile
\end_layout

\begin_layout Plain Layout


\backslash
newline
\end_layout

\begin_layout Plain Layout


\backslash
Function{DoMetropolisHastingsStep}{$
\backslash
boldsymbol{
\backslash
theta}_ {old}, 
\backslash
boldsymbol{y}, 
\backslash
epsilon$}
\end_layout

\begin_layout Plain Layout


\backslash
While{true}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
State Sample $
\backslash
boldsymbol{
\backslash
theta}_{new}$ from $q(
\backslash
boldsymbol{
\backslash
theta}_ {old}, 
\backslash
boldsymbol{
\backslash
theta}_ {new})$
\end_layout

\begin_layout Plain Layout


\backslash
If{$d(
\backslash
boldsymbol{x}, 
\backslash
boldsymbol{y}) < 
\backslash
epsilon$}
\end_layout

\begin_layout Plain Layout


\backslash
State $ratio 
\backslash
leftarrow 
\backslash
frac{q(
\backslash
boldsymbol{
\backslash
theta}_ {new}, 
\backslash
boldsymbol{
\backslash
theta}_ {old})p(
\backslash
boldsymbol{
\backslash
theta}_{new})}{q(
\backslash
boldsymbol{
\backslash
theta}_ {old}, 
\backslash
boldsymbol{
\backslash
theta}_ {new})p(
\backslash
boldsymbol{
\backslash
theta}_{old})}$
\end_layout

\begin_layout Plain Layout


\backslash
State Sample $u$ from $
\backslash
mathrm{Uniform}(0,1)$
\end_layout

\begin_layout Plain Layout


\backslash
If{$ratio < u$}
\end_layout

\begin_layout Plain Layout


\backslash
State 
\backslash
textbf{return} $
\backslash
boldsymbol{
\backslash
theta}_{new}$
\end_layout

\begin_layout Plain Layout


\backslash
EndIf
\end_layout

\begin_layout Plain Layout


\backslash
EndIf
\end_layout

\begin_layout Plain Layout


\backslash
EndWhile
\end_layout

\begin_layout Plain Layout


\backslash
EndFunction
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Markov Chain Monte Carlo in an ABC setting
\begin_inset CommandInset label
LatexCommand label
name "alg:Markov-Chain-Monte-in-ABC"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
We recognize the Metropolis-Hastings step, but see that is has been modified
 (like a cross between Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:Metropolis-Hastings"

\end_inset

 and Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:Likelihood-free-sampling"

\end_inset

).
 The stationary distribution of the Markov chain is 
\begin_inset Formula $p(\boldsymbol{\theta}|d(\boldsymbol{x},\boldsymbol{y})<\epsilon)$
\end_inset

, which we do not prove here, and this should be close to the posterior
 
\begin_inset Formula $p(\boldsymbol{\theta}|\boldsymbol{y})$
\end_inset

 based on the points in the discussion earlier.
\end_layout

\begin_layout Standard
In the algorithm 
\begin_inset Formula $\epsilon$
\end_inset

 is fixed.
 If it is too large, the approximation will be poor, is it is too low the
 running time of algorithm will become long.
 It is striking a balance between these two considerations, quality of approxima
tion and running time, that is addressed by using SMC methods in ABC.
 Instead of having 
\begin_inset Formula $\epsilon$
\end_inset

 fixed and given at the start, it is decreased throughout the run of the
 algorithm.
\end_layout

\begin_layout Section
Sequential Monte Carlo in an ABC setting
\end_layout

\begin_layout Standard
There exist several examples of how SMC methods are used within ABC, see
 for example 
\begin_inset CommandInset citation
LatexCommand cite
key "Peters2012,Toni187,adaptive_smc_for_abc"

\end_inset

, but we will in the following focus on the algorithm developed in 
\begin_inset CommandInset citation
LatexCommand cite
key "adaptive_smc_for_abc"

\end_inset

, which in turn builds on what is termed an SMC sampler developed in 
\begin_inset CommandInset citation
LatexCommand cite
key "citeulike:637817"

\end_inset

.
 The output in the end is a set of weighted samples, which in turn can be
 used to approximate a sample set from the target distribution in a manner
 similar to what we described in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Sampling-importance-resampling"

\end_inset

.
\end_layout

\begin_layout Subsection
Sequential Markov chain sampler
\end_layout

\begin_layout Standard
Recalling the nominator and denominator from (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:weight_decomposition"

\end_inset

), we see that the weight update iterations in the SMC method we described
 operate on an increasing probability space: 
\begin_inset Formula $x_{1},(x_{2}|x_{1}),(x_{3}|x_{1},x_{2}),...$
\end_inset

.
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
Unclear notation
\end_layout

\end_inset

 The SMC sampler developed in 
\begin_inset CommandInset citation
LatexCommand cite
key "citeulike:637817"

\end_inset

 instead operates on the same probability space through all the weight updates.
 This will be a key point later, since our the sequence of approximations
 we use in the ABC SMC method to be developed are defined on the same space,
 so we need this property of the sampler.
 
\end_layout

\begin_layout Standard
Also note that since the SMC sampler uses the same probability space at
 each step, we cannot use the decomposition shown in (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:weight_decomposition"

\end_inset

) right out of the box, since it implies that the probability space increases
 in dimension at each step.
\end_layout

\begin_layout Standard
Nevertheless, we still want to decompose the problem of drawing samples
 from 
\begin_inset Formula $p(\boldsymbol{x})$
\end_inset

 somehow.
 To do this we again start by defining a sequence of better and better approxima
te distributions to 
\begin_inset Formula $p(\boldsymbol{x})$
\end_inset

: 
\begin_inset Formula $\{p_{i}(\boldsymbol{x})\}_{i\in1,...,n}$
\end_inset

, and the the corresponding proposal distributions are denoted similarly
 
\begin_inset Formula $\{g_{i}(\boldsymbol{x})\}_{i\in1,...,n}$
\end_inset

.
 The idea developed in 
\begin_inset CommandInset citation
LatexCommand cite
key "citeulike:637817"

\end_inset

 uses a Markov kernel to establish the proposal distribution at step 
\begin_inset Formula $i$
\end_inset

:
\begin_inset Formula 
\[
g_{i}(\boldsymbol{x}|\boldsymbol{x}')=K(\boldsymbol{x}',\boldsymbol{x})
\]

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $\boldsymbol{x}'$
\end_inset

 is distributed according to 
\begin_inset Formula $g_{i-1}(\boldsymbol{x}')$
\end_inset

.
 The marginal distribution 
\begin_inset Formula $g_{i}(\boldsymbol{x})$
\end_inset

 is given as:
\begin_inset Formula 
\begin{equation}
g_{i}(\boldsymbol{x})=\int K(\boldsymbol{x}',\boldsymbol{x})g_{i-1}(\boldsymbol{x}\text{'})d\boldsymbol{x}'\label{eq:kernel_update}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Note that we need this marginal distribution, since the decomposition in
 (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:weight_decomposition"

\end_inset

) is unavailable to us.
 The rationale behind the use of a kernel, is that as the target distribution
 evolves from one step to the next, it should be possible for us to use
 the particles at step 
\begin_inset Formula $i-1$
\end_inset

 to make a good approximation to the target at step 
\begin_inset Formula $i$
\end_inset

.
 However the integral in (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:kernel_update"

\end_inset

) turns out to be impossible to compute in most cases.
 
\end_layout

\begin_layout Standard
One approach to get around this is to approximate 
\begin_inset Formula $g_{i}(\boldsymbol{x})$
\end_inset

 pointwise:
\begin_inset Formula 
\begin{equation}
g_{i}(\boldsymbol{x})\approx g_{i}^{n}(\boldsymbol{x})=\frac{1}{n}\sum_{j=1}^{n}K(\boldsymbol{X}_{i-1}^{(j)},\boldsymbol{x})\label{eq:update_approximation}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Assuming we use the 
\begin_inset Formula $n$
\end_inset

 particles we are evolving in when doing the weight update above, we need
 to perform 
\begin_inset Formula $n$
\end_inset

 pointwise evaluations of (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:update_approximation"

\end_inset

) for each of the 
\begin_inset Formula $n$
\end_inset

 particles, resulting in a complexity on the order of 
\begin_inset Formula $O(n^{2})$
\end_inset

 for one weight update step.
 This is computationally prohibitive when 
\begin_inset Formula $n$
\end_inset

 is large.
\end_layout

\begin_layout Subsubsection
Use of backward kernel in weight update
\end_layout

\begin_layout Standard
To avoid having to compute (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:update_approximation"

\end_inset

), 
\begin_inset CommandInset citation
LatexCommand cite
key "citeulike:637817"

\end_inset

 proposes to use what they call backward kernels.
 This idea also lets us frame the weight updates in the form we described
 in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Sequential-Importance-Sampling"

\end_inset

.
 The resulting algorithm has complexity 
\begin_inset Formula $O(n)$
\end_inset

 and provides asymptotically consistent estimates 
\begin_inset CommandInset citation
LatexCommand citet
key "citeulike:637817"

\end_inset

.
\end_layout

\begin_layout Standard
The backward kernel is introduced as a part of an approximation to the approxima
tion 
\begin_inset Formula $p_{i}(\boldsymbol{x}_{i})$
\end_inset

 as was described in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Sequential-Importance-Sampling"

\end_inset

, and is defined as follows:
\begin_inset Formula 
\[
\hat{p}_{i}(x_{i}|\boldsymbol{x}_{i-1})=p_{i}(\boldsymbol{x}_{i})\Pi_{t=1}^{i-1}L_{i}(x_{t+1},x_{t})
\]

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $L(x_{i+1},x_{i})$
\end_inset

 is a kernel that gives the probability going from 
\begin_inset Formula $x_{i+1}$
\end_inset

 to 
\begin_inset Formula $x_{i}$
\end_inset

.
 We will return to what this kernel can look like later.
 For the proposal distribution we set up a similar sequence of kernels,
 but here with increasing indices: From 
\begin_inset Formula $x_{i-1}$
\end_inset

 to 
\begin_inset Formula $x_{i}$
\end_inset

:
\begin_inset Formula 
\begin{align*}
g_{i}(x_{i}|\boldsymbol{x}_{i-1}) & =\hat{p}_{i-1}(\boldsymbol{x}_{i-1})K_{i}(\boldsymbol{x}_{i-1},x_{i})\\
 & =\hat{p}_{i-2}(\boldsymbol{x}_{i-2})K_{i-2}(\boldsymbol{x}_{i-2},\boldsymbol{x}_{i-1})K_{i-1}(\boldsymbol{x}_{i-1},x_{i})\\
 & =\hat{p}_{1}(\boldsymbol{x}_{1})\prod_{t=1}^{i-1}K(\boldsymbol{x}_{t},\boldsymbol{x}_{t+1})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Note that these approximations and proposals are not defined in terms of
 marginal distributions, 
\begin_inset Formula $g_{i}(\boldsymbol{x}_{i})$
\end_inset

, but conditional ones, 
\begin_inset Formula $g_{i}(x_{i}|\boldsymbol{x}_{i-1})$
\end_inset

.
\end_layout

\begin_layout Standard
Looking at the weight update we get:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
u_{i}(x_{i}) & =\frac{\hat{p}_{i}(x_{i}|\boldsymbol{x}_{i-1})}{g_{i}(x_{i}|\boldsymbol{x}_{i-1})}\nonumber \\
 & =\frac{p_{i}(\boldsymbol{x}_{i})\Pi_{i=1}^{t-1}L_{i}(\boldsymbol{x}_{t+1},\boldsymbol{x}_{t})}{\hat{p}_{i-1}(\boldsymbol{x}_{i-1})K(\boldsymbol{x}_{i-1},\boldsymbol{x}_{i})}\nonumber \\
 & =\frac{p_{i}(\boldsymbol{x}_{i})\Pi_{t=2}^{i}L_{t}(\boldsymbol{x}_{t},\boldsymbol{x}_{t-1})}{p_{i-1}(\boldsymbol{x}_{t})\Pi_{i=1}^{t-1}K(\boldsymbol{x}_{i-1},\boldsymbol{x}_{i})}\nonumber \\
 & =\frac{p_{i}(\boldsymbol{x}_{i})L_{i}(\boldsymbol{x}_{i},\boldsymbol{x}_{i-1})}{p_{i-1}(\boldsymbol{x}_{i-1})K(\boldsymbol{x}_{i-1},\boldsymbol{x}_{i})}\label{eq:weight_update}
\end{align}

\end_inset


\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
Check indices
\end_layout

\end_inset


\end_layout

\begin_layout Standard
To anchor the recursion at the start we assume that we are able to sample
 perfectly from the first approximation 
\begin_inset Formula $p_{1}(\boldsymbol{x}_{1})$
\end_inset

, so that we can set 
\begin_inset Formula $\hat{p}_{1}(\boldsymbol{x}_{1})=p_{1}(\boldsymbol{x}_{1})$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
w_{2}(x_{2}) & =w_{1}(x_{1})u_{2}(x_{1})\\
 & =\frac{p_{1}(x_{1})}{p_{1}(x_{1})}\frac{p_{2}(x_{2})L(x_{2},x_{1})}{p_{1}(x_{1})K(x_{1},x_{2})}\\
 & =\frac{p_{2}(x_{2})L(x_{2},x_{1})}{p_{1}(x_{1})K(x_{1},x_{2})}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In general the weight at 
\begin_inset Formula $i$
\end_inset

 is:
\begin_inset Formula 
\[
w_{i}(x_{i})=\frac{p_{i}(x_{i})\Pi_{t=2}^{i}L_{t}(x_{t},x_{t-1})}{p_{1}(x_{1})\Pi_{t=1}^{i-1}K(\boldsymbol{x}_{t},\boldsymbol{x}_{t+1})}
\]

\end_inset


\end_layout

\begin_layout Standard
At every step we have a weighted sample from the approximation to the target
 distribution 
\begin_inset Formula $\hat{p}_{i}(x_{i}|\boldsymbol{x}_{i-1})=p_{i}(x_{i})\Pi_{t=2}^{i}L_{t}(x_{t},x_{t-1})$
\end_inset

.
 However, our goal is to have a weighted sample from 
\begin_inset Formula $p_{i}(x_{i})$
\end_inset

, but viewing the expression for the weight on the equivalent form:
\begin_inset Formula 
\[
w_{i}(x_{i})=\frac{p_{i}(x_{i})}{\frac{p_{1}(x_{1})\Pi_{t=1}^{i-1}K(x_{t},\boldsymbol{x}_{t+1})}{\Pi_{t=2}^{i}L_{t}(x_{t},\boldsymbol{x}_{t-1})}}
\]

\end_inset


\end_layout

\begin_layout Standard
We recognize 
\begin_inset Formula $p_{i}(x_{i})$
\end_inset

 as the desired target distribution, and 
\begin_inset Formula $\frac{p_{1}(x_{1})\Pi_{t=1}^{i-1}K(\boldsymbol{x}_{t},\boldsymbol{x}_{t+1})}{\Pi_{t=2}^{i}L_{t}(x_{t},x_{t-1})}$
\end_inset

 as a proposal distribution.
 We now see why the approximation, 
\begin_inset Formula $\hat{p}_{i}(\boldsymbol{x}_{i})$
\end_inset

, to the target distribution had the form it did, and a requirement for
 an approximation distribution to function in this setup is that it has
 the target distribution as a marginal:
\begin_inset Formula 
\[
\int\hat{p}_{i}(x_{i}|\boldsymbol{x}_{i-1})d\boldsymbol{x}_{i-1}=p_{i}(x_{i})
\]

\end_inset


\end_layout

\begin_layout Standard
This requirement is necessary to be able to recover the target distibution,
 and is fulfilled by in our case by the construction of the approximation,
 as can be seen if we look at the integral for an arbitrary backward kernel:
\begin_inset Formula 
\[
\int_{\boldsymbol{X}}L(\boldsymbol{x}_{i},\boldsymbol{x}_{i-1})d\boldsymbol{x}_{i-1}=1
\]

\end_inset


\end_layout

\begin_layout Standard
With these kernels the problem of generating a weight sample can be written
 in the recursive form we described in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Sequential-Importance-Sampling"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Choice of backward kernel
\end_layout

\begin_layout Standard
The backward kernels are essentially arbitrary, but the choice of them will
 affect the efficiency of the computation.
 A desirable property, as mentioned, is that the weights have low variance,
 so we can try to choose a backward kernel that achieves this.
 
\begin_inset CommandInset citation
LatexCommand cite
key "citeulike:637817"

\end_inset

 do just this and show the following result: The sequence of backward kernels
 that minimize the variance of the unnormalized importance weights is given
 by:
\begin_inset Formula 
\begin{equation}
L_{i}(\boldsymbol{x}_{i},\boldsymbol{x}_{i-1})=\frac{g_{i-1}(\boldsymbol{x}_{i-1})K(\boldsymbol{x}_{i-1},\boldsymbol{x}_{i})}{g_{i}(\boldsymbol{x}_{i})}\label{eq:optimal_backward_kernel}
\end{equation}

\end_inset


\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
Check indices
\end_layout

\end_inset


\end_layout

\begin_layout Standard
To prove it consider the conditional variance formula applied to 
\begin_inset Formula $w_{i}(\boldsymbol{X}_{1:i})$
\end_inset

:
\begin_inset Formula 
\[
\mathrm{Var}(w_{i}(\boldsymbol{X}_{1:i}))=\mathrm{E}(\mathrm{Var}(w_{i}(\boldsymbol{X}_{1:i})|\boldsymbol{X}_{i}))+\mathrm{Var}(\mathrm{E}(w_{i}(\boldsymbol{X}_{1:i})|\boldsymbol{X}_{i}))
\]

\end_inset


\end_layout

\begin_layout Standard
We can use this formula since 
\begin_inset Formula $w_{i}(\boldsymbol{X}_{1:i})$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{X}_{i}$
\end_inset

, are defined on the same probability space: Even though 
\begin_inset Formula $\boldsymbol{X}_{1:i}$
\end_inset

 is a sequence of random vectors, the weight at step 
\begin_inset Formula $i$
\end_inset

 is a single random vector.
\end_layout

\begin_layout Standard
A property of conditional expectations is: 
\begin_inset Formula $\mathrm{E}(g(\boldsymbol{Y})\boldsymbol{X}|\boldsymbol{Y})=g(\boldsymbol{Y})\mathrm{E}(\boldsymbol{X}|\boldsymbol{Y})$
\end_inset

, where 
\begin_inset Formula $\boldsymbol{X}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{Y}$
\end_inset

 are random vectors, and 
\begin_inset Formula $g(y)$
\end_inset

 is a function from 
\begin_inset Formula $\mathbb{R}\to\mathbb{R}$
\end_inset

.
 This property also yields the following: 
\begin_inset Formula $\mathrm{E}(g(\boldsymbol{X})|\boldsymbol{X})=g(\boldsymbol{X})$
\end_inset

.
 Applying this, we have for the expectation in the second term:
\begin_inset Formula 
\[
\mathrm{E}(w_{i}(\boldsymbol{X}_{1:i})|\boldsymbol{X}_{i})=w_{i}(\boldsymbol{X}_{i})=\frac{\hat{p}_{i}(\boldsymbol{X}_{i})}{g_{i}(\boldsymbol{X}_{i})}
\]

\end_inset


\end_layout

\begin_layout Standard
Note that this expression does not depend on 
\begin_inset Formula $L_{i}(\boldsymbol{x}_{i},\boldsymbol{x}_{i-1})$
\end_inset

, so the choice of backward kernel does not influence this term.
\end_layout

\begin_layout Standard
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
Check that these distributions have been defined as used here
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
Check that the correct distributions are used here
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Now we turn our attention t 
\begin_inset Formula $\mathrm{Var}(w_{i}(\boldsymbol{X}_{1:i})|\boldsymbol{X}_{i})$
\end_inset

.
 If we insert 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:optimal_backward_kernel"

\end_inset

 into the expression for the weight update in Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:weight_update"

\end_inset

 we get:
\begin_inset Formula 
\[
\frac{p_{i}(\boldsymbol{x}_{i})L_{i}(\boldsymbol{x}_{i},\boldsymbol{x}_{i-1})}{p_{i-1}(\boldsymbol{x}_{i-1})K(\boldsymbol{x}_{i-1},\boldsymbol{x}_{i})}=\frac{p_{i}(\boldsymbol{x}_{i})}{p_{i-1}(\boldsymbol{x}_{i-1})K(\boldsymbol{x}_{i-1},\boldsymbol{x}_{i})}\frac{p_{i-1}(\boldsymbol{x}_{i-1})K(\boldsymbol{x}_{i-1},\boldsymbol{x}_{i})}{p_{i}(\boldsymbol{x}_{i})}=1
\]

\end_inset


\end_layout

\begin_layout Standard
Which is a constant, and so has 0 variance.
 Since this holds for all the weight updates, it also does for 
\begin_inset Formula $w_{i}(\boldsymbol{X}_{1:i})$
\end_inset

, and we have 
\begin_inset Formula $\mathrm{E}(\mathrm{Var}(w_{i}(\boldsymbol{X}_{1:i})|\boldsymbol{X}_{i}))=0$
\end_inset

.
\end_layout

\begin_layout Standard
To compute the optimal kernel we need to compute the distributions 
\begin_inset Formula $p_{i-1}(\boldsymbol{x}_{i-1})$
\end_inset

 and 
\begin_inset Formula $p_{i}(\boldsymbol{x}_{i})$
\end_inset

 which we often cannot do in practice.
 We are thus left to chose a suboptimal kernel, and we will return the question
 of how to chose one later when we describe the actual implementation of
 the SMC sampler.
\end_layout

\begin_layout Subsection
SMC sampler in ABC
\end_layout

\begin_layout Standard
We now follow the work done in 
\begin_inset CommandInset citation
LatexCommand cite
key "adaptive_smc_for_abc"

\end_inset

 and describe how the SMC sampler can be used in an ABC setting.
 Remembering the expression in Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:abc_sampling_distribution"

\end_inset

 for the distribution we are sampling from in ABC, a possible sequence of
 approximations to the true posterior is given by decreasing the distance
 between the observations and drawn samples, that is: Let 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

 be sample and 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 an observation, and define a sequence of decreasing values 
\begin_inset Formula $\epsilon_{1}>\epsilon_{2}>...>\epsilon_{n}$
\end_inset

.
 Let 
\begin_inset Formula $p_{\epsilon_{i}}(\boldsymbol{\theta},\boldsymbol{x}|\boldsymbol{y})$
\end_inset

 denote the distribution such that drawn samples from it lie within 
\begin_inset Formula $\epsilon_{i}$
\end_inset

 from 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, that is: 
\begin_inset Formula $d(\boldsymbol{x},\boldsymbol{y})<\epsilon_{i}$
\end_inset

.
 As 
\begin_inset Formula $\epsilon\to0$
\end_inset

 we expect 
\begin_inset Formula $\boldsymbol{x}\to\boldsymbol{y}$
\end_inset

, and hopefully as a consequence 
\begin_inset Formula $p_{\epsilon}(\boldsymbol{\theta},\boldsymbol{x}|\boldsymbol{y})$
\end_inset

 will converge to a distribution that is proportionalto 
\begin_inset Formula $p(\boldsymbol{\theta}|\boldsymbol{y})$
\end_inset

.
 If we let the likelihood function in 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:abc_sampling_distribution"

\end_inset

 be an indiator function that is 1 if 
\begin_inset Formula $d(\boldsymbol{x},\boldsymbol{y})<\epsilon$
\end_inset

, and 0 else, written 
\begin_inset Formula $I_{\epsilon,\boldsymbol{y}}(\boldsymbol{x})$
\end_inset

, these assumptions hold, that is: 
\begin_inset Formula 
\begin{align*}
\lim_{\epsilon\to0}p_{\epsilon}(\boldsymbol{\theta},\boldsymbol{x}|\boldsymbol{y}) & \propto\lim_{\epsilon\to0}I_{\epsilon,\boldsymbol{y}}(\boldsymbol{x})p(\boldsymbol{x}|\boldsymbol{\theta})p(\boldsymbol{\theta})\\
 & =p(\boldsymbol{y}|\boldsymbol{\theta})p(\boldsymbol{\theta})\\
 & \propto p(\boldsymbol{\theta}|\boldsymbol{y})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Using this sequence, 
\begin_inset Formula $p_{\epsilon_{i}}(\boldsymbol{\theta},\boldsymbol{x}|\boldsymbol{y})$
\end_inset

, as approximations to the target distribution, we are left with the tasks
 of specifying forward and backward kernels, and a schedule for updating
 the cutoff distances 
\begin_inset Formula $\epsilon_{i}$
\end_inset

.
\end_layout

\begin_layout Subsubsection
Use of multiple particles for each sample of 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "adaptive_smc_for_abc"

\end_inset

 use an MCMC kernel for 
\begin_inset Formula $K(x_{t},\boldsymbol{x}_{t+1})$
\end_inset

 in the weight update step, but before describing it we need to introduce
 one change to the above.
 Instead of having only one sample 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

, and parameter value 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

, drawn from 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $p_{\epsilon}(\boldsymbol{\theta},\boldsymbol{x}|\boldsymbol{y})$
\end_inset

, a number of independent samples are drawn.
 Let 
\begin_inset Formula $\{\boldsymbol{x}\}_{1:m}$
\end_inset

 denote 
\begin_inset Formula $m$
\end_inset

 samples that are independent given 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

.
 This modified proposal distribution is written as:
\begin_inset Formula 
\[
p_{\epsilon}(\boldsymbol{\theta},\{\boldsymbol{x}\}_{1:m}|\boldsymbol{y})
\]

\end_inset


\end_layout

\begin_layout Standard
The reason for introducing this as a proposal distribution is to reduce
 the variance of the Metropolis-Hastings ratio we will encounter in the
 next section, which in turn increases its performance
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
How is the performance increased?
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
The question is now whether this new proposal distribution is valid.
 We claim that the marginals for 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 in 
\begin_inset Formula $p_{\epsilon}(\boldsymbol{\theta},\{\boldsymbol{x}\}_{1:m}|\boldsymbol{y})$
\end_inset

 are equal up to a constant for any integer 
\begin_inset Formula $m>0$
\end_inset

.
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
Prove the claim?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
p_{\epsilon}(\boldsymbol{\theta},\{\boldsymbol{x}\}_{1:m}|\boldsymbol{y}) & \propto p(\boldsymbol{y}|\boldsymbol{\theta},\{\boldsymbol{x}\}_{1:m})p(\{\boldsymbol{x}\}_{1:m}|\boldsymbol{\theta})p(\boldsymbol{\theta})
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection
Proposal density with equal marginal likelihood for 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset


\end_layout

\begin_layout Standard
To motivate the proposal distribution in the next section we need to establish
 a result: That 
\begin_inset Formula $p_{\epsilon}(\boldsymbol{\theta},\{\boldsymbol{x}\}_{1:m}|\boldsymbol{y})$
\end_inset

 and 
\begin_inset Formula $(\frac{1}{m}\sum_{i=1}^{m}I_{\epsilon,\boldsymbol{y}}(\boldsymbol{x}_{i}))(\prod_{i=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}))p(\boldsymbol{\theta})$
\end_inset

 have the same marginals, up to a constant, for 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

.
 Remember that it is this marginal distribution that we are interested in,
 since it is an approximation to the posterior.
\end_layout

\begin_layout Standard
To show the equivalence for the two distributions, we follow 
\begin_inset CommandInset citation
LatexCommand cite
key "Beaumont1139"

\end_inset

 and start by calculating the marginal for 
\begin_inset Formula $(\frac{1}{m}\sum_{i=1}^{m}I_{\epsilon,\boldsymbol{y}}(\boldsymbol{x}_{i}))(\prod_{i=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}))p(\boldsymbol{\theta})$
\end_inset

, by in
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
tegrating out all the 
\begin_inset Formula $\boldsymbol{x}_{i}$
\end_inset

's:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\int...\int & \sum_{i=1}^{m}I_{\epsilon,y}(\boldsymbol{x}_{i})\prod_{i=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta})p(\boldsymbol{\theta})d\boldsymbol{x}_{1}...d\boldsymbol{x}_{m}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Let us extract 
\begin_inset Formula $i=1$
\end_inset

 from the sum above and look at the expression:
\begin_inset Formula 
\begin{align*}
\int...\int & I_{\epsilon,y}(\boldsymbol{x}_{i})\prod_{i=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta})p(\boldsymbol{\theta})d\boldsymbol{x}_{1}...d\boldsymbol{x}_{m}=\\
 & p(\boldsymbol{\theta})\int...\int I_{\epsilon,y}(\boldsymbol{x}_{1})\prod_{i=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta})d\boldsymbol{x}_{1}...d\boldsymbol{x}_{m}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
For the part of the integral where 
\begin_inset Formula $i=1$
\end_inset

 we get:
\begin_inset Formula 
\begin{align*}
p(\boldsymbol{\theta})\int I_{\epsilon,y}(\boldsymbol{x}_{1})\prod_{i=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta})d\boldsymbol{x}_{1} & =\\
p(\boldsymbol{\theta})\int I_{\epsilon,y}(\boldsymbol{x}_{1})p(\boldsymbol{x}_{1}|\boldsymbol{\theta})d\boldsymbol{x}_{1}\prod_{i=2}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}) & =\\
\text{by the definition of our likelihood} & \text{}\\
p_{\epsilon}(\boldsymbol{y}|\boldsymbol{\theta})\prod_{i=2}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $j\neq1$
\end_inset

 we get:
\begin_inset Formula 
\begin{align*}
p(\boldsymbol{\theta})\int p(\boldsymbol{x}_{2}|\boldsymbol{\theta})d\boldsymbol{x}_{2} & =\\
\mathrm{c}p(\boldsymbol{\theta})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Putting it all together we have:
\begin_inset Formula 
\begin{align*}
\int...\int & \sum_{i=1}^{m}I_{\epsilon,y}(\boldsymbol{x}_{i})\prod_{i=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta})p(\boldsymbol{\theta})d\boldsymbol{x}_{1}...d\boldsymbol{x}_{m}=\\
 & \mathrm{c}_{2}mp_{\epsilon}(\boldsymbol{y}|\boldsymbol{\theta})p(\boldsymbol{\theta})\propto\\
 & p_{\epsilon}(\boldsymbol{\theta}|\boldsymbol{y})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
So viewing it from the perspective of the marginal of 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 we can write:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
p_{\epsilon}(\boldsymbol{\theta},\{\boldsymbol{x}\}_{1:m}|\boldsymbol{y})\propto(\frac{1}{m}\sum_{i=1}^{m}I_{\epsilon,\boldsymbol{y}}(\boldsymbol{x}_{i}))(\prod_{i=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}))p(\boldsymbol{\theta})\label{eq:proportional_distributions}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
And our proposition is proved.
\end_layout

\begin_layout Subsubsection
Choice of kernel
\end_layout

\begin_layout Standard
Following 
\begin_inset CommandInset citation
LatexCommand cite
key "adaptive_smc_for_abc"

\end_inset

 the kernel uses a Metropolis-Hastings (MH) step to achieve the desired
 invariant density.
 To show the form of the kernel we start by defining a proposal distribution:
\begin_inset Formula 
\[
q_{i}(\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{i+1})\prod_{j=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}_{i+1})
\]

\end_inset


\end_layout

\begin_layout Standard
The MH-ratio term is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\alpha(i,i+1)=\min\left(1,\frac{p_{\epsilon}(\boldsymbol{\theta}_{i+1},\{\boldsymbol{x}_{i+1}\}_{1:m}|\boldsymbol{y})q_{i+1}(\boldsymbol{\theta}_{i+1},\boldsymbol{\theta}_{i})\prod_{j=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}_{i})}{p_{\epsilon}(\boldsymbol{\theta}_{i},\{\boldsymbol{x}_{i}\}_{1:m}|\boldsymbol{y})q_{i}(\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{i+1})\prod_{j=1}^{m}p(\boldsymbol{x}_{i+1}|\boldsymbol{\theta}_{i+1})}\right)\label{eq:mh-ratio}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
We now the invariant density, 
\begin_inset Formula $p_{\epsilon_{i}}(\boldsymbol{\theta},\boldsymbol{x}_{1:m}|\boldsymbol{y})$
\end_inset

, and the proposal density, and from those we can determine what the Markov
 chain update probability must look like: 
\begin_inset Formula 
\[
P(i,i+1)=q_{i}(\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{i+1})\prod_{j=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}_{i+1})\alpha(i,i+1)
\]

\end_inset

We check our suggestion for the update probability by showing that the detailed
 balance equation is fulfilled:
\begin_inset Formula 
\[
p_{\epsilon}(\boldsymbol{\theta}_{i},\{\boldsymbol{x}_{i}\}_{1:m}|\boldsymbol{y})P(i,i+1)=p_{\epsilon}(\boldsymbol{\theta}_{i+1},\{\boldsymbol{x}_{i+1}\}_{1:m}|\boldsymbol{y})P(i+1,i)
\]

\end_inset


\end_layout

\begin_layout Standard
Expanding 
\begin_inset Formula $P(i,i+1)$
\end_inset

 we get:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
p_{\epsilon}(\boldsymbol{\theta}_{i},\{\boldsymbol{x}_{i}\}_{1:m}|\boldsymbol{y})q_{i}(\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{i+1})\prod_{j=1}^{m}p(\boldsymbol{x}_{i+1}|\boldsymbol{\theta}_{i+1}) & \alpha(i,i+1)=\\
p_{\epsilon}(\boldsymbol{\theta}_{i+1},\{\boldsymbol{x}_{i+1}\}_{1:m}|\boldsymbol{y})q_{i+1}(\boldsymbol{\theta}_{i+1},\boldsymbol{\theta}_{i})\prod_{j=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}_{i})\alpha(i+1,i)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
If 
\begin_inset Formula $\alpha(i,i+1)=1$
\end_inset

, then 
\begin_inset Formula $\alpha(i+1,i)=\frac{p_{\epsilon}(\boldsymbol{\theta}_{i},\{\boldsymbol{x}_{i}\}_{1:m}|\boldsymbol{y})q_{i}(\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{i+1})\prod_{j=1}^{m}p(\boldsymbol{x}_{i+1}|\boldsymbol{\theta}_{i+1})}{p_{\epsilon}(\boldsymbol{\theta}_{i+1},\{\boldsymbol{x}_{i+1}\}_{1:m}|\boldsymbol{y})q_{i+1}(\boldsymbol{\theta}_{i+1},\boldsymbol{\theta}_{i})\prod_{j=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}_{i})}<1$
\end_inset

, 
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
Also check when it is equal to 1
\end_layout

\end_inset

 and we have:
\begin_inset Formula 
\begin{align*}
p_{\epsilon}(\boldsymbol{\theta}_{i},\{\boldsymbol{x}_{i}\}_{1:m}|\boldsymbol{y})q_{i}(\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{i+1})\prod_{j=1}^{m}p(\boldsymbol{x}_{i+1}|\boldsymbol{\theta}_{i+1}) & =\\
p_{\epsilon}(\boldsymbol{\theta}_{i+1},\{\boldsymbol{x}_{i+1}\}_{1:m}|\boldsymbol{y})q_{i+1}(\boldsymbol{\theta}_{i+1},\boldsymbol{\theta}_{i})\prod_{j=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}_{i})\frac{p_{\epsilon}(\boldsymbol{\theta}_{i},\{\boldsymbol{x}_{i}\}_{1:m}|\boldsymbol{y})q_{i}(\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{i+1})\prod_{j=1}^{m}p(\boldsymbol{x}_{i+1}|\boldsymbol{\theta}_{i+1})}{p_{\epsilon}(\boldsymbol{\theta}_{i+1},\{\boldsymbol{x}_{i+1}\}_{1:m}|\boldsymbol{y})q_{i+1}(\boldsymbol{\theta}_{i+1},\boldsymbol{\theta}_{i})\prod_{j=1}^{m}p(\boldsymbol{x}_{i}|\boldsymbol{\theta}_{i})} & =\\
p_{\epsilon}(\boldsymbol{\theta}_{i+1},\{\boldsymbol{x}_{i+1}\}_{1:m}|\boldsymbol{y})p_{\epsilon}(\boldsymbol{\theta}_{i},\{\boldsymbol{x}_{i}\}_{1:m}|\boldsymbol{y})q_{i}(\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{i+1})\prod_{j=1}^{m}p(\boldsymbol{x}_{i+1}|\boldsymbol{\theta}_{i+1})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Similarly when 
\begin_inset Formula $\alpha(i+1,i)=1$
\end_inset

.
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
Write more about conditions
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Metropolis-Hastings ratio without likelihood
\end_layout

\begin_layout Standard
The likelihood function, 
\begin_inset Formula $p(\boldsymbol{\boldsymbol{x}}|\boldsymbol{\theta})$
\end_inset

, appears in the Metropolis-Hastings ratio above, but we cannot evaluate
 it.
 It is here we can use the result in Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:proportional_distributions"

\end_inset

, by replacing the MH-ratio with an equivalent one:
\begin_inset Formula 
\begin{multline*}
\min\left(\frac{p_{\epsilon}(\boldsymbol{\theta}_{i+1},\{\boldsymbol{x}_{i+1}\}_{1:m}|\boldsymbol{y})q_{i+1}(\boldsymbol{\theta}_{i+1},\boldsymbol{\theta}_{i})\prod_{j=1}^{m}p(\boldsymbol{x}_{i}^{(j)}|\boldsymbol{\theta}_{i})}{p_{\epsilon}(\boldsymbol{\theta}_{i},\{\boldsymbol{x}_{i}\}_{1:m}|\boldsymbol{y})q_{i}(\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{i+1})\prod_{j=1}^{m}p(\boldsymbol{x}_{i+1}^{(j)}|\boldsymbol{\theta}_{i+1})}\right)=\\
\text{insert expression from \ref{eq:proportional_distributions}}\\
\min\left(\frac{(\frac{1}{m}\sum_{j=1}^{m}I_{\epsilon,\boldsymbol{y}}(\boldsymbol{x}_{i+1}))(\prod_{j=1}^{m}p(\boldsymbol{x}_{i+1}^{(j)}|\boldsymbol{\theta}_{i+1}))p(\boldsymbol{\theta}_{i+1})q_{i+1}(\boldsymbol{\theta}_{i+1},\boldsymbol{\theta}_{i})\prod_{j=1}^{m}p(\boldsymbol{x}_{i}^{(j)}|\boldsymbol{\theta}_{i})}{(\frac{1}{m}\sum_{j=1}^{m}I_{\epsilon,\boldsymbol{y}}(\boldsymbol{x}_{i}^{(j)}))(\prod_{j=1}^{m}p(\boldsymbol{x}_{i}^{(j)}|\boldsymbol{\theta}))p(\boldsymbol{\theta})q_{i}(\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{i+1})\prod_{j=1}^{m}p(\boldsymbol{x}_{i+1}^{(j)}|\boldsymbol{\theta}_{i+1})}\right)=\\
\min\left(1,\frac{\sum_{j=1}^{m}\mathrm{I}_{\epsilon_{i},y}(\boldsymbol{x}_{i+1}^{(j)})q_{i}(\boldsymbol{\theta}_{i+1},\boldsymbol{\theta})p(\boldsymbol{\theta}_{i+1})}{\sum_{j=1}^{m}\mathrm{I}_{\epsilon_{i},y}(\boldsymbol{x}_{i}^{(j)})q_{i}(\boldsymbol{\theta},\boldsymbol{\theta}_{i+1})p(\boldsymbol{\theta})}\right)
\end{multline*}

\end_inset


\end_layout

\begin_layout Standard
Intuitively we can see what the ratio is doing: If more of the samples generated
 at step 
\begin_inset Formula $i+1$
\end_inset

 lie within 
\begin_inset Formula $\epsilon_{i}$
\end_inset

 of 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 than the ones generated at step 
\begin_inset Formula $i$
\end_inset

, the update will be accepted.
 If fewer particles lie within this radius, there is less of a chance of
 the update being accepted.
\end_layout

\begin_layout Standard
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
Expression for variance of theta
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Algorithm
\begin_inset CommandInset label
LatexCommand label
name "sub:Algorithm"

\end_inset


\end_layout

\begin_layout Standard
Using a kernel function on the form described, the full algorithm looks
 as the pseduo-code given in 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:SMC-in-ABC"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
Transition to how this is implemented in the code example
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithmic}
\end_layout

\begin_layout Plain Layout


\backslash
Require $
\backslash
epsilon_{stop},
\backslash
alpha,
\backslash
beta,N$
\end_layout

\begin_layout Plain Layout


\backslash
State $
\backslash
epsilon 
\backslash
leftarrow 
\backslash
infty$
\end_layout

\begin_layout Plain Layout


\backslash
State $ess 
\backslash
leftarrow N$
\end_layout

\begin_layout Plain Layout


\backslash
State $
\backslash
boldsymbol{
\backslash
theta}_{n} 
\backslash
leftarrow$ $N$ samples from $p(
\backslash
boldsymbol{
\backslash
theta})$
\end_layout

\begin_layout Plain Layout


\backslash
State $particles 
\backslash
leftarrow $ $N$ samples from $p(
\backslash
boldsymbol{x}|
\backslash
boldsymbol{
\backslash
theta})$
\end_layout

\begin_layout Plain Layout


\backslash
State $
\backslash
boldsymbol{W}_{n}
\backslash
leftarrow [
\backslash
frac{1}{N},...,
\backslash
frac{1}{N}]$
\end_layout

\begin_layout Plain Layout


\backslash
While{$
\backslash
epsilon 
\backslash
geq 
\backslash
epsilon_{stop}$}
\end_layout

\begin_layout Plain Layout


\backslash
State $
\backslash
epsilon 
\backslash
leftarrow FindNextEpsilon(
\backslash
epsilon,
\backslash
boldsymbol{W}_{n})$
\end_layout

\begin_layout Plain Layout


\backslash
If{$ess < 
\backslash
beta N$}
\end_layout

\begin_layout Plain Layout


\backslash
State $(
\backslash
boldsymbol{
\backslash
theta}, particles) 
\backslash
leftarrow 
\backslash
mathrm{Resample}$
\backslash
Comment{Resampling}
\end_layout

\begin_layout Plain Layout


\backslash
EndIf
\end_layout

\begin_layout Plain Layout


\backslash
For{$i
\backslash
leftarrow[1,..,N]$}
\end_layout

\begin_layout Plain Layout


\backslash
State $(
\backslash
boldsymbol{
\backslash
theta}_{n}^{(i)}, particles^{(i)})
\backslash
leftarrow 
\backslash
mathrm{Mutate}(
\backslash
epsilon, particles^{(i)}, W_{n-1}^{(i)}, 
\backslash
boldsymbol{
\backslash
theta}^{(i)})$
\end_layout

\begin_layout Plain Layout


\backslash
EndFor
\end_layout

\begin_layout Plain Layout


\backslash
EndWhile
\end_layout

\begin_layout Plain Layout


\backslash
newline
\end_layout

\begin_layout Plain Layout


\backslash
Function{ESS}{$
\backslash
boldsymbol{W_{n}}$}
\end_layout

\begin_layout Plain Layout


\backslash
State 
\backslash
textbf{return} $(
\backslash
sum_{i=1}^{N}W_{n}^{(i)})^{-1}$
\end_layout

\begin_layout Plain Layout


\backslash
EndFunction
\end_layout

\begin_layout Plain Layout


\backslash
newline
\end_layout

\begin_layout Plain Layout


\backslash
Function{FindNextEpsilon}{$
\backslash
epsilon_{n-1},
\backslash
boldsymbol{w_{n-1}}$} 
\end_layout

\begin_layout Plain Layout


\backslash
State Solve $ESS(
\backslash
frac{I_{
\backslash
epsilon_{n}}(
\backslash
boldsymbol{x}_{k})}{I_{
\backslash
epsilon_{n-1}}(
\backslash
boldsymbol{x}_{k})})=
\backslash
alpha ESS(
\backslash
boldsymbol{w_{n-1}})$ for $
\backslash
epsilon_{n}$
\end_layout

\begin_layout Plain Layout


\backslash
State 
\backslash
textbf{return} $
\backslash
epsilon_{n}$
\end_layout

\begin_layout Plain Layout


\backslash
EndFunction
\end_layout

\begin_layout Plain Layout


\backslash
newline
\end_layout

\begin_layout Plain Layout


\backslash
Function{Mutate}{$
\backslash
epsilon,particle,
\backslash
boldsymbol{w},
\backslash
boldsymbol{
\backslash
theta}_{old}$}
\end_layout

\begin_layout Plain Layout


\backslash
State $
\backslash
boldsymbol{
\backslash
theta}_{new} 
\backslash
leftarrow$ Sample from $q(
\backslash
boldsymbol{
\backslash
theta}|
\backslash
boldsymbol{
\backslash
theta}_{old})$
\end_layout

\begin_layout Plain Layout


\backslash
State $particle_{new} 
\backslash
leftarrow$ Sample from $p(
\backslash
boldsymbol{x}|
\backslash
boldsymbol{
\backslash
theta}_{new})$
\end_layout

\begin_layout Plain Layout


\backslash
State $r 
\backslash
leftarrow 
\backslash
min(1,
\backslash
frac{I_{
\backslash
epsilon_{n}}(particle_{new})}{I_{
\backslash
epsilon_{n}}(particle)})$
\end_layout

\begin_layout Plain Layout


\backslash
If{$r < $ Sample from $Uniform(0, 1)$}
\backslash
Comment{Metropolis-Hastings step}
\end_layout

\begin_layout Plain Layout


\backslash
State 
\backslash
textbf{return} $(
\backslash
boldsymbol{
\backslash
theta},particle)$
\end_layout

\begin_layout Plain Layout


\backslash
Else
\end_layout

\begin_layout Plain Layout


\backslash
State 
\backslash
textbf{return} $(
\backslash
boldsymbol{
\backslash
theta}_{new},particle_{new})$
\end_layout

\begin_layout Plain Layout


\backslash
EndIf
\end_layout

\begin_layout Plain Layout


\backslash
EndFunction
\end_layout

\begin_layout Plain Layout


\backslash
newline
\end_layout

\begin_layout Plain Layout


\backslash
Function{Resample}{$
\backslash
boldsymbol{
\backslash
theta}, particles, 
\backslash
boldsymbol{w}$, N}
\end_layout

\begin_layout Plain Layout


\backslash
State Sample indices from a multinomial distribution $f(x_{1},...x_{N};N,w_{1},...,w_{
N})$
\end_layout

\begin_layout Plain Layout


\backslash
State 
\backslash
textbf{return} $(
\backslash
theta_{1}^{(1)},...,
\backslash
theta_{1}^{(x_{1})},...,
\backslash
theta_{N}^{(1)},...,
\backslash
theta_{N}^{(x_{N})},particles_{1}^{(1)},...,particles_{N}^{(x_{N})})$
\end_layout

\begin_layout Plain Layout


\backslash
EndFunction
\end_layout

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
SMC in ABC
\begin_inset CommandInset label
LatexCommand label
name "alg:SMC-in-ABC"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Most of the running time will be spent on generating samples.
\end_layout

\begin_layout Subsubsection
Resampling schedule
\end_layout

\begin_layout Standard
In Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:SMC-in-ABC"

\end_inset

 we have used the same update strategy as in 
\begin_inset CommandInset citation
LatexCommand cite
key "adaptive_smc_for_abc"

\end_inset

.
 At each iteration the following equation is solved for 
\begin_inset Formula $\epsilon_{n}$
\end_inset

:
\begin_inset Formula 
\begin{equation}
\mathrm{ESS}(\boldsymbol{w}_{n})=\alpha\mathrm{ESS}(\boldsymbol{w}_{n-1})\label{eq:ess_update}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $\alpha\in(0,1)$
\end_inset

 is some given constant that will be explained later.
 The dependency on 
\begin_inset Formula $\epsilon_{n}$
\end_inset

 shows up if we expand the expression for how we calculate 
\begin_inset Formula $\boldsymbol{w}_{n}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\boldsymbol{w}_{n}=\boldsymbol{w}_{n-1}\frac{\sum_{i=1}^{m}\mathrm{I}_{\epsilon_{n}}(\boldsymbol{x}_{n-1}^{(i)})}{\sum_{i=1}^{m}\mathrm{I}_{\epsilon_{n-1}}(\boldsymbol{x}_{n-1}^{(i)})}
\]

\end_inset


\end_layout

\begin_layout Standard
Where each particle has 
\begin_inset Formula $m$
\end_inset

 replicates.
 As a function of 
\begin_inset Formula $\epsilon_{n}$
\end_inset

 it is not continuous, so we cannot solve 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ess_update"

\end_inset

 by finding the derivative, and it is not certain that an exact solution
 exists for all 
\begin_inset Formula $\epsilon_{n}$
\end_inset

.
 So in practice an approximate solution is found using some numerical method.
 In our implementation the bisection method is used.
\end_layout

\begin_layout Standard
The idea behind 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ess_update"

\end_inset

 is to find a 
\begin_inset Formula $\epsilon_{n}$
\end_inset

 so that we make reasonable progress towards 0.
 Remember that we would like 
\begin_inset Formula $\epsilon_{n}\to0$
\end_inset

 as 
\begin_inset Formula $n$
\end_inset

 increases to get a better and better approximation to the distribution.
 The other concern when updating 
\begin_inset Formula $\epsilon_{n}$
\end_inset

 is to avoid taking a too big step so that algorithm collapses.
 We see that all the weights can collapse to 0 if the step is too big.
\end_layout

\begin_layout Standard
To control the update schedule, the parameter 
\begin_inset Formula $\alpha$
\end_inset

 is given as input to the algorithm.
 A small 
\begin_inset Formula $\alpha$
\end_inset

 favours taking large steps, which means rapid progress towards 0, and hence
 quicker overall computation, but at the danger of the algorithm collapsing,
 and even if it does not, the final approximation may be bad.
 A large 
\begin_inset Formula $\alpha$
\end_inset

 works in the opposition direction: The final approximation is good, with
 the caveat that the statistics we have chosen actually gives a good approximati
on to the distribution when 
\begin_inset Formula $\epsilon_{n}\to0$
\end_inset

.
 The downside is that the approximation progresses more slowly.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
FloatBarrier
\end_layout

\end_inset


\end_layout

\begin_layout Section
Examples
\end_layout

\begin_layout Standard
We provide an implementation of the algorithm in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Algorithm"

\end_inset

in R, and illustrate it on two simple examples.
 
\end_layout

\begin_layout Subsection
Estimating expected value in simple mixture model
\end_layout

\begin_layout Standard
This example is used in both 
\begin_inset CommandInset citation
LatexCommand cite
key "adaptive_smc_for_abc"

\end_inset

, 
\begin_inset CommandInset citation
LatexCommand cite
key "Beaumont12102009"

\end_inset

 and 
\begin_inset CommandInset citation
LatexCommand cite
key "Sisson06022007"

\end_inset

.
 The distribution we wish to create a sample set from is given as follows,
 first the likelihood is specified as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(x|\theta)\sim\frac{1}{2}\mathrm{N}(\theta,1)+\frac{1}{2}\mathrm{N}(\theta,\frac{1}{100})
\]

\end_inset


\end_layout

\begin_layout Standard
The parameter 
\begin_inset Formula $\theta$
\end_inset

 is assumed to be uniform on the interval 
\begin_inset Formula $[-10,10]$
\end_inset

, and the posterior then has the form:
\begin_inset Formula 
\[
p(\theta|x)\sim(\mathrm{N}(\theta,1)+\mathrm{N}(\theta,\frac{1}{100}))\mathrm{I}_{[-10,10]}(\theta)
\]

\end_inset


\end_layout

\begin_layout Standard
A single observation, 
\begin_inset Formula $y=0$
\end_inset

, is introduced, and the absolute difference between the generated 
\begin_inset Formula $x$
\end_inset

 and the observation 
\begin_inset Formula $y$
\end_inset

 is chosen as the distance function: 
\begin_inset Formula $d(x,y)=|x-y|$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
What to focus on here? How much should be done?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/experiment1_histogram.png
	scale 30

\end_inset


\begin_inset Graphics
	filename figures/exp1_09_10000_histogram.png
	scale 30

\end_inset


\begin_inset Graphics
	filename figures/exp1_09_100000_histogram.png
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption

\begin_layout Plain Layout
Histogram showing sample distribution of 
\begin_inset Formula $\theta$
\end_inset

 with 1000, 10000 and 100 000 particles respectively.
 When running 
\begin_inset Formula $\alpha$
\end_inset

 was set to 0.9, and 
\begin_inset Formula $\epsilon=0.01$
\end_inset

 was the stopping criterion.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Estimating the coefficients of an MA(2) process
\end_layout

\begin_layout Standard
This example is used in 
\begin_inset CommandInset citation
LatexCommand citet
key "approx_bayes_comp"

\end_inset

.
 The problem is to estimate the parameters of an MA(2) stochastic process,
 which is defined as:
\begin_inset Formula 
\begin{equation}
z_{t}=a_{t}-\theta_{1}a_{t-1}-\theta_{2}a_{t-2}\label{eq:ma_2_model}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where the 
\begin_inset Formula $a_{t}$
\end_inset

, 
\begin_inset Formula $a_{t-1}$
\end_inset

 and 
\begin_inset Formula $a_{t-2}$
\end_inset

 is 
\begin_inset Quotes eld
\end_inset

white noise.
\begin_inset Quotes erd
\end_inset

 That is: A sequence of uncorrelated random variables with 
\begin_inset Formula $\mathrm{E}(a_{t})=0$
\end_inset

 and 
\begin_inset Formula $\mathrm{Var}(a_{t})=\sigma_{a}^{2}$
\end_inset

.
 In the example here they are standard normal random variables,
\begin_inset Formula $\mathrm{N}(0,1)$
\end_inset

.
 The parameters 
\begin_inset Formula $\boldsymbol{\theta}=\left[\theta_{1},\theta_{2}\right]$
\end_inset

 are the ones we wish to estimate based on a realisation of the stochastic
 process.
\end_layout

\begin_layout Standard
Like the previous example this is also for illustation purposes, and estimates
 for the parameters can be provided without using ABC methods.
 Given a time series a standard method to determine a suitable model is
 to look at what is called the autocorrelation function computed for the
 realisation.
 Based on the shape of it a general model is choosen, and after the type
 is chosen, the relation between the autocorrelation function and the model
 parameters can be used to provide estimates for the latter.
\end_layout

\begin_layout Standard
In fact for the MA(q) model we have a closed expression for the likelihood
 which we can evaluate.
 The likelihood of a process of order 
\begin_inset Formula $q$
\end_inset

 is: 
\begin_inset Formula 
\[
L(\boldsymbol{\theta},\sigma_{a}^{2}|\boldsymbol{z})=(\sigma_{a}^{2})^{-\frac{n}{2}}\left|\boldsymbol{\mathrm{D}}\right|^{-\frac{1}{2}}\exp\left(-\frac{1}{2\sigma_{a}^{2}}\sum_{t=1-q}^{n}\hat{a}_{t}^{2}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
The derivation can be found in 
\begin_inset CommandInset citation
LatexCommand citet
key "Model_estimation"

\end_inset

, and we only describe the terms here.
 The matrix 
\begin_inset Formula $\mathrm{\boldsymbol{D}}=\mathrm{\boldsymbol{I}}_{q}+\mathrm{\boldsymbol{F}}^{T}(\mathrm{\boldsymbol{L}}^{T})^{-1}\mathrm{\boldsymbol{L}}^{-1}\mathrm{\boldsymbol{F}}$
\end_inset

, where 
\begin_inset Formula $\mathrm{\boldsymbol{I}}_{q}$
\end_inset

 is the identity matrix of size 
\begin_inset Formula $q$
\end_inset

, 
\begin_inset Formula $\mathrm{\boldsymbol{L}}$
\end_inset

 is an 
\begin_inset Formula $n\times n$
\end_inset

 lower triangular matrix with ones on the main diagonal, 
\begin_inset Formula $-\theta_{1}$
\end_inset

 on the first subdiagonal, 
\begin_inset Formula $-\theta_{2}$
\end_inset

 on the second subdiagonal and so on.
 The matrix 
\begin_inset Formula $\mathrm{\boldsymbol{F}}=\left[\mathrm{\boldsymbol{B}}_{q}^{T},\boldsymbol{0}^{T}\right]^{T}$
\end_inset

 where:
\begin_inset Formula 
\[
\mathrm{\boldsymbol{B}}_{q}=-\left[\begin{array}{cccc}
\theta_{q} & \theta_{q-1} & \dots & \theta_{1}\\
0 & \theta_{q} & \dots & \theta_{2}\\
\vdots & \vdots &  & \vdots\\
0 & 0 & \dots & \theta_{q}
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Standard
And 
\begin_inset Formula $\boldsymbol{0}$
\end_inset

 an 
\begin_inset Formula $(n-2)\times q$
\end_inset

 matrix filled with zeros, thus 
\begin_inset Formula $\mathrm{\boldsymbol{F}}$
\end_inset

 is an 
\begin_inset Formula $n\times q$
\end_inset

 matrix.
 The actual time series values is 
\begin_inset Formula $\boldsymbol{z}$
\end_inset

, our observation, and 
\begin_inset Formula $\hat{a}_{t}=z_{t}+\theta_{1}\hat{a}_{t-1}+\theta_{2}\hat{a}_{t-2}$
\end_inset

, the realisations of the 
\begin_inset Formula $a_{t}$
\end_inset

.
 Note that because an element in the time series is directly dependent on
 the two previous steps, because of the 
\begin_inset Formula $a_{t}$
\end_inset

 in (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ma_2_model"

\end_inset

), we need to provide some starter values, 
\begin_inset Formula $\hat{a}_{-1}$
\end_inset

 and 
\begin_inset Formula $\hat{a}_{-2}$
\end_inset

, to be able to compute 
\begin_inset Formula $\hat{a}_{1}$
\end_inset

 and 
\begin_inset Formula $\hat{a}_{2}$
\end_inset

.
\end_layout

\begin_layout Standard
We put some restrictions on the allowed values of 
\begin_inset Formula $\theta_{1}$
\end_inset

 and 
\begin_inset Formula $\theta_{2}$
\end_inset

 to make the process what is called 
\shape italic
invertible
\shape default
.
 This means that the value at time 
\begin_inset Formula $t$
\end_inset

 is less impacted by values of 
\begin_inset Formula $a_{t}$
\end_inset

 that are further back than it is by recent ones, which makes intuitive
 sense.
 We do not give a proof for this, and just state the conditions we put on
 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 to make the process invertible:
\begin_inset Formula 
\begin{align*}
\theta_{1}+\theta_{2} & <1\\
\theta_{2}-\theta_{1} & <1\\
-1<\theta_{2} & <1
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The conditions are enforced through the prior, which we define to be uniform
 on the set of allowed values.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
pagebreak
\end_layout

\end_inset


\end_layout

\begin_layout Section
\start_of_appendix
Source code
\end_layout

\begin_layout Standard
An implementation of the algorithm is available as R code 
\begin_inset CommandInset citation
LatexCommand cite
key "R_language"

\end_inset

, and the source code is available from GitHub at 
\begin_inset CommandInset href
LatexCommand href
name "https://github.com/torebre/abcProject"
target "https://github.com/torebre/abcProject"

\end_inset

.
 The code may be downloaded as a zip-file through the web page, or if the
 user is familiar with the Git source code management system, he can clone
 the repository using the link found on that page.
\end_layout

\begin_layout Subsection
Installing the package in R
\end_layout

\begin_layout Standard
The code in the repository is laid out in the form of an R-package.
 To use it the user must install the package.
 The easiest way to do this is by the devtools-package,
\begin_inset CommandInset citation
LatexCommand cite
key "devtools"

\end_inset

, which is available on CRAN.
\end_layout

\begin_layout Standard
One function in the devtools-package allows the user to install R-packages
 directly from GitHub.
 In the following snippet the code for this project is installed with a
 flag that builds the vignettes for the project.
 A vignette is term for long form documentation that can be included with
 R-packages.
 Building them can take some time, and all the suggested package installs
 specified in the package will also be installed when build_vignettes is
 set to true.
 If the user is not interested in viewing the vignettes, because he only
 wants to look at and use the code say, he can drop the build_vignettes
 argument from the install command, since the default value is false.
\end_layout

\begin_layout Standard
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

install.packages("devtools")
\end_layout

\begin_layout Plain Layout

devtools::install_github("torebre/abcProject", build_vignettes = TRUE)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
If the code is installed with the build_vignettes flag set to true, it is
 possible to see a vignette describing the toy example:
\end_layout

\begin_layout Standard
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

vignette("smcToyExample")
\end_layout

\end_inset


\end_layout

\begin_layout Standard
To uninstall the package run:
\end_layout

\begin_layout Standard
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

devtools::devtools::uninstall("abcProject")
\end_layout

\end_inset


\begin_inset Note Greyedout
status open

\begin_layout Plain Layout
Check that the uninstall works
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
pagebreak
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "references"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
